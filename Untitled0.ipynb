{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qK5FYkm-1ewak1HUhb3E7bEVq-jxjSRf",
      "authorship_tag": "ABX9TyObnuNawCuiKLr8lJh2VtSc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joel224/Financial-ai/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install alpaca_trade_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rRrpvVIGtp0l",
        "outputId": "6f1e2fb6-2247-4fbb-9a04-56c6d2219707"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting alpaca_trade_api\n",
            "  Downloading alpaca_trade_api-3.2.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.11/dist-packages (from alpaca_trade_api) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from alpaca_trade_api) (2.0.2)\n",
            "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.11/dist-packages (from alpaca_trade_api) (2.32.3)\n",
            "Collecting urllib3<2,>1.24 (from alpaca_trade_api)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.11/dist-packages (from alpaca_trade_api) (1.8.0)\n",
            "Collecting websockets<11,>=9.0 (from alpaca_trade_api)\n",
            "  Downloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting msgpack==1.0.3 (from alpaca_trade_api)\n",
            "  Downloading msgpack-1.0.3.tar.gz (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from alpaca_trade_api) (3.11.15)\n",
            "Collecting PyYAML==6.0.1 (from alpaca_trade_api)\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting deprecation==2.1.0 (from alpaca_trade_api)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from deprecation==2.1.0->alpaca_trade_api) (25.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca_trade_api) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca_trade_api) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca_trade_api) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca_trade_api) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca_trade_api) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca_trade_api) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca_trade_api) (1.20.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18.1->alpaca_trade_api) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18.1->alpaca_trade_api) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18.1->alpaca_trade_api) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>2->alpaca_trade_api) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>2->alpaca_trade_api) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>2->alpaca_trade_api) (2025.7.14)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.1.2->aiohttp<4,>=3.8.3->alpaca_trade_api) (4.14.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.18.1->alpaca_trade_api) (1.17.0)\n",
            "Downloading alpaca_trade_api-3.2.0-py3-none-any.whl (34 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: msgpack\n",
            "  Building wheel for msgpack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for msgpack: filename=msgpack-1.0.3-cp311-cp311-linux_x86_64.whl size=15688 sha256=f396b5bb83bb32fadbba8a05a1ed0f8941494e812ab56a4d1b1af6a42ff045e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/35/da/ed9b26b510235e00e3a3c3bab7bad97b59214729662255ab3d\n",
            "Successfully built msgpack\n",
            "Installing collected packages: msgpack, websockets, urllib3, PyYAML, deprecation, alpaca_trade_api\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.1.1\n",
            "    Uninstalling msgpack-1.1.1:\n",
            "      Successfully uninstalled msgpack-1.1.1\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.26.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 10.4 which is incompatible.\n",
            "dataproc-spark-connect 0.8.2 requires websockets>=14.0, but you have websockets 10.4 which is incompatible.\n",
            "yfinance 0.2.65 requires websockets>=13.0, but you have websockets 10.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-6.0.1 alpaca_trade_api-3.2.0 deprecation-2.1.0 msgpack-1.0.3 urllib3-1.26.20 websockets-10.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "d04a8992",
        "outputId": "d9ed33e6-46d9-4673-f04b-87880a070ae5"
      },
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "from alpaca_trade_api import rest\n",
        "from google.colab import userdata # Import userdata here\n",
        "\n",
        "# 1. Define the start and end dates for data fetching.\n",
        "# Using a recent date range for fetching real data\n",
        "start_date = datetime(2023, 1, 1, tzinfo=pytz.utc) # Start date (inclusive, UTC)\n",
        "end_date = datetime(2023, 12, 31, tzinfo=pytz.utc) # End date (inclusive, UTC)\n",
        "\n",
        "# Format dates as strings in 'YYYY-MM-DD' format for the API call\n",
        "start_date_str = start_date.strftime('%Y-%m-%d')\n",
        "end_date_str = end_date.strftime('%Y-%m-%d')\n",
        "\n",
        "# Define the financial instrument (stock symbol)\n",
        "symbol = 'AAPL'\n",
        "\n",
        "# Ensure Alpaca API is instantiated and keys are available\n",
        "# Assuming 'api' (Alpaca REST client) is available from previous steps\n",
        "# Retrieve API keys from Colab secrets\n",
        "try:\n",
        "    ALPACA_API_KEY = userdata.get('APKey')\n",
        "    ALPACA_SECRET_KEY = userdata.get('APSecret')\n",
        "    ALPACA_BASE_URL = \"https://paper-api.alpaca.markets\" # Or \"https://api.alpaca.markets\"\n",
        "\n",
        "    if not ALPACA_API_KEY:\n",
        "        print(\"Alpaca API key ('APKey') not found in Colab secrets. Cannot instantiate client.\")\n",
        "        api = None\n",
        "    elif not ALPACA_SECRET_KEY:\n",
        "        print(\"Alpaca Secret key ('APSecret') not found in Colab secrets. Cannot instantiate client.\")\n",
        "        api = None\n",
        "    else:\n",
        "        # Instantiate the Alpaca REST client\n",
        "        api = rest.REST(ALPACA_API_KEY, ALPACA_SECRET_KEY, ALPACA_BASE_URL)\n",
        "        print(\"Alpaca REST client instantiated successfully.\")\n",
        "\n",
        "    df_financial_alpaca = pd.DataFrame() # Initialize empty DataFrame\n",
        "\n",
        "    if api:\n",
        "        # 2. Use the instantiated Alpaca REST client to fetch historical daily bar data\n",
        "        # Using '1D' for daily bars\n",
        "        print(f\"Fetching historical data for {symbol} from {start_date_str} to {end_date_str} from Alpaca API...\")\n",
        "        try:\n",
        "            barset = api.get_bars(symbol, rest.TimeFrame.Day, start=start_date_str, end=end_date_str).df\n",
        "\n",
        "            if barset is not None and not barset.empty:\n",
        "                df_financial_alpaca = barset.copy() # Use .copy() to avoid SettingWithCopyWarning later\n",
        "\n",
        "                print(f\"Successfully fetched historical data for {symbol}.\")\n",
        "                print(f\"Shape of the fetched data: {df_financial_alpaca.shape}\")\n",
        "\n",
        "                # 3. Convert the fetched Alpaca data into a pandas DataFrame, ensure index and rename columns.\n",
        "                # The result is already a pandas DataFrame if using the .df property.\n",
        "                # Ensure the index is a DatetimeIndex and is sorted.\n",
        "                # The index from Alpaca is already a DatetimeIndex with timezone info.\n",
        "                # Remove timezone info to ensure consistency with other potential data sources later.\n",
        "                df_financial_alpaca.index = df_financial_alpaca.index.tz_convert(None)\n",
        "                df_financial_alpaca.index = df_financial_alpaca.index.normalize() # Set time to midnight\n",
        "                df_financial_alpaca.index.name = 'Date'\n",
        "                df_financial_alpaca.sort_index(inplace=True)\n",
        "\n",
        "                # Rename columns to a consistent format (e.g., 'Open', 'High', 'Low', 'Close', 'Volume').\n",
        "                # Keep only the required columns for the model input.\n",
        "                df_financial_processed = df_financial_alpaca[['open', 'high', 'low', 'close', 'volume']].copy()\n",
        "                df_financial_processed.rename(columns={\n",
        "                    'open': 'Open',\n",
        "                    'high': 'High',\n",
        "                    'low': 'Low',\n",
        "                    'close': 'Close',\n",
        "                    'volume': 'Volume'\n",
        "                }, inplace=True)\n",
        "\n",
        "                print(\"\\nProcessed financial data:\")\n",
        "                display(df_financial_processed.head())\n",
        "                print(\"\\nInfo of the processed financial data:\")\n",
        "                df_financial_processed.info()\n",
        "\n",
        "\n",
        "            else:\n",
        "                print(f\"No data fetched for {symbol} in the specified date range from Alpaca.\")\n",
        "                df_financial_processed = pd.DataFrame() # Create an empty DataFrame if no data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching historical data from Alpaca API: {e}\")\n",
        "            df_financial_processed = pd.DataFrame() # Create an empty DataFrame in case of error\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during Alpaca API key retrieval or client instantiation: {e}\")\n",
        "    df_financial_processed = pd.DataFrame() # Ensure df_financial_processed is defined even on setup error\n",
        "\n",
        "\n",
        "# Initialize loaded_dataframes if not already present (e.g., if running this cell first)\n",
        "if 'loaded_dataframes' not in locals():\n",
        "    loaded_dataframes = {}\n",
        "    print(\"\\n'loaded_dataframes' dictionary initialized.\")\n",
        "\n",
        "# Store the processed financial data\n",
        "loaded_dataframes['financial_time_series'] = df_financial_processed\n",
        "print(\"\\nProcessed financial data stored in loaded_dataframes['financial_time_series'].\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpaca REST client instantiated successfully.\n",
            "Fetching historical data for AAPL from 2023-01-01 to 2023-12-31 from Alpaca API...\n",
            "Successfully fetched historical data for AAPL.\n",
            "Shape of the fetched data: (250, 7)\n",
            "\n",
            "Processed financial data:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               Open      High     Low   Close     Volume\n",
              "Date                                                    \n",
              "2023-01-03  130.280  130.9000  124.17  125.07  124289279\n",
              "2023-01-04  126.890  128.6557  125.08  126.36   95426133\n",
              "2023-01-05  127.130  127.7700  124.76  125.02   88344592\n",
              "2023-01-06  126.010  130.2900  124.89  129.62   96468673\n",
              "2023-01-09  130.465  133.4100  129.89  130.15   76653608"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-017b9d44-51a1-481e-8eae-10ab9f23c332\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-01-03</th>\n",
              "      <td>130.280</td>\n",
              "      <td>130.9000</td>\n",
              "      <td>124.17</td>\n",
              "      <td>125.07</td>\n",
              "      <td>124289279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-04</th>\n",
              "      <td>126.890</td>\n",
              "      <td>128.6557</td>\n",
              "      <td>125.08</td>\n",
              "      <td>126.36</td>\n",
              "      <td>95426133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-05</th>\n",
              "      <td>127.130</td>\n",
              "      <td>127.7700</td>\n",
              "      <td>124.76</td>\n",
              "      <td>125.02</td>\n",
              "      <td>88344592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-06</th>\n",
              "      <td>126.010</td>\n",
              "      <td>130.2900</td>\n",
              "      <td>124.89</td>\n",
              "      <td>129.62</td>\n",
              "      <td>96468673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09</th>\n",
              "      <td>130.465</td>\n",
              "      <td>133.4100</td>\n",
              "      <td>129.89</td>\n",
              "      <td>130.15</td>\n",
              "      <td>76653608</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-017b9d44-51a1-481e-8eae-10ab9f23c332')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-017b9d44-51a1-481e-8eae-10ab9f23c332 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-017b9d44-51a1-481e-8eae-10ab9f23c332');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bec5bd29-5c0e-4c9c-a5ca-ef7bfa1f553a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bec5bd29-5c0e-4c9c-a5ca-ef7bfa1f553a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bec5bd29-5c0e-4c9c-a5ca-ef7bfa1f553a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nProcessed financial data stored in loaded_dataframes['financial_time_series']\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-01-03 00:00:00\",\n        \"max\": \"2023-01-09 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2023-01-04 00:00:00\",\n          \"2023-01-09 00:00:00\",\n          \"2023-01-05 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0678249442348844,\n        \"min\": 126.01,\n        \"max\": 130.465,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          126.89,\n          130.465,\n          127.13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1847099574085354,\n        \"min\": 127.77,\n        \"max\": 133.41,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          128.6557,\n          133.41,\n          127.77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.334752663559883,\n        \"min\": 124.17,\n        \"max\": 129.89,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          125.08,\n          129.89,\n          124.76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.4771011283353017,\n        \"min\": 125.02,\n        \"max\": 130.15,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          126.36,\n          130.15,\n          125.02\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17560188,\n        \"min\": 76653608,\n        \"max\": 124289279,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          95426133,\n          76653608,\n          88344592\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Info of the processed financial data:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 250 entries, 2023-01-03 to 2023-12-29\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Open    250 non-null    float64\n",
            " 1   High    250 non-null    float64\n",
            " 2   Low     250 non-null    float64\n",
            " 3   Close   250 non-null    float64\n",
            " 4   Volume  250 non-null    int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 11.7 KB\n",
            "\n",
            "'loaded_dataframes' dictionary initialized.\n",
            "\n",
            "Processed financial data stored in loaded_dataframes['financial_time_series'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "06d35346",
        "outputId": "62ab4019-fd39-486c-8243-590be1b64bd0"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the directory containing the financial data CSV files\n",
        "data_dir = '/content/drive/MyDrive/financial_prediction_project/data/'\n",
        "\n",
        "# List all files in the directory\n",
        "try:\n",
        "    all_files = os.listdir(data_dir)\n",
        "    # Filter for CSV files that likely contain financial data (adjust pattern if needed)\n",
        "    # Ensure the pattern includes all relevant years\n",
        "    csv_files = [f for f in all_files if f.endswith('.csv') and ('Global_Markets_Data' in f or 'Stock_Prices' in f)]\n",
        "    csv_files.sort() # Sort files to process chronologically\n",
        "\n",
        "    if not csv_files:\n",
        "        print(f\"No relevant CSV files found in {data_dir}\")\n",
        "        # Initialize an empty DataFrame if no files are found\n",
        "        df_financial_combined_csv = pd.DataFrame()\n",
        "    else:\n",
        "        print(f\"Found {len(csv_files)} relevant CSV files:\")\n",
        "        for f in csv_files:\n",
        "            print(f\"- {f}\")\n",
        "\n",
        "        # List to hold dataframes\n",
        "        list_dfs = []\n",
        "\n",
        "        # Read each CSV into a dataframe and append to the list\n",
        "        print(\"\\nLoading and processing CSV files...\")\n",
        "        for f in csv_files:\n",
        "            file_path = os.path.join(data_dir, f)\n",
        "            try:\n",
        "                # Read the CSV, explicitly not parsing dates initially to handle potential errors\n",
        "                df = pd.read_csv(file_path)\n",
        "\n",
        "                # Attempt to convert a potential date column to datetime and set as index\n",
        "                # Look for common date column names case-insensitively\n",
        "                potential_date_cols = [col for col in df.columns if 'date' in col.lower() or 'timestamp' in col.lower()]\n",
        "                date_col_name = None\n",
        "\n",
        "                if potential_date_cols:\n",
        "                     # Prioritize columns named 'Date' or 'date'\n",
        "                     preferred_cols = ['Date', 'date']\n",
        "                     for pref_col in preferred_cols:\n",
        "                         if pref_col in df.columns:\n",
        "                             date_col_name = pref_col\n",
        "                             break\n",
        "                     # If not found, take the first potential date column\n",
        "                     if date_col_name is None:\n",
        "                          date_col_name = potential_date_cols[0]\n",
        "\n",
        "\n",
        "                if date_col_name and date_col_name in df.columns:\n",
        "                    # Convert date column to datetime, coercing errors to NaT\n",
        "                    df[date_col_name] = pd.to_datetime(df[date_col_name], errors='coerce')\n",
        "                    # Drop rows where date conversion failed\n",
        "                    df.dropna(subset=[date_col_name], inplace=True)\n",
        "                    # Set the date column as index\n",
        "                    df.set_index(date_col_name, inplace=True)\n",
        "                    df.index.name = 'Date' # Ensure index name is 'Date'\n",
        "                    df.sort_index(inplace=True) # Sort by date index\n",
        "                    # Drop the original date column if set_index didn't remove it (shouldn't happen)\n",
        "                    if date_col_name in df.columns:\n",
        "                         df.drop(columns=[date_col_name], inplace=True)\n",
        "\n",
        "                else:\n",
        "                     print(f\"  - Warning: No suitable date column found for {f}. Skipping date indexing.\")\n",
        "                     # If no date column found, try to use the first column as index if it looks like dates\n",
        "                     if len(df.columns) > 0:\n",
        "                          try:\n",
        "                               df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0], errors='coerce')\n",
        "                               df.dropna(subset=[df.columns[0]], inplace=True)\n",
        "                               df.set_index(df.columns[0], inplace=True)\n",
        "                               df.index.name = 'Date'\n",
        "                               df.sort_index(inplace=True)\n",
        "                               print(f\"  - Used first column as date index for {f}.\")\n",
        "                          except Exception as e:\n",
        "                               print(f\"  - Could not use first column as date index for {f}: {e}. Proceeding without date index.\")\n",
        "\n",
        "\n",
        "                # Explicitly drop problematic columns before concatenation\n",
        "                cols_to_drop = ['Ticker', 'Unnamed: 0', 'ticker'] # Include 'ticker' as it appeared in previous info\n",
        "                existing_cols_to_drop = [col for col in cols_to_drop if col in df.columns]\n",
        "                if existing_cols_to_drop:\n",
        "                    df.drop(columns=existing_cols_to_drop, inplace=True)\n",
        "                    print(f\"  - Dropped columns {existing_cols_to_drop} from {f}\")\n",
        "\n",
        "\n",
        "                list_dfs.append(df)\n",
        "                print(f\"  - Processed and added {f} ({len(df)} rows) to list.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  - Error processing {f}: {e}. Skipping this file.\")\n",
        "\n",
        "        # Concatenate all dataframes in the list\n",
        "        if list_dfs:\n",
        "            print(\"\\nConcatenating dataframes...\")\n",
        "            # Concatenate now that problematic columns are removed and dates are handled\n",
        "            df_financial_combined_csv = pd.concat(list_dfs, axis=0, ignore_index=False)\n",
        "            print(\"All CSV files concatenated.\")\n",
        "\n",
        "            # Initial Cleaning: Handle potential duplicate index entries (should be less likely now with date indexing)\n",
        "            initial_rows = len(df_financial_combined_csv)\n",
        "            df_financial_combined_csv = df_financial_combined_csv[~df_financial_combined_csv.index.duplicated(keep='first')]\n",
        "            if len(df_financial_combined_csv) < initial_rows:\n",
        "                print(f\"Removed {initial_rows - len(df_financial_combined_csv)} duplicate index entries.\")\n",
        "\n",
        "            # Ensure the final combined index is a DatetimeIndex and is sorted\n",
        "            # This should already be the case if date indexing worked for individual files\n",
        "            if not isinstance(df_financial_combined_csv.index, pd.DatetimeIndex):\n",
        "                 print(\"Warning: Final combined index is not a DatetimeIndex. Attempting conversion.\")\n",
        "                 df_financial_combined_csv.index = pd.to_datetime(df_financial_combined_csv.index, errors='coerce')\n",
        "                 df_financial_combined_csv.dropna(subset=[df_financial_combined_csv.index.name], inplace=True)\n",
        "                 df_financial_combined_csv.index.name = 'Date'\n",
        "                 df_financial_combined_csv.sort_index(inplace=True)\n",
        "                 print(\"Final index converted and sorted.\")\n",
        "            else:\n",
        "                 df_financial_combined_csv.sort_index(inplace=True) # Ensure final sort\n",
        "\n",
        "            # --- Initial Cleaning for Numerical Data ---\n",
        "            # Identify numerical columns after concatenation\n",
        "            numerical_cols = df_financial_combined_csv.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "            print(\"\\nCombined financial data from CSVs:\")\n",
        "            print(f\"Shape: {df_financial_combined_csv.shape}\")\n",
        "            print(\"Head:\")\n",
        "            display(df_financial_combined_csv.head())\n",
        "            print(\"\\nInfo:\")\n",
        "            df_financial_combined_csv.info()\n",
        "            print(\"\\nMissing values before general cleaning:\")\n",
        "            print(df_financial_combined_csv.isnull().sum())\n",
        "\n",
        "            # Add imputation here if desired, but for initial loading just reporting is fine.\n",
        "            if numerical_cols:\n",
        "                print(\"\\nChecking and reporting missing values in numerical columns:\")\n",
        "                print(df_financial_combined_csv[numerical_cols].isnull().sum())\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(\"\\nNo dataframes were successfully loaded and processed from CSVs.\")\n",
        "            df_financial_combined_csv = pd.DataFrame() # Ensure df is defined as empty\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Directory not found at {data_dir}\")\n",
        "    df_financial_combined_csv = pd.DataFrame() # Ensure df is defined as empty\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred during file listing or processing: {e}\")\n",
        "    df_financial_combined_csv = pd.DataFrame() # Ensure df is defined as empty\n",
        "\n",
        "\n",
        "# Initialize loaded_dataframes if not already present (e.g., if running this cell first)\n",
        "if 'loaded_dataframes' not in locals():\n",
        "    loaded_dataframes = {}\n",
        "    print(\"\\n'loaded_dataframes' dictionary initialized.\")\n",
        "\n",
        "# Store the combined financial data from CSVs\n",
        "loaded_dataframes['financial_time_series_csv'] = df_financial_combined_csv\n",
        "\n",
        "print(\"\\nCombined financial data from CSVs stored in loaded_dataframes['financial_time_series_csv'].\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14 relevant CSV files:\n",
            "- 2010_Global_Markets_Data.csv\n",
            "- 2011_Global_Markets_Data.csv\n",
            "- 2012_Global_Markets_Data.csv\n",
            "- 2013_Global_Markets_Data.csv\n",
            "- 2014_Global_Markets_Data.csv\n",
            "- 2015_Global_Markets_Data.csv\n",
            "- 2016_Global_Markets_Data.csv\n",
            "- 2017_Global_Markets_Data.csv\n",
            "- 2018_Global_Markets_Data.csv\n",
            "- 2019_Global_Markets_Data.csv\n",
            "- 2020_Global_Markets_Data.csv\n",
            "- 2021_Global_Markets_Data.csv\n",
            "- 2022_Global_Markets_Data.csv\n",
            "- 2023_Global_Markets_Data.csv\n",
            "\n",
            "Loading and processing CSV files...\n",
            "  - Dropped columns ['Ticker'] from 2010_Global_Markets_Data.csv\n",
            "  - Processed and added 2010_Global_Markets_Data.csv (3005 rows) to list.\n",
            "  - Dropped columns ['Ticker'] from 2011_Global_Markets_Data.csv\n",
            "  - Processed and added 2011_Global_Markets_Data.csv (2997 rows) to list.\n",
            "  - Dropped columns ['Ticker'] from 2012_Global_Markets_Data.csv\n",
            "  - Processed and added 2012_Global_Markets_Data.csv (2981 rows) to list.\n",
            "  - Dropped columns ['Ticker'] from 2013_Global_Markets_Data.csv\n",
            "  - Processed and added 2013_Global_Markets_Data.csv (2997 rows) to list.\n",
            "  - Dropped columns ['Ticker'] from 2014_Global_Markets_Data.csv\n",
            "  - Processed and added 2014_Global_Markets_Data.csv (2988 rows) to list.\n",
            "  - Dropped columns ['Ticker'] from 2015_Global_Markets_Data.csv\n",
            "  - Processed and added 2015_Global_Markets_Data.csv (2997 rows) to list.\n",
            "  - Dropped columns ['Ticker'] from 2016_Global_Markets_Data.csv\n",
            "  - Processed and added 2016_Global_Markets_Data.csv (2996 rows) to list.\n",
            "  - Dropped columns ['Ticker'] from 2017_Global_Markets_Data.csv\n",
            "  - Processed and added 2017_Global_Markets_Data.csv (3000 rows) to list.\n",
            "  - Dropped columns ['Ticker'] from 2018_Global_Markets_Data.csv\n",
            "  - Processed and added 2018_Global_Markets_Data.csv (2993 rows) to list.\n",
            "  - Dropped columns ['Ticker'] from 2019_Global_Markets_Data.csv\n",
            "  - Processed and added 2019_Global_Markets_Data.csv (2985 rows) to list.\n",
            "  - Dropped columns ['Ticker'] from 2020_Global_Markets_Data.csv\n",
            "  - Processed and added 2020_Global_Markets_Data.csv (3012 rows) to list.\n",
            "  - Dropped columns ['Ticker'] from 2021_Global_Markets_Data.csv\n",
            "  - Processed and added 2021_Global_Markets_Data.csv (3004 rows) to list.\n",
            "  - Dropped columns ['Ticker'] from 2022_Global_Markets_Data.csv\n",
            "  - Processed and added 2022_Global_Markets_Data.csv (2993 rows) to list.\n",
            "  - Dropped columns ['Ticker'] from 2023_Global_Markets_Data.csv\n",
            "  - Processed and added 2023_Global_Markets_Data.csv (1712 rows) to list.\n",
            "\n",
            "Concatenating dataframes...\n",
            "All CSV files concatenated.\n",
            "Removed 37125 duplicate index entries.\n",
            "\n",
            "Combined financial data from CSVs:\n",
            "Shape: (3535, 6)\n",
            "Head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   Open         High          Low        Close    Adj Close  \\\n",
              "Date                                                                          \n",
              "2010-01-04  7184.979980  7331.120117  7184.979980  7326.740234  7326.740234   \n",
              "2010-01-05  7326.740234  7359.459961  7313.600098  7354.870117  7354.870117   \n",
              "2010-01-06  7354.850098  7389.279785  7342.490234  7377.700195  7377.700195   \n",
              "2010-01-07  7377.700195  7398.209961  7325.509766  7393.930176  7393.930176   \n",
              "2010-01-08  7393.930176  7426.410156  7367.810059  7425.350098  7425.350098   \n",
              "\n",
              "                  Volume  \n",
              "Date                      \n",
              "2010-01-04  3.991400e+09  \n",
              "2010-01-05  2.491020e+09  \n",
              "2010-01-06  4.972660e+09  \n",
              "2010-01-07  5.270680e+09  \n",
              "2010-01-08  4.389590e+09  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12a78661-982e-4344-a6a5-d8f4437c3ea6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>7184.979980</td>\n",
              "      <td>7331.120117</td>\n",
              "      <td>7184.979980</td>\n",
              "      <td>7326.740234</td>\n",
              "      <td>7326.740234</td>\n",
              "      <td>3.991400e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>7326.740234</td>\n",
              "      <td>7359.459961</td>\n",
              "      <td>7313.600098</td>\n",
              "      <td>7354.870117</td>\n",
              "      <td>7354.870117</td>\n",
              "      <td>2.491020e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>7354.850098</td>\n",
              "      <td>7389.279785</td>\n",
              "      <td>7342.490234</td>\n",
              "      <td>7377.700195</td>\n",
              "      <td>7377.700195</td>\n",
              "      <td>4.972660e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>7377.700195</td>\n",
              "      <td>7398.209961</td>\n",
              "      <td>7325.509766</td>\n",
              "      <td>7393.930176</td>\n",
              "      <td>7393.930176</td>\n",
              "      <td>5.270680e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>7393.930176</td>\n",
              "      <td>7426.410156</td>\n",
              "      <td>7367.810059</td>\n",
              "      <td>7425.350098</td>\n",
              "      <td>7425.350098</td>\n",
              "      <td>4.389590e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12a78661-982e-4344-a6a5-d8f4437c3ea6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-12a78661-982e-4344-a6a5-d8f4437c3ea6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-12a78661-982e-4344-a6a5-d8f4437c3ea6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-55c7d8f5-0338-42c8-8c6b-81c8ccd97f71\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-55c7d8f5-0338-42c8-8c6b-81c8ccd97f71')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-55c7d8f5-0338-42c8-8c6b-81c8ccd97f71 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nCombined financial data from CSVs stored in loaded_dataframes['financial_time_series_csv']\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2010-01-04 00:00:00\",\n        \"max\": \"2010-01-08 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2010-01-05 00:00:00\",\n          \"2010-01-08 00:00:00\",\n          \"2010-01-06 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 83.65627699856185,\n        \"min\": 7184.97998046875,\n        \"max\": 7393.93017578125,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7326.740234375,\n          7393.93017578125,\n          7354.85009765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.66995294683895,\n        \"min\": 7331.1201171875,\n        \"max\": 7426.41015625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7359.4599609375,\n          7426.41015625,\n          7389.27978515625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 71.12032665577134,\n        \"min\": 7184.97998046875,\n        \"max\": 7367.81005859375,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7313.60009765625,\n          7367.81005859375,\n          7342.490234375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.52470288340124,\n        \"min\": 7326.740234375,\n        \"max\": 7425.35009765625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7354.8701171875,\n          7425.35009765625,\n          7377.7001953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.52470288340124,\n        \"min\": 7326.740234375,\n        \"max\": 7425.35009765625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7354.8701171875,\n          7425.35009765625,\n          7377.7001953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1088665350.5554404,\n        \"min\": 2491020000.0,\n        \"max\": 5270680000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2491020000.0,\n          4389590000.0,\n          4972660000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 3535 entries, 2010-01-04 to 2023-07-28\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Open       3535 non-null   float64\n",
            " 1   High       3535 non-null   float64\n",
            " 2   Low        3535 non-null   float64\n",
            " 3   Close      3535 non-null   float64\n",
            " 4   Adj Close  3535 non-null   float64\n",
            " 5   Volume     3535 non-null   float64\n",
            "dtypes: float64(6)\n",
            "memory usage: 193.3 KB\n",
            "\n",
            "Missing values before general cleaning:\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "\n",
            "Checking and reporting missing values in numerical columns:\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "\n",
            "Combined financial data from CSVs stored in loaded_dataframes['financial_time_series_csv'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "282fa290",
        "outputId": "7474fe02-ecd8-4414-afd2-4809a1974e68"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Access the combined financial data from CSVs\n",
        "# Assuming 'financial_time_series_csv' is available in loaded_dataframes\n",
        "if 'financial_time_series_csv' in loaded_dataframes:\n",
        "    df_financial_combined = loaded_dataframes['financial_time_series_csv'].copy()\n",
        "    print(\"Accessing combined financial data from CSVs for initial cleaning.\")\n",
        "else:\n",
        "    print(\"Error: 'financial_time_series_csv' not found in loaded_dataframes. Cannot proceed with initial cleaning.\")\n",
        "    # Exit the cell if the required data is not available\n",
        "    df_financial_combined = pd.DataFrame() # Set to empty to prevent errors\n",
        "\n",
        "\n",
        "if not df_financial_combined.empty:\n",
        "    print(\"\\n--- Performing Initial Cleaning on Combined Financial Data ---\")\n",
        "\n",
        "    # Ensure the index is a DatetimeIndex and is sorted (should be from previous step, but double check)\n",
        "    if not isinstance(df_financial_combined.index, pd.DatetimeIndex):\n",
        "        print(\"Warning: Index is not a DatetimeIndex. Attempting conversion.\")\n",
        "        df_financial_combined.index = pd.to_datetime(df_financial_combined.index, errors='coerce')\n",
        "        df_financial_combined.dropna(subset=[df_financial_combined.index.name], inplace=True)\n",
        "        df_financial_combined.sort_index(inplace=True)\n",
        "        df_financial_combined.index.name = 'Date'\n",
        "        print(\"Index converted and sorted.\")\n",
        "    else:\n",
        "        df_financial_combined.sort_index(inplace=True) # Ensure sorted\n",
        "\n",
        "\n",
        "    # Identify numerical columns for cleaning\n",
        "    numerical_cols = df_financial_combined.select_dtypes(include=np.number).columns.tolist()\n",
        "    print(f\"\\nNumerical columns identified for cleaning: {numerical_cols}\")\n",
        "\n",
        "    if numerical_cols:\n",
        "        # 1. Handle missing values for numerical columns (using median imputation)\n",
        "        print(\"\\nHandling missing values in numerical columns:\")\n",
        "        for col in numerical_cols:\n",
        "            if df_financial_combined[col].isnull().any():\n",
        "                median_val = df_financial_combined[col].median()\n",
        "                missing_count = df_financial_combined[col].isnull().sum()\n",
        "                df_financial_combined[col].fillna(median_val, inplace=True)\n",
        "                print(f\"  - Imputed {missing_count} missing values in '{col}' with the median ({median_val:.2f}).\")\n",
        "        print(\"Missing values after imputation:\")\n",
        "        print(df_financial_combined[numerical_cols].isnull().sum())\n",
        "\n",
        "\n",
        "        # 2. Address basic outliers in numerical columns (using a simple capping method, e.g., based on quantiles or standard deviations)\n",
        "        # Using IQR for capping as in previous attempts\n",
        "        print(\"\\nAddressing basic outliers in numerical columns (using IQR capping):\")\n",
        "        for col in numerical_cols:\n",
        "            Q1 = df_financial_combined[col].quantile(0.25)\n",
        "            Q3 = df_financial_combined[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            # Define bounds - adjust multiplier (1.5) if needed\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "            # Capping outliers\n",
        "            outlier_count_lower = df_financial_combined[df_financial_combined[col] < lower_bound].shape[0]\n",
        "            outlier_count_upper = df_financial_combined[df_financial_combined[col] > upper_bound].shape[0]\n",
        "            if outlier_count_lower > 0 or outlier_count_upper > 0:\n",
        "                df_financial_combined[col] = df_financial_combined[col].clip(lower=lower_bound, upper=upper_bound)\n",
        "                print(f\"  - Capped {outlier_count_lower} lower and {outlier_count_upper} upper outliers in '{col}' using IQR.\")\n",
        "            else:\n",
        "                print(f\"  - No outliers detected in '{col}' based on IQR method.\")\n",
        "\n",
        "        print(\"\\nInitial cleaning complete.\")\n",
        "        print(\"Head of the cleaned financial data:\")\n",
        "        display(df_financial_combined.head())\n",
        "        print(\"\\nInfo of the cleaned financial data:\")\n",
        "        df_financial_combined.info()\n",
        "\n",
        "        # Store the cleaned financial data back into loaded_dataframes\n",
        "        loaded_dataframes['financial_time_series_cleaned'] = df_financial_combined\n",
        "        print(\"\\nCleaned financial data stored in loaded_dataframes['financial_time_series_cleaned'].\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\nNo numerical columns found for cleaning.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nFinancial combined dataframe is empty. Skipping initial cleaning.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accessing combined financial data from CSVs for initial cleaning.\n",
            "\n",
            "--- Performing Initial Cleaning on Combined Financial Data ---\n",
            "\n",
            "Numerical columns identified for cleaning: ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
            "\n",
            "Handling missing values in numerical columns:\n",
            "Missing values after imputation:\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "dtype: int64\n",
            "\n",
            "Addressing basic outliers in numerical columns (using IQR capping):\n",
            "  - Capped 0 lower and 14 upper outliers in 'Open' using IQR.\n",
            "  - Capped 0 lower and 14 upper outliers in 'High' using IQR.\n",
            "  - Capped 0 lower and 13 upper outliers in 'Low' using IQR.\n",
            "  - Capped 0 lower and 13 upper outliers in 'Close' using IQR.\n",
            "  - Capped 0 lower and 13 upper outliers in 'Adj Close' using IQR.\n",
            "  - Capped 149 lower and 155 upper outliers in 'Volume' using IQR.\n",
            "\n",
            "Initial cleaning complete.\n",
            "Head of the cleaned financial data:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   Open         High          Low        Close    Adj Close  \\\n",
              "Date                                                                          \n",
              "2010-01-04  7184.979980  7331.120117  7184.979980  7326.740234  7326.740234   \n",
              "2010-01-05  7326.740234  7359.459961  7313.600098  7354.870117  7354.870117   \n",
              "2010-01-06  7354.850098  7389.279785  7342.490234  7377.700195  7377.700195   \n",
              "2010-01-07  7377.700195  7398.209961  7325.509766  7393.930176  7393.930176   \n",
              "2010-01-08  7393.930176  7426.410156  7367.810059  7425.350098  7425.350098   \n",
              "\n",
              "                  Volume  \n",
              "Date                      \n",
              "2010-01-04  3.991400e+09  \n",
              "2010-01-05  2.491020e+09  \n",
              "2010-01-06  4.972660e+09  \n",
              "2010-01-07  5.270680e+09  \n",
              "2010-01-08  4.389590e+09  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5abbdc11-9ab9-446d-a479-db404818ac92\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>7184.979980</td>\n",
              "      <td>7331.120117</td>\n",
              "      <td>7184.979980</td>\n",
              "      <td>7326.740234</td>\n",
              "      <td>7326.740234</td>\n",
              "      <td>3.991400e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>7326.740234</td>\n",
              "      <td>7359.459961</td>\n",
              "      <td>7313.600098</td>\n",
              "      <td>7354.870117</td>\n",
              "      <td>7354.870117</td>\n",
              "      <td>2.491020e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>7354.850098</td>\n",
              "      <td>7389.279785</td>\n",
              "      <td>7342.490234</td>\n",
              "      <td>7377.700195</td>\n",
              "      <td>7377.700195</td>\n",
              "      <td>4.972660e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>7377.700195</td>\n",
              "      <td>7398.209961</td>\n",
              "      <td>7325.509766</td>\n",
              "      <td>7393.930176</td>\n",
              "      <td>7393.930176</td>\n",
              "      <td>5.270680e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>7393.930176</td>\n",
              "      <td>7426.410156</td>\n",
              "      <td>7367.810059</td>\n",
              "      <td>7425.350098</td>\n",
              "      <td>7425.350098</td>\n",
              "      <td>4.389590e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5abbdc11-9ab9-446d-a479-db404818ac92')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5abbdc11-9ab9-446d-a479-db404818ac92 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5abbdc11-9ab9-446d-a479-db404818ac92');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-669dba8a-4858-4b80-912a-ae86bc8ce606\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-669dba8a-4858-4b80-912a-ae86bc8ce606')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-669dba8a-4858-4b80-912a-ae86bc8ce606 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"\\\\nFinancial combined dataframe is empty\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2010-01-04 00:00:00\",\n        \"max\": \"2010-01-08 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2010-01-05 00:00:00\",\n          \"2010-01-08 00:00:00\",\n          \"2010-01-06 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 83.65627699856185,\n        \"min\": 7184.97998046875,\n        \"max\": 7393.93017578125,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7326.740234375,\n          7393.93017578125,\n          7354.85009765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.66995294683895,\n        \"min\": 7331.1201171875,\n        \"max\": 7426.41015625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7359.4599609375,\n          7426.41015625,\n          7389.27978515625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 71.12032665577134,\n        \"min\": 7184.97998046875,\n        \"max\": 7367.81005859375,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7313.60009765625,\n          7367.81005859375,\n          7342.490234375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.52470288340124,\n        \"min\": 7326.740234375,\n        \"max\": 7425.35009765625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7354.8701171875,\n          7425.35009765625,\n          7377.7001953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.52470288340124,\n        \"min\": 7326.740234375,\n        \"max\": 7425.35009765625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7354.8701171875,\n          7425.35009765625,\n          7377.7001953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1088665350.5554404,\n        \"min\": 2491020000.0,\n        \"max\": 5270680000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2491020000.0,\n          4389590000.0,\n          4972660000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Info of the cleaned financial data:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 3535 entries, 2010-01-04 to 2023-07-28\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Open       3535 non-null   float64\n",
            " 1   High       3535 non-null   float64\n",
            " 2   Low        3535 non-null   float64\n",
            " 3   Close      3535 non-null   float64\n",
            " 4   Adj Close  3535 non-null   float64\n",
            " 5   Volume     3535 non-null   float64\n",
            "dtypes: float64(6)\n",
            "memory usage: 193.3 KB\n",
            "\n",
            "Cleaned financial data stored in loaded_dataframes['financial_time_series_cleaned'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5f4bf4e6",
        "outputId": "d073fe6f-83fe-4eae-c0ed-b5ca1f0862c7"
      },
      "source": [
        "import pandas as pd\n",
        "import pandas_datareader.data as web\n",
        "import datetime\n",
        "\n",
        "# Ensure the cleaned financial data is available\n",
        "if 'financial_time_series_cleaned' in loaded_dataframes:\n",
        "    df_financial_cleaned = loaded_dataframes['financial_time_series_cleaned'].copy()\n",
        "    print(\"Accessing cleaned financial data for macroeconomic data integration.\")\n",
        "else:\n",
        "    print(\"Error: 'financial_time_series_cleaned' not found in loaded_dataframes. Cannot proceed with macroeconomic data integration.\")\n",
        "    # Exit the cell if required data is missing\n",
        "    df_financial_cleaned = pd.DataFrame() # Set to empty to prevent errors\n",
        "\n",
        "\n",
        "if not df_financial_cleaned.empty:\n",
        "    print(\"\\n--- Fetching and Integrating Macroeconomic Data ---\")\n",
        "\n",
        "    # Define the date range for fetching macroeconomic data based on the financial data\n",
        "    start_date_macro = df_financial_cleaned.index.min()\n",
        "    end_date_macro = df_financial_cleaned.index.max()\n",
        "    print(f\"Fetching macroeconomic data from {start_date_macro.strftime('%Y-%m-%d')} to {end_date_macro.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "    # Choose a macroeconomic indicator (e.g., Federal Funds Effective Rate)\n",
        "    fred_symbol = 'DFF' # Federal Funds Effective Rate\n",
        "\n",
        "    # Fetch data from FRED\n",
        "    try:\n",
        "        df_macroeconomic = web.DataReader(fred_symbol, 'fred', start_date_macro, end_date_macro)\n",
        "\n",
        "        if not df_macroeconomic.empty:\n",
        "            print(f\"Successfully fetched macroeconomic data ({fred_symbol}) from FRED.\")\n",
        "            print(f\"Shape of the fetched data: {df_macroeconomic.shape}\")\n",
        "            print(\"\\nHead of the macroeconomic data:\")\n",
        "            display(df_macroeconomic.head())\n",
        "            print(\"\\nInfo of the macroeconomic data:\")\n",
        "            df_macroeconomic.info()\n",
        "\n",
        "            # Ensure the index is a DatetimeIndex and is named 'Date' and sorted\n",
        "            df_macroeconomic.index = pd.to_datetime(df_macroeconomic.index)\n",
        "            df_macroeconomic.index.name = 'Date'\n",
        "            df_macroeconomic.sort_index(inplace=True)\n",
        "\n",
        "            # Temporal Alignment: Merge the macroeconomic data with the financial data\n",
        "            # Create a full daily date range based on the financial data\n",
        "            full_daily_date_range = pd.date_range(start=df_financial_cleaned.index.min(), end=df_financial_cleaned.index.max(), freq='D')\n",
        "\n",
        "            # Reindex the macroeconomic data to the full daily date range and forward-fill missing values\n",
        "            df_macroeconomic_aligned = df_macroeconomic.reindex(full_daily_date_range).ffill()\n",
        "\n",
        "            # Merge the aligned macroeconomic DataFrame with the financial time series DataFrame\n",
        "            # Use a left merge to keep all dates from the financial time series\n",
        "            df_financial_macro_combined = df_financial_cleaned.merge(df_macroeconomic_aligned, left_index=True, right_index=True, how='left')\n",
        "\n",
        "            # Fill any remaining NaNs in the macroeconomic column after merge (e.g., at the very beginning if macro data starts later)\n",
        "            # Use backward-fill for any initial NaNs\n",
        "            df_financial_macro_combined.fillna(method='bfill', inplace=True)\n",
        "\n",
        "            print(\"\\nMacroeconomic data integrated and aligned with financial data.\")\n",
        "            print(\"Head of the combined Financial and Macroeconomic DataFrame:\")\n",
        "            display(df_financial_macro_combined.head())\n",
        "            print(\"\\nInfo of the combined Financial and Macroeconomic DataFrame:\")\n",
        "            df_financial_macro_combined.info()\n",
        "            print(\"\\nMissing values in the combined DataFrame after alignment and filling:\")\n",
        "            print(df_financial_macro_combined.isnull().sum()) # Should ideally be all zeros for numerical cols\n",
        "\n",
        "            # Store the combined DataFrame\n",
        "            loaded_dataframes['financial_macro_combined'] = df_financial_macro_combined\n",
        "            print(\"\\nCombined financial and macroeconomic data stored in loaded_dataframes['financial_macro_combined'].\")\n",
        "\n",
        "        else:\n",
        "            print(f\"No data fetched for {fred_symbol} in the specified date range from FRED.\")\n",
        "            # Store the financial data as the combined data if macro data is missing\n",
        "            loaded_dataframes['financial_macro_combined'] = df_financial_cleaned.copy()\n",
        "            print(\"\\nMacroeconomic data not available. Storing only financial data in loaded_dataframes['financial_macro_combined'].\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching or integrating macroeconomic data from FRED: {e}\")\n",
        "        # Store the financial data as the combined data in case of error\n",
        "        loaded_dataframes['financial_macro_combined'] = df_financial_cleaned.copy()\n",
        "        print(\"\\nError during macroeconomic data integration. Storing only financial data in loaded_dataframes['financial_macro_combined'].\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nFinancial cleaned dataframe is empty. Skipping macroeconomic data integration.\")\n",
        "    loaded_dataframes['financial_macro_combined'] = pd.DataFrame() # Ensure combined df is empty if financial data is empty"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accessing cleaned financial data for macroeconomic data integration.\n",
            "\n",
            "--- Fetching and Integrating Macroeconomic Data ---\n",
            "Fetching macroeconomic data from 2010-01-04 to 2023-07-28\n",
            "Successfully fetched macroeconomic data (DFF) from FRED.\n",
            "Shape of the fetched data: (4954, 1)\n",
            "\n",
            "Head of the macroeconomic data:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             DFF\n",
              "DATE            \n",
              "2010-01-04  0.12\n",
              "2010-01-05  0.12\n",
              "2010-01-06  0.12\n",
              "2010-01-07  0.10\n",
              "2010-01-08  0.11"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acd4fafa-1d56-4fc0-ba5d-33ba1797229a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DFF</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATE</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acd4fafa-1d56-4fc0-ba5d-33ba1797229a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-acd4fafa-1d56-4fc0-ba5d-33ba1797229a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-acd4fafa-1d56-4fc0-ba5d-33ba1797229a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c73749fc-6bfd-43d6-b068-2b7c88cd81fb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c73749fc-6bfd-43d6-b068-2b7c88cd81fb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c73749fc-6bfd-43d6-b068-2b7c88cd81fb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    loaded_dataframes['financial_macro_combined'] = pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"DATE\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2010-01-04 00:00:00\",\n        \"max\": \"2010-01-08 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2010-01-05 00:00:00\",\n          \"2010-01-08 00:00:00\",\n          \"2010-01-06 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DFF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008944271909999154,\n        \"min\": 0.1,\n        \"max\": 0.12,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.12,\n          0.1,\n          0.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Info of the macroeconomic data:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 4954 entries, 2010-01-04 to 2023-07-28\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   DFF     4954 non-null   float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 77.4 KB\n",
            "\n",
            "Macroeconomic data integrated and aligned with financial data.\n",
            "Head of the combined Financial and Macroeconomic DataFrame:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-3847567139.py:56: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_financial_macro_combined.fillna(method='bfill', inplace=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   Open         High          Low        Close    Adj Close  \\\n",
              "Date                                                                          \n",
              "2010-01-04  7184.979980  7331.120117  7184.979980  7326.740234  7326.740234   \n",
              "2010-01-05  7326.740234  7359.459961  7313.600098  7354.870117  7354.870117   \n",
              "2010-01-06  7354.850098  7389.279785  7342.490234  7377.700195  7377.700195   \n",
              "2010-01-07  7377.700195  7398.209961  7325.509766  7393.930176  7393.930176   \n",
              "2010-01-08  7393.930176  7426.410156  7367.810059  7425.350098  7425.350098   \n",
              "\n",
              "                  Volume   DFF  \n",
              "Date                            \n",
              "2010-01-04  3.991400e+09  0.12  \n",
              "2010-01-05  2.491020e+09  0.12  \n",
              "2010-01-06  4.972660e+09  0.12  \n",
              "2010-01-07  5.270680e+09  0.10  \n",
              "2010-01-08  4.389590e+09  0.11  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a10011fe-4d18-4b30-92a4-fb5eb926416f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>DFF</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>7184.979980</td>\n",
              "      <td>7331.120117</td>\n",
              "      <td>7184.979980</td>\n",
              "      <td>7326.740234</td>\n",
              "      <td>7326.740234</td>\n",
              "      <td>3.991400e+09</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>7326.740234</td>\n",
              "      <td>7359.459961</td>\n",
              "      <td>7313.600098</td>\n",
              "      <td>7354.870117</td>\n",
              "      <td>7354.870117</td>\n",
              "      <td>2.491020e+09</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>7354.850098</td>\n",
              "      <td>7389.279785</td>\n",
              "      <td>7342.490234</td>\n",
              "      <td>7377.700195</td>\n",
              "      <td>7377.700195</td>\n",
              "      <td>4.972660e+09</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>7377.700195</td>\n",
              "      <td>7398.209961</td>\n",
              "      <td>7325.509766</td>\n",
              "      <td>7393.930176</td>\n",
              "      <td>7393.930176</td>\n",
              "      <td>5.270680e+09</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>7393.930176</td>\n",
              "      <td>7426.410156</td>\n",
              "      <td>7367.810059</td>\n",
              "      <td>7425.350098</td>\n",
              "      <td>7425.350098</td>\n",
              "      <td>4.389590e+09</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a10011fe-4d18-4b30-92a4-fb5eb926416f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a10011fe-4d18-4b30-92a4-fb5eb926416f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a10011fe-4d18-4b30-92a4-fb5eb926416f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f6722e30-bdac-48ad-80a6-e0dd9cad7be9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6722e30-bdac-48ad-80a6-e0dd9cad7be9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f6722e30-bdac-48ad-80a6-e0dd9cad7be9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    loaded_dataframes['financial_macro_combined'] = pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2010-01-04 00:00:00\",\n        \"max\": \"2010-01-08 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2010-01-05 00:00:00\",\n          \"2010-01-08 00:00:00\",\n          \"2010-01-06 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 83.65627699856185,\n        \"min\": 7184.97998046875,\n        \"max\": 7393.93017578125,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7326.740234375,\n          7393.93017578125,\n          7354.85009765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.66995294683895,\n        \"min\": 7331.1201171875,\n        \"max\": 7426.41015625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7359.4599609375,\n          7426.41015625,\n          7389.27978515625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 71.12032665577134,\n        \"min\": 7184.97998046875,\n        \"max\": 7367.81005859375,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7313.60009765625,\n          7367.81005859375,\n          7342.490234375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.52470288340124,\n        \"min\": 7326.740234375,\n        \"max\": 7425.35009765625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7354.8701171875,\n          7425.35009765625,\n          7377.7001953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.52470288340124,\n        \"min\": 7326.740234375,\n        \"max\": 7425.35009765625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7354.8701171875,\n          7425.35009765625,\n          7377.7001953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1088665350.5554404,\n        \"min\": 2491020000.0,\n        \"max\": 5270680000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2491020000.0,\n          4389590000.0,\n          4972660000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DFF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008944271909999154,\n        \"min\": 0.1,\n        \"max\": 0.12,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.12,\n          0.1,\n          0.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Info of the combined Financial and Macroeconomic DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 3535 entries, 2010-01-04 to 2023-07-28\n",
            "Data columns (total 7 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Open       3535 non-null   float64\n",
            " 1   High       3535 non-null   float64\n",
            " 2   Low        3535 non-null   float64\n",
            " 3   Close      3535 non-null   float64\n",
            " 4   Adj Close  3535 non-null   float64\n",
            " 5   Volume     3535 non-null   float64\n",
            " 6   DFF        3535 non-null   float64\n",
            "dtypes: float64(7)\n",
            "memory usage: 220.9 KB\n",
            "\n",
            "Missing values in the combined DataFrame after alignment and filling:\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "DFF          0\n",
            "dtype: int64\n",
            "\n",
            "Combined financial and macroeconomic data stored in loaded_dataframes['financial_macro_combined'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "65e7da24",
        "outputId": "9b8311f5-cbc2-4fe1-9704-ed52a3aad6a7"
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define the directory containing the news data CSV file\n",
        "data_dir = '/content/drive/MyDrive/financial_prediction_project/data/'\n",
        "news_file_name = 'News_Articles.csv' # Assuming this is the name of the news file\n",
        "\n",
        "news_file_path = os.path.join(data_dir, news_file_name)\n",
        "\n",
        "df_news_articles = pd.DataFrame() # Initialize empty DataFrame\n",
        "\n",
        "# Load the news articles CSV file\n",
        "try:\n",
        "    if os.path.exists(news_file_path):\n",
        "        print(f\"Loading news articles from {news_file_path}\")\n",
        "        # Attempt to parse dates and set index on load\n",
        "        df_news_articles = pd.read_csv(news_file_path, parse_dates=['publishedAt'], index_col='publishedAt')\n",
        "        df_news_articles.index.name = 'Date' # Rename index\n",
        "        df_news_articles.sort_index(inplace=True) # Sort by date index\n",
        "        print(\"News articles CSV loaded successfully.\")\n",
        "        print(f\"Shape of the news DataFrame: {df_news_articles.shape}\")\n",
        "        print(\"\\nHead of the raw news data:\")\n",
        "        display(df_news_articles.head())\n",
        "        print(\"\\nInfo of the raw news data:\")\n",
        "        df_news_articles.info()\n",
        "\n",
        "    else:\n",
        "        print(f\"News file not found at {news_file_path}. Skipping news data processing.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading news articles CSV: {e}. Skipping news data processing.\")\n",
        "\n",
        "\n",
        "# --- Text Data Processing for News Articles ---\n",
        "if not df_news_articles.empty:\n",
        "    print(\"\\n--- Processing news_articles ---\")\n",
        "\n",
        "    # Handle any remaining missing values in text columns (e.g., 'content', 'title', 'description')\n",
        "    text_cols = ['title', 'description', 'content'] # Common text columns in news data\n",
        "    processed_text_col = 'Cleaned_Content' # Name for the processed text column\n",
        "    original_text_col_to_process = None # The column that will be processed\n",
        "\n",
        "    # Find a suitable text column to process\n",
        "    for col in ['content', 'description', 'title']:\n",
        "        # Check if the column exists and has non-null values\n",
        "        if col in df_news_articles.columns and df_news_articles[col].notna().any():\n",
        "             original_text_col_to_process = col\n",
        "             print(f\"Using column '{original_text_col_to_process}' for text processing.\")\n",
        "             break\n",
        "\n",
        "    if original_text_col_to_process:\n",
        "        # Fill missing values in the selected text column with empty strings\n",
        "        if df_news_articles[original_text_col_to_process].isnull().any():\n",
        "            missing_count = df_news_articles[original_text_col_to_process].isnull().sum()\n",
        "            df_news_articles[original_text_col_to_process].fillna('', inplace=True)\n",
        "            print(f\"  - Filled {missing_count} missing values in '{original_text_col_to_process}' with an empty string.\")\n",
        "\n",
        "        # Load spaCy model (ensure downloaded: !python -m spacy download en_core_web_sm)\n",
        "        try:\n",
        "            nlp = spacy.load(\"en_core_web_sm\")\n",
        "        except OSError:\n",
        "            print(\"Downloading spaCy model 'en_core_web_sm'...\")\n",
        "            # Using !pip to download the spacy model as a separate step before loading\n",
        "            # This avoids mixing shell commands and Python code in a single cell if not necessary\n",
        "            # Or we can add the spacy download command in a separate cell if preferred\n",
        "            # For now, let's add the download command here for simplicity if the model is not found.\n",
        "            print(\"SpaCy model 'en_core_web_sm' not found. Please run `!python -m spacy download en_core_web_sm` in a separate cell.\")\n",
        "            nlp = None # Set nlp to None if model loading fails\n",
        "\n",
        "\n",
        "        if nlp:\n",
        "            # Define the text processing pipeline function\n",
        "            def process_text(text):\n",
        "                if not isinstance(text, str):\n",
        "                    return \"\"\n",
        "                doc = nlp(text.lower()) # Lowercasing\n",
        "                # Tokenization, removing stop words and punctuation, and lemmatization\n",
        "                processed_tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
        "                return \" \".join(processed_tokens)\n",
        "\n",
        "            # Apply the text processing pipeline to the selected text column\n",
        "            df_news_articles[processed_text_col] = df_news_articles[original_text_col_to_process].apply(process_text)\n",
        "            print(f\"Text processing applied to '{original_text_col_to_process}' and stored in '{processed_text_col}'.\")\n",
        "\n",
        "            # Generate text embeddings using SentenceTransformer\n",
        "            try:\n",
        "                # Choose a pre-trained model suitable for CPU\n",
        "                model_st = SentenceTransformer('all-MiniLM-L6-v2') # Renamed variable to avoid conflict with Keras model\n",
        "                print(\"SentenceTransformer model loaded.\")\n",
        "            except Exception as e:\n",
        "                 print(f\"Error loading SentenceTransformer model: {e}. Skipping embedding generation.\")\n",
        "                 model_st = None # Set to None if model loading fails\n",
        "\n",
        "            if model_st:\n",
        "                print(f\"Generating text embeddings for '{processed_text_col}'...\")\n",
        "                # Handle potential empty strings or non-string values\n",
        "                cleaned_content_list = df_news_articles[processed_text_col].tolist()\n",
        "                # Ensure all elements are strings before encoding\n",
        "                cleaned_content_list = [str(content) for content in cleaned_content_list]\n",
        "\n",
        "                # Generate embeddings\n",
        "                # The batch size for SentenceTransformer encode can be adjusted if memory is an issue\n",
        "                text_embeddings = model_st.encode(cleaned_content_list, show_progress_bar=True)\n",
        "\n",
        "                # Store the embeddings in a new column\n",
        "                embedding_dim_news = text_embeddings.shape[1] # Get the actual embedding dimension\n",
        "                df_news_articles['Text_Embeddings'] = list(text_embeddings)\n",
        "                print(f\"Text embeddings generated with shape: {text_embeddings.shape}\")\n",
        "                print(\"Embeddings stored in 'Text_Embeddings' column.\")\n",
        "\n",
        "                # Display the first few rows with the new 'Cleaned_Content' and 'Text_Embeddings' columns\n",
        "                display(df_news_articles[[original_text_col_to_process, processed_text_col, 'Text_Embeddings']].head())\n",
        "\n",
        "            else:\n",
        "                print(\"Text embedding generation skipped due to model loading failure.\")\n",
        "\n",
        "        else:\n",
        "            print(\"SpaCy model not loaded. Skipping text processing and embedding generation.\")\n",
        "\n",
        "    else:\n",
        "        print(\"Warning: No suitable text column (content, description, or title) with data found for processing in news_articles.\")\n",
        "\n",
        "\n",
        "    print(\"--- Finished processing news_articles ---\")\n",
        "    # Store the processed news dataframe\n",
        "    loaded_dataframes['news_articles_processed'] = df_news_articles\n",
        "\n",
        "else:\n",
        "    print(\"\\nNews articles dataframe is empty. Skipping news data processing.\")\n",
        "\n",
        "# Optional: Display head and info of all cleaned dataframes to verify\n",
        "print(\"\\n--- Overview of all processed dataframes loaded so far ---\")\n",
        "for df_name, df in loaded_dataframes.items():\n",
        "     print(f\"\\nDataFrame: {df_name}\")\n",
        "     # Check if the dataframe is not empty before displaying head\n",
        "     if not df.empty:\n",
        "         display(df.head())\n",
        "         df.info()\n",
        "     else:\n",
        "         print(\"DataFrame is empty or not found.\")\n",
        "     print(\"-\" * 30)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "News file not found at /content/drive/MyDrive/financial_prediction_project/data/News_Articles.csv. Skipping news data processing.\n",
            "\n",
            "News articles dataframe is empty. Skipping news data processing.\n",
            "\n",
            "--- Overview of all processed dataframes loaded so far ---\n",
            "\n",
            "DataFrame: financial_time_series\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               Open      High     Low   Close     Volume\n",
              "Date                                                    \n",
              "2023-01-03  130.280  130.9000  124.17  125.07  124289279\n",
              "2023-01-04  126.890  128.6557  125.08  126.36   95426133\n",
              "2023-01-05  127.130  127.7700  124.76  125.02   88344592\n",
              "2023-01-06  126.010  130.2900  124.89  129.62   96468673\n",
              "2023-01-09  130.465  133.4100  129.89  130.15   76653608"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf4c35c4-174b-42d8-9d26-198a72013cf8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-01-03</th>\n",
              "      <td>130.280</td>\n",
              "      <td>130.9000</td>\n",
              "      <td>124.17</td>\n",
              "      <td>125.07</td>\n",
              "      <td>124289279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-04</th>\n",
              "      <td>126.890</td>\n",
              "      <td>128.6557</td>\n",
              "      <td>125.08</td>\n",
              "      <td>126.36</td>\n",
              "      <td>95426133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-05</th>\n",
              "      <td>127.130</td>\n",
              "      <td>127.7700</td>\n",
              "      <td>124.76</td>\n",
              "      <td>125.02</td>\n",
              "      <td>88344592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-06</th>\n",
              "      <td>126.010</td>\n",
              "      <td>130.2900</td>\n",
              "      <td>124.89</td>\n",
              "      <td>129.62</td>\n",
              "      <td>96468673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-09</th>\n",
              "      <td>130.465</td>\n",
              "      <td>133.4100</td>\n",
              "      <td>129.89</td>\n",
              "      <td>130.15</td>\n",
              "      <td>76653608</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf4c35c4-174b-42d8-9d26-198a72013cf8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf4c35c4-174b-42d8-9d26-198a72013cf8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf4c35c4-174b-42d8-9d26-198a72013cf8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-afc70599-a5aa-4d8b-85ed-4dd9a5255250\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-afc70599-a5aa-4d8b-85ed-4dd9a5255250')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-afc70599-a5aa-4d8b-85ed-4dd9a5255250 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"     print(\\\"-\\\" * 30)\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-01-03 00:00:00\",\n        \"max\": \"2023-01-09 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2023-01-04 00:00:00\",\n          \"2023-01-09 00:00:00\",\n          \"2023-01-05 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0678249442348844,\n        \"min\": 126.01,\n        \"max\": 130.465,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          126.89,\n          130.465,\n          127.13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1847099574085354,\n        \"min\": 127.77,\n        \"max\": 133.41,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          128.6557,\n          133.41,\n          127.77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.334752663559883,\n        \"min\": 124.17,\n        \"max\": 129.89,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          125.08,\n          129.89,\n          124.76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.4771011283353017,\n        \"min\": 125.02,\n        \"max\": 130.15,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          126.36,\n          130.15,\n          125.02\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17560188,\n        \"min\": 76653608,\n        \"max\": 124289279,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          95426133,\n          76653608,\n          88344592\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 250 entries, 2023-01-03 to 2023-12-29\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Open    250 non-null    float64\n",
            " 1   High    250 non-null    float64\n",
            " 2   Low     250 non-null    float64\n",
            " 3   Close   250 non-null    float64\n",
            " 4   Volume  250 non-null    int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 11.7 KB\n",
            "------------------------------\n",
            "\n",
            "DataFrame: financial_time_series_csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   Open         High          Low        Close    Adj Close  \\\n",
              "Date                                                                          \n",
              "2010-01-04  7184.979980  7331.120117  7184.979980  7326.740234  7326.740234   \n",
              "2010-01-05  7326.740234  7359.459961  7313.600098  7354.870117  7354.870117   \n",
              "2010-01-06  7354.850098  7389.279785  7342.490234  7377.700195  7377.700195   \n",
              "2010-01-07  7377.700195  7398.209961  7325.509766  7393.930176  7393.930176   \n",
              "2010-01-08  7393.930176  7426.410156  7367.810059  7425.350098  7425.350098   \n",
              "\n",
              "                  Volume  \n",
              "Date                      \n",
              "2010-01-04  3.991400e+09  \n",
              "2010-01-05  2.491020e+09  \n",
              "2010-01-06  4.972660e+09  \n",
              "2010-01-07  5.270680e+09  \n",
              "2010-01-08  4.389590e+09  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca375266-1a43-43e3-9fa4-7d42cc3e6499\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>7184.979980</td>\n",
              "      <td>7331.120117</td>\n",
              "      <td>7184.979980</td>\n",
              "      <td>7326.740234</td>\n",
              "      <td>7326.740234</td>\n",
              "      <td>3.991400e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>7326.740234</td>\n",
              "      <td>7359.459961</td>\n",
              "      <td>7313.600098</td>\n",
              "      <td>7354.870117</td>\n",
              "      <td>7354.870117</td>\n",
              "      <td>2.491020e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>7354.850098</td>\n",
              "      <td>7389.279785</td>\n",
              "      <td>7342.490234</td>\n",
              "      <td>7377.700195</td>\n",
              "      <td>7377.700195</td>\n",
              "      <td>4.972660e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>7377.700195</td>\n",
              "      <td>7398.209961</td>\n",
              "      <td>7325.509766</td>\n",
              "      <td>7393.930176</td>\n",
              "      <td>7393.930176</td>\n",
              "      <td>5.270680e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>7393.930176</td>\n",
              "      <td>7426.410156</td>\n",
              "      <td>7367.810059</td>\n",
              "      <td>7425.350098</td>\n",
              "      <td>7425.350098</td>\n",
              "      <td>4.389590e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca375266-1a43-43e3-9fa4-7d42cc3e6499')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca375266-1a43-43e3-9fa4-7d42cc3e6499 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca375266-1a43-43e3-9fa4-7d42cc3e6499');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9f406552-e7a4-43d4-9737-ad29ac0a4b89\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f406552-e7a4-43d4-9737-ad29ac0a4b89')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9f406552-e7a4-43d4-9737-ad29ac0a4b89 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"     print(\\\"-\\\" * 30)\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2010-01-04 00:00:00\",\n        \"max\": \"2010-01-08 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2010-01-05 00:00:00\",\n          \"2010-01-08 00:00:00\",\n          \"2010-01-06 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 83.65627699856185,\n        \"min\": 7184.97998046875,\n        \"max\": 7393.93017578125,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7326.740234375,\n          7393.93017578125,\n          7354.85009765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.66995294683895,\n        \"min\": 7331.1201171875,\n        \"max\": 7426.41015625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7359.4599609375,\n          7426.41015625,\n          7389.27978515625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 71.12032665577134,\n        \"min\": 7184.97998046875,\n        \"max\": 7367.81005859375,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7313.60009765625,\n          7367.81005859375,\n          7342.490234375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.52470288340124,\n        \"min\": 7326.740234375,\n        \"max\": 7425.35009765625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7354.8701171875,\n          7425.35009765625,\n          7377.7001953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.52470288340124,\n        \"min\": 7326.740234375,\n        \"max\": 7425.35009765625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7354.8701171875,\n          7425.35009765625,\n          7377.7001953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1088665350.5554404,\n        \"min\": 2491020000.0,\n        \"max\": 5270680000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2491020000.0,\n          4389590000.0,\n          4972660000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 3535 entries, 2010-01-04 to 2023-07-28\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Open       3535 non-null   float64\n",
            " 1   High       3535 non-null   float64\n",
            " 2   Low        3535 non-null   float64\n",
            " 3   Close      3535 non-null   float64\n",
            " 4   Adj Close  3535 non-null   float64\n",
            " 5   Volume     3535 non-null   float64\n",
            "dtypes: float64(6)\n",
            "memory usage: 193.3 KB\n",
            "------------------------------\n",
            "\n",
            "DataFrame: financial_time_series_cleaned\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   Open         High          Low        Close    Adj Close  \\\n",
              "Date                                                                          \n",
              "2010-01-04  7184.979980  7331.120117  7184.979980  7326.740234  7326.740234   \n",
              "2010-01-05  7326.740234  7359.459961  7313.600098  7354.870117  7354.870117   \n",
              "2010-01-06  7354.850098  7389.279785  7342.490234  7377.700195  7377.700195   \n",
              "2010-01-07  7377.700195  7398.209961  7325.509766  7393.930176  7393.930176   \n",
              "2010-01-08  7393.930176  7426.410156  7367.810059  7425.350098  7425.350098   \n",
              "\n",
              "                  Volume  \n",
              "Date                      \n",
              "2010-01-04  3.991400e+09  \n",
              "2010-01-05  2.491020e+09  \n",
              "2010-01-06  4.972660e+09  \n",
              "2010-01-07  5.270680e+09  \n",
              "2010-01-08  4.389590e+09  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e997a541-bef7-4e07-9348-8bf6b1446111\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>7184.979980</td>\n",
              "      <td>7331.120117</td>\n",
              "      <td>7184.979980</td>\n",
              "      <td>7326.740234</td>\n",
              "      <td>7326.740234</td>\n",
              "      <td>3.991400e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>7326.740234</td>\n",
              "      <td>7359.459961</td>\n",
              "      <td>7313.600098</td>\n",
              "      <td>7354.870117</td>\n",
              "      <td>7354.870117</td>\n",
              "      <td>2.491020e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>7354.850098</td>\n",
              "      <td>7389.279785</td>\n",
              "      <td>7342.490234</td>\n",
              "      <td>7377.700195</td>\n",
              "      <td>7377.700195</td>\n",
              "      <td>4.972660e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>7377.700195</td>\n",
              "      <td>7398.209961</td>\n",
              "      <td>7325.509766</td>\n",
              "      <td>7393.930176</td>\n",
              "      <td>7393.930176</td>\n",
              "      <td>5.270680e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>7393.930176</td>\n",
              "      <td>7426.410156</td>\n",
              "      <td>7367.810059</td>\n",
              "      <td>7425.350098</td>\n",
              "      <td>7425.350098</td>\n",
              "      <td>4.389590e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e997a541-bef7-4e07-9348-8bf6b1446111')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e997a541-bef7-4e07-9348-8bf6b1446111 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e997a541-bef7-4e07-9348-8bf6b1446111');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a4e33b73-db2d-4459-91b2-b6c3147b6122\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a4e33b73-db2d-4459-91b2-b6c3147b6122')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a4e33b73-db2d-4459-91b2-b6c3147b6122 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"     print(\\\"-\\\" * 30)\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2010-01-04 00:00:00\",\n        \"max\": \"2010-01-08 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2010-01-05 00:00:00\",\n          \"2010-01-08 00:00:00\",\n          \"2010-01-06 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 83.65627699856185,\n        \"min\": 7184.97998046875,\n        \"max\": 7393.93017578125,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7326.740234375,\n          7393.93017578125,\n          7354.85009765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.66995294683895,\n        \"min\": 7331.1201171875,\n        \"max\": 7426.41015625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7359.4599609375,\n          7426.41015625,\n          7389.27978515625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 71.12032665577134,\n        \"min\": 7184.97998046875,\n        \"max\": 7367.81005859375,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7313.60009765625,\n          7367.81005859375,\n          7342.490234375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.52470288340124,\n        \"min\": 7326.740234375,\n        \"max\": 7425.35009765625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7354.8701171875,\n          7425.35009765625,\n          7377.7001953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.52470288340124,\n        \"min\": 7326.740234375,\n        \"max\": 7425.35009765625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7354.8701171875,\n          7425.35009765625,\n          7377.7001953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1088665350.5554404,\n        \"min\": 2491020000.0,\n        \"max\": 5270680000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2491020000.0,\n          4389590000.0,\n          4972660000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 3535 entries, 2010-01-04 to 2023-07-28\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Open       3535 non-null   float64\n",
            " 1   High       3535 non-null   float64\n",
            " 2   Low        3535 non-null   float64\n",
            " 3   Close      3535 non-null   float64\n",
            " 4   Adj Close  3535 non-null   float64\n",
            " 5   Volume     3535 non-null   float64\n",
            "dtypes: float64(6)\n",
            "memory usage: 193.3 KB\n",
            "------------------------------\n",
            "\n",
            "DataFrame: financial_macro_combined\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   Open         High          Low        Close    Adj Close  \\\n",
              "Date                                                                          \n",
              "2010-01-04  7184.979980  7331.120117  7184.979980  7326.740234  7326.740234   \n",
              "2010-01-05  7326.740234  7359.459961  7313.600098  7354.870117  7354.870117   \n",
              "2010-01-06  7354.850098  7389.279785  7342.490234  7377.700195  7377.700195   \n",
              "2010-01-07  7377.700195  7398.209961  7325.509766  7393.930176  7393.930176   \n",
              "2010-01-08  7393.930176  7426.410156  7367.810059  7425.350098  7425.350098   \n",
              "\n",
              "                  Volume   DFF  \n",
              "Date                            \n",
              "2010-01-04  3.991400e+09  0.12  \n",
              "2010-01-05  2.491020e+09  0.12  \n",
              "2010-01-06  4.972660e+09  0.12  \n",
              "2010-01-07  5.270680e+09  0.10  \n",
              "2010-01-08  4.389590e+09  0.11  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ffe022c-d8d5-4563-b080-412a259d3aa1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>DFF</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>7184.979980</td>\n",
              "      <td>7331.120117</td>\n",
              "      <td>7184.979980</td>\n",
              "      <td>7326.740234</td>\n",
              "      <td>7326.740234</td>\n",
              "      <td>3.991400e+09</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>7326.740234</td>\n",
              "      <td>7359.459961</td>\n",
              "      <td>7313.600098</td>\n",
              "      <td>7354.870117</td>\n",
              "      <td>7354.870117</td>\n",
              "      <td>2.491020e+09</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>7354.850098</td>\n",
              "      <td>7389.279785</td>\n",
              "      <td>7342.490234</td>\n",
              "      <td>7377.700195</td>\n",
              "      <td>7377.700195</td>\n",
              "      <td>4.972660e+09</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>7377.700195</td>\n",
              "      <td>7398.209961</td>\n",
              "      <td>7325.509766</td>\n",
              "      <td>7393.930176</td>\n",
              "      <td>7393.930176</td>\n",
              "      <td>5.270680e+09</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>7393.930176</td>\n",
              "      <td>7426.410156</td>\n",
              "      <td>7367.810059</td>\n",
              "      <td>7425.350098</td>\n",
              "      <td>7425.350098</td>\n",
              "      <td>4.389590e+09</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ffe022c-d8d5-4563-b080-412a259d3aa1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ffe022c-d8d5-4563-b080-412a259d3aa1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ffe022c-d8d5-4563-b080-412a259d3aa1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-04c15c7b-c896-40eb-bd1e-1272575a1993\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-04c15c7b-c896-40eb-bd1e-1272575a1993')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-04c15c7b-c896-40eb-bd1e-1272575a1993 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"     print(\\\"-\\\" * 30)\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2010-01-04 00:00:00\",\n        \"max\": \"2010-01-08 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2010-01-05 00:00:00\",\n          \"2010-01-08 00:00:00\",\n          \"2010-01-06 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 83.65627699856185,\n        \"min\": 7184.97998046875,\n        \"max\": 7393.93017578125,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7326.740234375,\n          7393.93017578125,\n          7354.85009765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.66995294683895,\n        \"min\": 7331.1201171875,\n        \"max\": 7426.41015625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7359.4599609375,\n          7426.41015625,\n          7389.27978515625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 71.12032665577134,\n        \"min\": 7184.97998046875,\n        \"max\": 7367.81005859375,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7313.60009765625,\n          7367.81005859375,\n          7342.490234375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.52470288340124,\n        \"min\": 7326.740234375,\n        \"max\": 7425.35009765625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7354.8701171875,\n          7425.35009765625,\n          7377.7001953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.52470288340124,\n        \"min\": 7326.740234375,\n        \"max\": 7425.35009765625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7354.8701171875,\n          7425.35009765625,\n          7377.7001953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1088665350.5554404,\n        \"min\": 2491020000.0,\n        \"max\": 5270680000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2491020000.0,\n          4389590000.0,\n          4972660000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DFF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008944271909999154,\n        \"min\": 0.1,\n        \"max\": 0.12,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.12,\n          0.1,\n          0.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 3535 entries, 2010-01-04 to 2023-07-28\n",
            "Data columns (total 7 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Open       3535 non-null   float64\n",
            " 1   High       3535 non-null   float64\n",
            " 2   Low        3535 non-null   float64\n",
            " 3   Close      3535 non-null   float64\n",
            " 4   Adj Close  3535 non-null   float64\n",
            " 5   Volume     3535 non-null   float64\n",
            " 6   DFF        3535 non-null   float64\n",
            "dtypes: float64(7)\n",
            "memory usage: 220.9 KB\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "cd7b4768",
        "outputId": "b9d6a3ec-5f45-4080-8def-58aca0a046fe"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Access the processed dataframes from loaded_dataframes\n",
        "# Assuming 'financial_macro_combined' and 'news_articles_processed' are available\n",
        "df_financial_macro_combined = loaded_dataframes.get('financial_macro_combined')\n",
        "df_news_processed = loaded_dataframes.get('news_articles_processed')\n",
        "\n",
        "# Check if required dataframes are loaded and processed\n",
        "# Financial and News are critical for the combined data\n",
        "if df_financial_macro_combined is None or df_financial_macro_combined.empty:\n",
        "    print(\"Error: 'financial_macro_combined' dataframe not found or is empty. Cannot proceed with integration.\")\n",
        "    integration_successful = False\n",
        "elif df_news_processed is None or df_news_processed.empty:\n",
        "    print(\"Warning: 'news_articles_processed' dataframe not found or is empty. Proceeding with financial and macro data only.\")\n",
        "    integration_successful = True # Proceed with only financial and macro data\n",
        "    df_news_aligned = pd.DataFrame(index=df_financial_macro_combined.index) # Create an empty news dataframe aligned to financial dates\n",
        "else:\n",
        "    integration_successful = True\n",
        "    print(\"Required dataframes for integration found.\")\n",
        "\n",
        "\n",
        "if integration_successful:\n",
        "    print(\"\\n--- Integrating Dataframes ---\")\n",
        "\n",
        "    # Ensure all dataframes have a DatetimeIndex and are sorted by Date\n",
        "    # This should have been handled in the preprocessing step, but double-check\n",
        "    dataframes_to_check_index = {\n",
        "        'financial_macro_combined': df_financial_macro_combined,\n",
        "        'news_articles_processed': df_news_processed # Check news if it exists\n",
        "    }\n",
        "\n",
        "    for df_name, df in dataframes_to_check_index.items():\n",
        "        if df is not None and not df.empty:\n",
        "            if not isinstance(df.index, pd.DatetimeIndex):\n",
        "                print(f\"Warning: DataFrame '{df_name}' does not have a DatetimeIndex. Attempting to convert.\")\n",
        "                try:\n",
        "                    # Convert index to datetime, coercing errors\n",
        "                    df.index = pd.to_datetime(df.index, errors='coerce')\n",
        "                    # Drop rows where index conversion failed\n",
        "                    df.dropna(subset=[df.index.name], inplace=True)\n",
        "                    df.index.name = 'Date'\n",
        "                    df.sort_index(inplace=True)\n",
        "                    print(f\"  - Converted index of '{df_name}' to DatetimeIndex and sorted.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  - Error converting index of '{df_name}' to DatetimeIndex: {e}. Cannot proceed with integration for this dataframe.\")\n",
        "                    # Set the dataframe to None to exclude it from merging\n",
        "                    if df_name == 'financial_macro_combined':\n",
        "                         df_financial_macro_combined = None\n",
        "                         integration_successful = False # Critical data missing\n",
        "                    elif df_name == 'news_articles_processed':\n",
        "                         df_news_processed = None # Non-critical, proceed without news\n",
        "                         df_news_aligned = pd.DataFrame(index=df_financial_macro_combined.index) # Create an empty news dataframe aligned to financial dates\n",
        "\n",
        "            else:\n",
        "                 df.index.name = 'Date' # Ensure index name is 'Date'\n",
        "                 df.sort_index(inplace=True) # Ensure sorted\n",
        "\n",
        "\n",
        "    if integration_successful and df_financial_macro_combined is not None and not df_financial_macro_combined.empty:\n",
        "        # Create a full date range covering all available dataframes\n",
        "        all_dates = df_financial_macro_combined.index\n",
        "        if df_news_processed is not None and not df_news_processed.empty:\n",
        "            all_dates = all_dates.union(df_news_processed.index)\n",
        "\n",
        "\n",
        "        # Create a daily date range based on the min and max dates\n",
        "        full_daily_date_range = pd.date_range(start=all_dates.min(), end=all_dates.max(), freq='D')\n",
        "        print(f\"\\nCreated a full daily date range from {full_daily_date_range.min().strftime('%Y-%m-%d')} to {full_daily_date_range.max().strftime('%Y-%m-%d')}.\")\n",
        "\n",
        "\n",
        "        # Align dataframes to the full daily date range using reindex and forward-fill/fillna\n",
        "        # Financial data usually has gaps (weekends, holidays), so reindex and fillna\n",
        "        # News data might have multiple articles per day or gaps, need to aggregate by day and then reindex/fillna\n",
        "\n",
        "        # 1. Align Financial and Macro Data\n",
        "        # Reindex to the full daily date range\n",
        "        df_financial_macro_aligned = df_financial_macro_combined.reindex(full_daily_date_range)\n",
        "        # Fill missing financial/macro data (e.g., weekends) using forward-fill\n",
        "        df_financial_macro_aligned.fillna(method='ffill', inplace=True)\n",
        "        # Fill any remaining NaNs at the very beginning (if ffill couldn't fill) with backward-fill\n",
        "        df_financial_macro_aligned.fillna(method='bfill', inplace=True)\n",
        "        print(\"Financial and Macro data aligned and missing dates filled.\")\n",
        "\n",
        "\n",
        "        # 2. Align News Data (Requires daily aggregation of embeddings)\n",
        "        if df_news_processed is not None and not df_news_processed.empty and 'Text_Embeddings' in df_news_processed.columns:\n",
        "             print(\"Aggregating news embeddings by day...\")\n",
        "             # Group news articles by date and average their embeddings\n",
        "             # Need to handle potential errors if 'Text_Embeddings' column contains non-list/non-array items\n",
        "             try:\n",
        "                 # Ensure embeddings are numpy arrays before averaging\n",
        "                 df_news_processed['Text_Embeddings_Array'] = df_news_processed['Text_Embeddings'].apply(lambda x: np.array(x) if isinstance(x, (list, np.ndarray)) else np.nan)\n",
        "                 # Drop rows where embedding conversion failed\n",
        "                 df_news_processed.dropna(subset=['Text_Embeddings_Array'], inplace=True)\n",
        "\n",
        "                 # Group by date (index) and average the embedding arrays\n",
        "                 # Need to handle cases where a date might have no articles after dropping NaNs\n",
        "                 if not df_news_processed.empty:\n",
        "                     # Use a lambda function to average numpy arrays in a Series\n",
        "                     df_news_daily_avg_embedding = df_news_processed.groupby(df_news_processed.index)['Text_Embeddings_Array'].apply(lambda x: np.mean(np.stack(x.values), axis=0) if x.values.size > 0 else np.zeros(x.iloc[0].shape)) # Handle empty groups\n",
        "                     # Convert the resulting Series of arrays back to a DataFrame\n",
        "                     df_news_aligned = pd.DataFrame(df_news_daily_avg_embedding.tolist(), index=df_news_daily_avg_embedding.index)\n",
        "                     df_news_aligned.index.name = 'Date' # Ensure index name is Date\n",
        "\n",
        "                     # Reindex to the full daily date range and fill missing dates with zeros\n",
        "                     # Fill missing news embeddings with zeros (or another appropriate value)\n",
        "                     # Get the embedding dimension from the first valid embedding, default to a size if none\n",
        "                     if not df_news_aligned.empty:\n",
        "                         embedding_dim_news = df_news_aligned.shape[1]\n",
        "                         df_news_aligned = df_news_aligned.reindex(full_daily_date_range).fillna(0) # Fill missing days with zero vector embeddings of correct dimension\n",
        "                     else:\n",
        "                         # If df_news_aligned is empty after aggregation, create an empty aligned dataframe\n",
        "                         print(\"No news embeddings available after aggregation. Creating empty aligned news DataFrame.\")\n",
        "                         df_news_aligned = pd.DataFrame(index=full_daily_date_range)\n",
        "\n",
        "                     print(\"News embeddings aggregated by day, aligned, and missing dates filled with zeros.\")\n",
        "                 else:\n",
        "                     print(\"No news articles with valid embeddings found after cleaning. Creating empty aligned news DataFrame.\")\n",
        "                     df_news_aligned = pd.DataFrame(index=full_daily_date_range) # Empty if no news data with embeddings\n",
        "             except Exception as e:\n",
        "                 print(f\"Error during news embedding aggregation or alignment: {e}. Creating empty aligned news DataFrame.\")\n",
        "                 df_news_aligned = pd.DataFrame(index=full_daily_date_range) # Empty if error\n",
        "        else:\n",
        "            print(\"News articles dataframe not found or processed, or 'Text_Embeddings' column missing. Creating empty aligned news DataFrame.\")\n",
        "            df_news_aligned = pd.DataFrame(index=full_daily_date_range) # Empty if news data missing or embeddings not processed\n",
        "\n",
        "\n",
        "        # 3. Merge all aligned dataframes into a single combined dataframe\n",
        "        # Start with financial and macro data as the base, then merge news\n",
        "        df_combined = df_financial_macro_aligned.copy()\n",
        "\n",
        "        if not df_news_aligned.empty:\n",
        "             # Merge News embeddings\n",
        "             # Ensure news aligned columns do not clash with existing columns (e.g., if KPI or Financial had numeric columns named 0, 1, etc.)\n",
        "             # Rename news embedding columns to be distinct, e.g., 'news_emb_0', 'news_emb_1', ...\n",
        "             news_col_map = {i: f'news_emb_{i}' for i in range(df_news_aligned.shape[1])}\n",
        "             df_news_aligned_renamed = df_news_aligned.rename(columns=news_col_map)\n",
        "\n",
        "             df_combined = df_combined.merge(df_news_aligned_renamed, left_index=True, right_index=True, how='left')\n",
        "             print(\"News embeddings merged.\")\n",
        "        else:\n",
        "             print(\"News aligned dataframe is empty or missing. Skipping News embedding merge.\")\n",
        "\n",
        "\n",
        "        # Display the head and info of the final combined DataFrame\n",
        "        print(\"\\n--- Final Combined DataFrame ---\")\n",
        "        print(\"Head of the combined DataFrame:\")\n",
        "        display(df_combined.head())\n",
        "        print(\"\\nInfo of the combined DataFrame:\")\n",
        "        df_combined.info()\n",
        "        print(\"\\nMissing values in the combined DataFrame after filling:\")\n",
        "        print(df_combined.isnull().sum()) # Should ideally be all zeros after filling\n",
        "\n",
        "\n",
        "        # Store the final combined DataFrame in loaded_dataframes\n",
        "        loaded_dataframes['combined_data'] = df_combined\n",
        "        print(\"\\nFinal combined dataframe stored in loaded_dataframes['combined_data'].\")\n",
        "    else:\n",
        "        print(\"\\nIntegration failed due to missing critical dataframes.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nIntegration skipped because financial_macro_combined dataframe is empty or missing.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: 'news_articles_processed' dataframe not found or is empty. Proceeding with financial and macro data only.\n",
            "\n",
            "--- Integrating Dataframes ---\n",
            "\n",
            "Created a full daily date range from 2010-01-04 to 2023-07-28.\n",
            "Financial and Macro data aligned and missing dates filled.\n",
            "News articles dataframe not found or processed, or 'Text_Embeddings' column missing. Creating empty aligned news DataFrame.\n",
            "News aligned dataframe is empty or missing. Skipping News embedding merge.\n",
            "\n",
            "--- Final Combined DataFrame ---\n",
            "Head of the combined DataFrame:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-7-1642938988.py:80: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_financial_macro_aligned.fillna(method='ffill', inplace=True)\n",
            "/tmp/ipython-input-7-1642938988.py:82: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_financial_macro_aligned.fillna(method='bfill', inplace=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   Open         High          Low        Close    Adj Close  \\\n",
              "2010-01-04  7184.979980  7331.120117  7184.979980  7326.740234  7326.740234   \n",
              "2010-01-05  7326.740234  7359.459961  7313.600098  7354.870117  7354.870117   \n",
              "2010-01-06  7354.850098  7389.279785  7342.490234  7377.700195  7377.700195   \n",
              "2010-01-07  7377.700195  7398.209961  7325.509766  7393.930176  7393.930176   \n",
              "2010-01-08  7393.930176  7426.410156  7367.810059  7425.350098  7425.350098   \n",
              "\n",
              "                  Volume   DFF  \n",
              "2010-01-04  3.991400e+09  0.12  \n",
              "2010-01-05  2.491020e+09  0.12  \n",
              "2010-01-06  4.972660e+09  0.12  \n",
              "2010-01-07  5.270680e+09  0.10  \n",
              "2010-01-08  4.389590e+09  0.11  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec5a4797-8856-4ede-b683-21172d848b3a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>DFF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>7184.979980</td>\n",
              "      <td>7331.120117</td>\n",
              "      <td>7184.979980</td>\n",
              "      <td>7326.740234</td>\n",
              "      <td>7326.740234</td>\n",
              "      <td>3.991400e+09</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>7326.740234</td>\n",
              "      <td>7359.459961</td>\n",
              "      <td>7313.600098</td>\n",
              "      <td>7354.870117</td>\n",
              "      <td>7354.870117</td>\n",
              "      <td>2.491020e+09</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>7354.850098</td>\n",
              "      <td>7389.279785</td>\n",
              "      <td>7342.490234</td>\n",
              "      <td>7377.700195</td>\n",
              "      <td>7377.700195</td>\n",
              "      <td>4.972660e+09</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>7377.700195</td>\n",
              "      <td>7398.209961</td>\n",
              "      <td>7325.509766</td>\n",
              "      <td>7393.930176</td>\n",
              "      <td>7393.930176</td>\n",
              "      <td>5.270680e+09</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>7393.930176</td>\n",
              "      <td>7426.410156</td>\n",
              "      <td>7367.810059</td>\n",
              "      <td>7425.350098</td>\n",
              "      <td>7425.350098</td>\n",
              "      <td>4.389590e+09</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec5a4797-8856-4ede-b683-21172d848b3a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ec5a4797-8856-4ede-b683-21172d848b3a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ec5a4797-8856-4ede-b683-21172d848b3a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-45d8bd7b-6a12-4073-938d-09b6ae61e06d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-45d8bd7b-6a12-4073-938d-09b6ae61e06d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-45d8bd7b-6a12-4073-938d-09b6ae61e06d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"\\\\nIntegration skipped because financial_macro_combined dataframe is empty or missing\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 83.65627699856185,\n        \"min\": 7184.97998046875,\n        \"max\": 7393.93017578125,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7326.740234375,\n          7393.93017578125,\n          7354.85009765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.66995294683895,\n        \"min\": 7331.1201171875,\n        \"max\": 7426.41015625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7359.4599609375,\n          7426.41015625,\n          7389.27978515625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 71.12032665577134,\n        \"min\": 7184.97998046875,\n        \"max\": 7367.81005859375,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7313.60009765625,\n          7367.81005859375,\n          7342.490234375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.52470288340124,\n        \"min\": 7326.740234375,\n        \"max\": 7425.35009765625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7354.8701171875,\n          7425.35009765625,\n          7377.7001953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37.52470288340124,\n        \"min\": 7326.740234375,\n        \"max\": 7425.35009765625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7354.8701171875,\n          7425.35009765625,\n          7377.7001953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1088665350.5554404,\n        \"min\": 2491020000.0,\n        \"max\": 5270680000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2491020000.0,\n          4389590000.0,\n          4972660000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DFF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008944271909999154,\n        \"min\": 0.1,\n        \"max\": 0.12,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.12,\n          0.1,\n          0.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Info of the combined DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 4954 entries, 2010-01-04 to 2023-07-28\n",
            "Freq: D\n",
            "Data columns (total 7 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Open       4954 non-null   float64\n",
            " 1   High       4954 non-null   float64\n",
            " 2   Low        4954 non-null   float64\n",
            " 3   Close      4954 non-null   float64\n",
            " 4   Adj Close  4954 non-null   float64\n",
            " 5   Volume     4954 non-null   float64\n",
            " 6   DFF        4954 non-null   float64\n",
            "dtypes: float64(7)\n",
            "memory usage: 309.6 KB\n",
            "\n",
            "Missing values in the combined DataFrame after filling:\n",
            "Open         0\n",
            "High         0\n",
            "Low          0\n",
            "Close        0\n",
            "Adj Close    0\n",
            "Volume       0\n",
            "DFF          0\n",
            "dtype: int64\n",
            "\n",
            "Final combined dataframe stored in loaded_dataframes['combined_data'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ec3fd67e",
        "outputId": "47265579-7a8c-46bb-ada5-530a6ae2fda8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ensure the combined data is available\n",
        "if 'combined_data' in loaded_dataframes and not loaded_dataframes['combined_data'].empty:\n",
        "    df_combined = loaded_dataframes['combined_data'].copy()\n",
        "    print(\"Accessing combined data for feature engineering.\")\n",
        "else:\n",
        "    print(\"Error: 'combined_data' dataframe not found or is empty. Cannot proceed with feature engineering.\")\n",
        "    # Exit the cell if required data is missing\n",
        "    df_combined_features = pd.DataFrame() # Set to empty to prevent errors\n",
        "\n",
        "\n",
        "if not df_combined.empty:\n",
        "    print(\"\\n--- Calculating Technical and Volatility Features ---\")\n",
        "\n",
        "    # Ensure the index is a DatetimeIndex and is sorted\n",
        "    if not isinstance(df_combined.index, pd.DatetimeIndex):\n",
        "        print(\"Warning: Index is not a DatetimeIndex. Attempting conversion.\")\n",
        "        df_combined.index = pd.to_datetime(df_combined.index, errors='coerce')\n",
        "        df_combined.dropna(subset=[df_combined.index.name], inplace=True)\n",
        "        df_combined.sort_index(inplace=True)\n",
        "        df_combined.index.name = 'Date'\n",
        "        print(\"Index converted and sorted.\")\n",
        "    else:\n",
        "        df_combined.sort_index(inplace=True) # Ensure sorted\n",
        "\n",
        "    df_combined_features = df_combined.copy() # Start with a copy of the combined data\n",
        "\n",
        "    # Ensure 'Close' and 'Volume' columns are available for feature calculation\n",
        "    if 'Close' not in df_combined_features.columns:\n",
        "        print(\"Error: 'Close' column not found in the combined data. Cannot calculate most technical features.\")\n",
        "    if 'Volume' not in df_combined_features.columns:\n",
        "        print(\"Warning: 'Volume' column not found in the combined data. Cannot calculate Volume-based features like ATR if needed.\")\n",
        "\n",
        "    # Calculate Technical Features (if 'Close' is available)\n",
        "    if 'Close' in df_combined_features.columns:\n",
        "        print(\"\\nCalculating Moving Averages (SMA/EMA):\")\n",
        "        # Moving Averages: 5-day, 10-day, 20-day SMA/EMA\n",
        "        for window in [5, 10, 20]:\n",
        "            if len(df_combined_features) >= window: # Ensure enough data for the window size\n",
        "                df_combined_features[f'SMA_{window}'] = df_combined_features['Close'].rolling(window=window).mean()\n",
        "                df_combined_features[f'EMA_{window}'] = df_combined_features['Close'].ewm(span=window, adjust=False).mean()\n",
        "                print(f\"  - Calculated {window}-day SMA and EMA.\")\n",
        "            else:\n",
        "                print(f\"  - Not enough data ({len(df_combined_features)} days) to calculate {window}-day moving averages. Skipping.\")\n",
        "\n",
        "\n",
        "        print(\"\\nCalculating RSI (14-period):\")\n",
        "        # RSI: 14-period\n",
        "        if len(df_combined_features) >= 14:\n",
        "            # Calculate price changes\n",
        "            delta = df_combined_features['Close'].diff()\n",
        "            # Get gains and losses\n",
        "            gain = delta.where(delta > 0, 0)\n",
        "            loss = -delta.where(delta < 0, 0)\n",
        "            # Calculate Exponential Moving Average of gains and losses\n",
        "            avg_gain = gain.ewm(span=14, adjust=False).mean()\n",
        "            avg_loss = loss.ewm(span=14, adjust=False).mean()\n",
        "            # Calculate Relative Strength (RS)\n",
        "            rs = avg_gain / avg_loss\n",
        "            # Calculate Relative Strength Index (RSI)\n",
        "            df_combined_features['RSI_14'] = 100 - (100 / (1 + rs))\n",
        "            print(\"  - Calculated 14-period RSI.\")\n",
        "        else:\n",
        "            print(\"  - Not enough data to calculate 14-period RSI. Skipping.\")\n",
        "\n",
        "\n",
        "        print(\"\\nCalculating MACD (12, 26, 9):\")\n",
        "        # MACD: (12, 26, 9)\n",
        "        if len(df_combined_features) >= 26: # Need at least 26 periods for the longer EMA\n",
        "            exp1 = df_combined_features['Close'].ewm(span=12, adjust=False).mean()\n",
        "            exp2 = df_combined_features['Close'].ewm(span=26, adjust=False).mean()\n",
        "            df_combined_features['MACD'] = exp1 - exp2\n",
        "            df_combined_features['Signal_Line'] = df_combined_features['MACD'].ewm(span=9, adjust=False).mean()\n",
        "            df_combined_features['MACD_Histogram'] = df_combined_features['MACD'] - df_combined_features['Signal_Line']\n",
        "            print(\"  - Calculated MACD, Signal Line, and MACD Histogram.\")\n",
        "        else:\n",
        "            print(\"  - Not enough data to calculate MACD (need at least 26 periods). Skipping.\")\n",
        "\n",
        "\n",
        "        print(\"\\nCalculating Bollinger Bands (±2σ around 20-day SMA):\")\n",
        "        # Bollinger Bands: ±2σ around 20-day SMA\n",
        "        window_bb = 20\n",
        "        if len(df_combined_features) >= window_bb:\n",
        "            rolling_mean_bb = df_combined_features['Close'].rolling(window=window_bb).mean()\n",
        "            rolling_std_bb = df_combined_features['Close'].rolling(window=window_bb).std()\n",
        "            df_combined_features['Bollinger_Upper'] = rolling_mean_bb + (rolling_std_bb * 2)\n",
        "            df_combined_features['Bollinger_Lower'] = rolling_mean_bb - (rolling_std_bb * 2)\n",
        "            print(f\"  - Calculated Bollinger Bands ({window_bb}-day SMA, ±2σ).\")\n",
        "        else:\n",
        "             print(f\"  - Not enough data ({len(df_combined_features)} days) to calculate Bollinger Bands. Skipping.\")\n",
        "\n",
        "\n",
        "        print(\"\\nCalculating Rolling Volatility (standard deviation of log-returns over window):\")\n",
        "        # Rolling Volatility: standard deviation of log-returns over window (e.g., 20-day window)\n",
        "        window_vol = 20\n",
        "        if len(df_combined_features) >= window_vol:\n",
        "            df_combined_features['Log_Return'] = np.log(df_combined_features['Close'] / df_combined_features['Close'].shift(1))\n",
        "            df_combined_features['Rolling_Volatility'] = df_combined_features['Log_Return'].rolling(window=window_vol).std()\n",
        "            print(f\"  - Calculated Rolling Volatility ({window_vol}-day standard deviation of log returns).\")\n",
        "        else:\n",
        "             print(f\"  - Not enough data ({len(df_combined_features)} days) to calculate Rolling Volatility. Skipping.\")\n",
        "\n",
        "\n",
        "    # Calculate ATR (Average True Range over window) (requires High, Low, Close)\n",
        "    if 'High' in df_combined_features.columns and 'Low' in df_combined_features.columns and 'Close' in df_combined_features.columns:\n",
        "        print(\"\\nCalculating ATR (Average True Range):\")\n",
        "        window_atr = 14 # Common ATR window\n",
        "        if len(df_combined_features) >= window_atr:\n",
        "            # Calculate True Range\n",
        "            high_low = df_combined_features['High'] - df_combined_features['Low']\n",
        "            high_close_prev = np.abs(df_combined_features['High'] - df_combined_features['Close'].shift(1))\n",
        "            low_close_prev = np.abs(df_combined_features['Low'] - df_combined_features['Close'].shift(1))\n",
        "            true_range = pd.concat([high_low, high_close_prev, low_close_prev], axis=1).max(axis=1)\n",
        "\n",
        "            # Calculate ATR (using Exponential Moving Average of True Range)\n",
        "            df_combined_features['ATR'] = true_range.ewm(span=window_atr, adjust=False).mean()\n",
        "            print(f\"  - Calculated ATR ({window_atr}-period).\")\n",
        "        else:\n",
        "            print(f\"  - Not enough data ({len(df_combined_features)} days) to calculate ATR. Skipping.\")\n",
        "    else:\n",
        "        print(\"\\nWarning: Required columns (High, Low, Close) not found for ATR calculation. Skipping ATR.\")\n",
        "\n",
        "\n",
        "    # Drop rows with NaN values that resulted from rolling calculations (usually at the beginning)\n",
        "    initial_rows = len(df_combined_features)\n",
        "    df_combined_features.dropna(inplace=True)\n",
        "    if len(df_combined_features) < initial_rows:\n",
        "        print(f\"\\nDropped {initial_rows - len(df_combined_features)} rows with NaN values introduced by feature calculation.\")\n",
        "\n",
        "\n",
        "    print(\"\\nFeature engineering complete.\")\n",
        "    print(\"Head of the DataFrame with new features:\")\n",
        "    display(df_combined_features.head())\n",
        "    print(\"\\nInfo of the DataFrame with new features:\")\n",
        "    df_combined_features.info()\n",
        "\n",
        "    # Store the DataFrame with new features\n",
        "    loaded_dataframes['combined_data_features'] = df_combined_features\n",
        "    print(\"\\nDataFrame with technical and volatility features stored in loaded_dataframes['combined_data_features'].\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nCombined dataframe is empty. Skipping feature engineering.\")\n",
        "    loaded_dataframes['combined_data_features'] = pd.DataFrame() # Ensure the output df is empty if input was empty"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accessing combined data for feature engineering.\n",
            "\n",
            "--- Calculating Technical and Volatility Features ---\n",
            "\n",
            "Calculating Moving Averages (SMA/EMA):\n",
            "  - Calculated 5-day SMA and EMA.\n",
            "  - Calculated 10-day SMA and EMA.\n",
            "  - Calculated 20-day SMA and EMA.\n",
            "\n",
            "Calculating RSI (14-period):\n",
            "  - Calculated 14-period RSI.\n",
            "\n",
            "Calculating MACD (12, 26, 9):\n",
            "  - Calculated MACD, Signal Line, and MACD Histogram.\n",
            "\n",
            "Calculating Bollinger Bands (±2σ around 20-day SMA):\n",
            "  - Calculated Bollinger Bands (20-day SMA, ±2σ).\n",
            "\n",
            "Calculating Rolling Volatility (standard deviation of log-returns over window):\n",
            "  - Calculated Rolling Volatility (20-day standard deviation of log returns).\n",
            "\n",
            "Calculating ATR (Average True Range):\n",
            "  - Calculated ATR (14-period).\n",
            "\n",
            "Dropped 20 rows with NaN values introduced by feature calculation.\n",
            "\n",
            "Feature engineering complete.\n",
            "Head of the DataFrame with new features:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   Open         High          Low        Close    Adj Close  \\\n",
              "2010-01-24  7174.459961  7174.459961  7021.029785  7030.609863  7030.609863   \n",
              "2010-01-25  7030.609863  7118.220215  7030.609863  7073.129883  7073.129883   \n",
              "2010-01-26  7073.140137  7098.770020  7008.979980  7028.319824  7028.319824   \n",
              "2010-01-27  7028.419922  7044.520020  6944.080078  7035.609863  7035.609863   \n",
              "2010-01-28  7035.620117  7061.609863  6913.299805  6956.990234  6956.990234   \n",
              "\n",
              "                  Volume   DFF        SMA_5        EMA_5       SMA_10  ...  \\\n",
              "2010-01-24  5.789682e+09  0.11  7119.223926  7057.965474  7060.456982  ...   \n",
              "2010-01-25  4.481390e+09  0.12  7067.883887  7063.020277  7032.090967  ...   \n",
              "2010-01-26  4.731910e+09  0.12  7038.655859  7051.453459  6999.243945  ...   \n",
              "2010-01-27  5.319120e+09  0.12  7039.655859  7046.172261  6967.125928  ...   \n",
              "2010-01-28  5.452400e+09  0.12  7024.931934  7016.444919  7113.384961  ...   \n",
              "\n",
              "                 EMA_20     RSI_14       MACD  Signal_Line  MACD_Histogram  \\\n",
              "2010-01-24  7174.915410  47.113720 -84.542257   -63.866465      -20.675792   \n",
              "2010-01-25  7165.221550  48.330264 -81.868172   -67.466806      -14.401366   \n",
              "2010-01-26  7152.183290  47.015182 -82.414712   -70.456387      -11.958325   \n",
              "2010-01-27  7141.081059  47.284444 -81.322172   -72.629544       -8.692628   \n",
              "2010-01-28  7123.548600  44.472152 -85.811097   -75.265855      -10.545242   \n",
              "\n",
              "            Bollinger_Upper  Bollinger_Lower  Log_Return  Rolling_Volatility  \\\n",
              "2010-01-24      8102.472749      6368.055327    0.000000            0.097011   \n",
              "2010-01-25      8089.357822      6352.996231    0.006030            0.097020   \n",
              "2010-01-26      8072.687574      6334.728442   -0.006355            0.097017   \n",
              "2010-01-27      8053.031885      6318.552099    0.001037            0.097014   \n",
              "2010-01-28      8027.668961      6297.079037   -0.011237            0.097020   \n",
              "\n",
              "                   ATR  \n",
              "2010-01-24  352.710840  \n",
              "2010-01-25  317.364108  \n",
              "2010-01-26  287.020899  \n",
              "2010-01-27  262.143438  \n",
              "2010-01-28  246.965654  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-428b22ce-0e16-426c-9ba7-e9b8e66eb7e9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>DFF</th>\n",
              "      <th>SMA_5</th>\n",
              "      <th>EMA_5</th>\n",
              "      <th>SMA_10</th>\n",
              "      <th>...</th>\n",
              "      <th>EMA_20</th>\n",
              "      <th>RSI_14</th>\n",
              "      <th>MACD</th>\n",
              "      <th>Signal_Line</th>\n",
              "      <th>MACD_Histogram</th>\n",
              "      <th>Bollinger_Upper</th>\n",
              "      <th>Bollinger_Lower</th>\n",
              "      <th>Log_Return</th>\n",
              "      <th>Rolling_Volatility</th>\n",
              "      <th>ATR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-24</th>\n",
              "      <td>7174.459961</td>\n",
              "      <td>7174.459961</td>\n",
              "      <td>7021.029785</td>\n",
              "      <td>7030.609863</td>\n",
              "      <td>7030.609863</td>\n",
              "      <td>5.789682e+09</td>\n",
              "      <td>0.11</td>\n",
              "      <td>7119.223926</td>\n",
              "      <td>7057.965474</td>\n",
              "      <td>7060.456982</td>\n",
              "      <td>...</td>\n",
              "      <td>7174.915410</td>\n",
              "      <td>47.113720</td>\n",
              "      <td>-84.542257</td>\n",
              "      <td>-63.866465</td>\n",
              "      <td>-20.675792</td>\n",
              "      <td>8102.472749</td>\n",
              "      <td>6368.055327</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.097011</td>\n",
              "      <td>352.710840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-25</th>\n",
              "      <td>7030.609863</td>\n",
              "      <td>7118.220215</td>\n",
              "      <td>7030.609863</td>\n",
              "      <td>7073.129883</td>\n",
              "      <td>7073.129883</td>\n",
              "      <td>4.481390e+09</td>\n",
              "      <td>0.12</td>\n",
              "      <td>7067.883887</td>\n",
              "      <td>7063.020277</td>\n",
              "      <td>7032.090967</td>\n",
              "      <td>...</td>\n",
              "      <td>7165.221550</td>\n",
              "      <td>48.330264</td>\n",
              "      <td>-81.868172</td>\n",
              "      <td>-67.466806</td>\n",
              "      <td>-14.401366</td>\n",
              "      <td>8089.357822</td>\n",
              "      <td>6352.996231</td>\n",
              "      <td>0.006030</td>\n",
              "      <td>0.097020</td>\n",
              "      <td>317.364108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-26</th>\n",
              "      <td>7073.140137</td>\n",
              "      <td>7098.770020</td>\n",
              "      <td>7008.979980</td>\n",
              "      <td>7028.319824</td>\n",
              "      <td>7028.319824</td>\n",
              "      <td>4.731910e+09</td>\n",
              "      <td>0.12</td>\n",
              "      <td>7038.655859</td>\n",
              "      <td>7051.453459</td>\n",
              "      <td>6999.243945</td>\n",
              "      <td>...</td>\n",
              "      <td>7152.183290</td>\n",
              "      <td>47.015182</td>\n",
              "      <td>-82.414712</td>\n",
              "      <td>-70.456387</td>\n",
              "      <td>-11.958325</td>\n",
              "      <td>8072.687574</td>\n",
              "      <td>6334.728442</td>\n",
              "      <td>-0.006355</td>\n",
              "      <td>0.097017</td>\n",
              "      <td>287.020899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-27</th>\n",
              "      <td>7028.419922</td>\n",
              "      <td>7044.520020</td>\n",
              "      <td>6944.080078</td>\n",
              "      <td>7035.609863</td>\n",
              "      <td>7035.609863</td>\n",
              "      <td>5.319120e+09</td>\n",
              "      <td>0.12</td>\n",
              "      <td>7039.655859</td>\n",
              "      <td>7046.172261</td>\n",
              "      <td>6967.125928</td>\n",
              "      <td>...</td>\n",
              "      <td>7141.081059</td>\n",
              "      <td>47.284444</td>\n",
              "      <td>-81.322172</td>\n",
              "      <td>-72.629544</td>\n",
              "      <td>-8.692628</td>\n",
              "      <td>8053.031885</td>\n",
              "      <td>6318.552099</td>\n",
              "      <td>0.001037</td>\n",
              "      <td>0.097014</td>\n",
              "      <td>262.143438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-28</th>\n",
              "      <td>7035.620117</td>\n",
              "      <td>7061.609863</td>\n",
              "      <td>6913.299805</td>\n",
              "      <td>6956.990234</td>\n",
              "      <td>6956.990234</td>\n",
              "      <td>5.452400e+09</td>\n",
              "      <td>0.12</td>\n",
              "      <td>7024.931934</td>\n",
              "      <td>7016.444919</td>\n",
              "      <td>7113.384961</td>\n",
              "      <td>...</td>\n",
              "      <td>7123.548600</td>\n",
              "      <td>44.472152</td>\n",
              "      <td>-85.811097</td>\n",
              "      <td>-75.265855</td>\n",
              "      <td>-10.545242</td>\n",
              "      <td>8027.668961</td>\n",
              "      <td>6297.079037</td>\n",
              "      <td>-0.011237</td>\n",
              "      <td>0.097020</td>\n",
              "      <td>246.965654</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-428b22ce-0e16-426c-9ba7-e9b8e66eb7e9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-428b22ce-0e16-426c-9ba7-e9b8e66eb7e9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-428b22ce-0e16-426c-9ba7-e9b8e66eb7e9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6447f760-fcd8-4043-828f-17210bceca1d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6447f760-fcd8-4043-828f-17210bceca1d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6447f760-fcd8-4043-828f-17210bceca1d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Info of the DataFrame with new features:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 4934 entries, 2010-01-24 to 2023-07-28\n",
            "Freq: D\n",
            "Data columns (total 22 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   Open                4934 non-null   float64\n",
            " 1   High                4934 non-null   float64\n",
            " 2   Low                 4934 non-null   float64\n",
            " 3   Close               4934 non-null   float64\n",
            " 4   Adj Close           4934 non-null   float64\n",
            " 5   Volume              4934 non-null   float64\n",
            " 6   DFF                 4934 non-null   float64\n",
            " 7   SMA_5               4934 non-null   float64\n",
            " 8   EMA_5               4934 non-null   float64\n",
            " 9   SMA_10              4934 non-null   float64\n",
            " 10  EMA_10              4934 non-null   float64\n",
            " 11  SMA_20              4934 non-null   float64\n",
            " 12  EMA_20              4934 non-null   float64\n",
            " 13  RSI_14              4934 non-null   float64\n",
            " 14  MACD                4934 non-null   float64\n",
            " 15  Signal_Line         4934 non-null   float64\n",
            " 16  MACD_Histogram      4934 non-null   float64\n",
            " 17  Bollinger_Upper     4934 non-null   float64\n",
            " 18  Bollinger_Lower     4934 non-null   float64\n",
            " 19  Log_Return          4934 non-null   float64\n",
            " 20  Rolling_Volatility  4934 non-null   float64\n",
            " 21  ATR                 4934 non-null   float64\n",
            "dtypes: float64(22)\n",
            "memory usage: 886.6 KB\n",
            "\n",
            "DataFrame with technical and volatility features stored in loaded_dataframes['combined_data_features'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ensure the feature-engineered data is available\n",
        "if 'combined_data_features' in loaded_dataframes and not loaded_dataframes['combined_data_features'].empty:\n",
        "    df_combined_features = loaded_dataframes['combined_data_features'].copy()\n",
        "    print(\"Accessing feature-engineered data for multi-scale windowing and target creation.\")\n",
        "else:\n",
        "    print(\"Error: 'combined_data_features' dataframe not found or is empty. Cannot proceed with multi-scale data preparation.\")\n",
        "    # Exit the cell if required data is missing\n",
        "    df_combined_features = pd.DataFrame() # Set to empty to prevent errors\n",
        "\n",
        "\n",
        "# Define the function to create sliding windows and targets\n",
        "def create_sliding_windows_and_targets(dataframe, window_size, target_column='Close', step=1):\n",
        "    \"\"\"\n",
        "    Creates sliding windows (sequences) of features and corresponding log return targets.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): The input DataFrame with features and target_column.\n",
        "                                  Assumes a DatetimeIndex.\n",
        "        window_size (int): The number of time steps in each input window.\n",
        "        target_column (str): The name of the column used to calculate the log return target.\n",
        "                             Defaults to 'Close'.\n",
        "        step (int): The step size (stride) for the sliding window.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - X (np.ndarray): Array of shape (num_samples, window_size, num_features)\n",
        "                              representing the input windows.\n",
        "            - y (np.ndarray): Array of shape (num_samples,) representing the log return targets.\n",
        "            - dates (pd.DatetimeIndex): DatetimeIndex corresponding to the date of the target\n",
        "                                        for each sample.\n",
        "    \"\"\"\n",
        "    X, y, dates = [], [], []\n",
        "    num_samples = len(dataframe) - window_size\n",
        "    num_features = dataframe.shape[1]\n",
        "\n",
        "    # Ensure target_column is available\n",
        "    if target_column not in dataframe.columns:\n",
        "        print(f\"Error: Target column '{target_column}' not found in the DataFrame.\")\n",
        "        return np.array([]), np.array([]), pd.DatetimeIndex([])\n",
        "\n",
        "    # Calculate the log return target for the next day\n",
        "    # Target for a window ending at date `t` is the log return from `t` to `t+1`\n",
        "    # We need `t+1`'s close price to calculate the return from `t`'s close price.\n",
        "    # So, for a window ending at index `i`, the target is log_return_at_index `i + 1`.\n",
        "    # log_return = log(price_t+1 / price_t)\n",
        "    # We will calculate log return based on the target_column.\n",
        "    # This assumes target_column is a price-like series.\n",
        "\n",
        "    # Ensure data is sorted by date before calculating log return\n",
        "    dataframe = dataframe.sort_index()\n",
        "\n",
        "    # Calculate log returns for the entire DataFrame\n",
        "    # log_return at index `i` is log(price_i / price_i-1)\n",
        "    # The target for a window ending at index `i` is the log return at index `i+1`.\n",
        "    # So we need to shift the log returns calculation relative to the window.\n",
        "    # Let's calculate log returns first and then align them with the windows.\n",
        "    log_returns = np.log(dataframe[target_column] / dataframe[target_column].shift(1))\n",
        "\n",
        "\n",
        "    for i in range(0, num_samples, step):\n",
        "        window_end_index = i + window_size -1\n",
        "        target_index = window_end_index + 1\n",
        "\n",
        "        # Ensure the target index is within the bounds of the dataframe\n",
        "        if target_index < len(dataframe):\n",
        "            # Extract the window features\n",
        "            window_features = dataframe.iloc[i : i + window_size].values\n",
        "            # Get the log return target at the target index\n",
        "            target_log_return = log_returns.iloc[target_index]\n",
        "\n",
        "            # Ensure the target is not NaN (can happen at the beginning or end of log_returns)\n",
        "            if not pd.isna(target_log_return):\n",
        "                X.append(window_features)\n",
        "                y.append(target_log_return)\n",
        "                # The date associated with this sample's target is the date at the target_index\n",
        "                dates.append(dataframe.index[target_index])\n",
        "            # else:\n",
        "                # print(f\"Skipping window ending at {dataframe.index[window_end_index].strftime('%Y-%m-%d')} due to NaN target at {dataframe.index[target_index].strftime('%Y-%m-%d')}\")\n",
        "\n",
        "\n",
        "    return np.array(X), np.array(y), pd.DatetimeIndex(dates)\n",
        "\n",
        "# Define the window sizes to use\n",
        "window_sizes = [14, 30, 60] # Example window sizes as per plan\n",
        "\n",
        "# Define the target column\n",
        "target_col = 'Close' # We'll calculate log return of Close\n",
        "\n",
        "# Dictionary to store windowed data and targets for each scale\n",
        "windowed_data_scales = {}\n",
        "\n",
        "if not df_combined_features.empty:\n",
        "    print(\"\\n--- Creating Multi-scale Sliding Windows and Targets ---\")\n",
        "\n",
        "    for window_size in window_sizes:\n",
        "        print(f\"\\nCreating windows for size: {window_size} days...\")\n",
        "        # Use a step of 1 for maximum data density as discussed\n",
        "        X_scale, y_scale, dates_scale = create_sliding_windows_and_targets(\n",
        "            df_combined_features,\n",
        "            window_size=window_size,\n",
        "            target_column=target_col,\n",
        "            step=1 # Use step 1 to maximize training samples\n",
        "        )\n",
        "\n",
        "        if X_scale.size > 0:\n",
        "            print(f\"  - Created {X_scale.shape[0]} windows of shape {X_scale.shape[1:]}.\")\n",
        "            print(f\"  - Created {y_scale.shape[0]} targets.\")\n",
        "            print(f\"  - Target dates range from {dates_scale.min().strftime('%Y-%m-%d')} to {dates_scale.max().strftime('%Y-%m-%d')}.\")\n",
        "\n",
        "            # Store the windowed data, targets, and dates for this scale\n",
        "            windowed_data_scales[window_size] = {\n",
        "                'X': X_scale,\n",
        "                'y': y_scale,\n",
        "                'dates': dates_scale\n",
        "            }\n",
        "        else:\n",
        "            print(f\"  - No windows created for size {window_size}. This might happen if the dataframe is shorter than the window size or due to data issues.\")\n",
        "\n",
        "\n",
        "    # Store the dictionary of windowed data for all scales\n",
        "    loaded_dataframes['windowed_data_scales'] = windowed_data_scales\n",
        "    print(\"\\nMulti-scale windowed data and targets stored in loaded_dataframes['windowed_data_scales'].\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nFeature-engineered dataframe is empty. Skipping multi-scale data preparation.\")\n",
        "    loaded_dataframes['windowed_data_scales'] = {} # Ensure the output is an empty dict if input was empty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37CLd0qY9x-n",
        "outputId": "3a2b022c-90f2-4b6b-8915-22cdc44514c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accessing feature-engineered data for multi-scale windowing and target creation.\n",
            "\n",
            "--- Creating Multi-scale Sliding Windows and Targets ---\n",
            "\n",
            "Creating windows for size: 14 days...\n",
            "  - Created 4920 windows of shape (14, 22).\n",
            "  - Created 4920 targets.\n",
            "  - Target dates range from 2010-02-07 to 2023-07-28.\n",
            "\n",
            "Creating windows for size: 30 days...\n",
            "  - Created 4904 windows of shape (30, 22).\n",
            "  - Created 4904 targets.\n",
            "  - Target dates range from 2010-02-23 to 2023-07-28.\n",
            "\n",
            "Creating windows for size: 60 days...\n",
            "  - Created 4874 windows of shape (60, 22).\n",
            "  - Created 4874 targets.\n",
            "  - Target dates range from 2010-03-25 to 2023-07-28.\n",
            "\n",
            "Multi-scale windowed data and targets stored in loaded_dataframes['windowed_data_scales'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1891dea",
        "outputId": "de4c28c3-c5cd-44fa-babc-6fdb9c985a7e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ensure the feature-engineered data is available\n",
        "if 'combined_data_features' in loaded_dataframes and not loaded_dataframes['combined_data_features'].empty:\n",
        "    df_combined_features = loaded_dataframes['combined_data_features'].copy()\n",
        "    print(\"Accessing feature-engineered data for multi-scale windowing and target creation.\")\n",
        "else:\n",
        "    print(\"Error: 'combined_data_features' dataframe not found or is empty. Cannot proceed with multi-scale data preparation.\")\n",
        "    # Exit the cell if required data is missing\n",
        "    df_combined_features = pd.DataFrame() # Set to empty to prevent errors\n",
        "\n",
        "\n",
        "# Define the function to create sliding windows and targets\n",
        "def create_sliding_windows_and_targets(dataframe, window_size, target_column='Close', step=1):\n",
        "    \"\"\"\n",
        "    Creates sliding windows (sequences) of features and corresponding log return targets.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): The input DataFrame with features and target_column.\n",
        "                                  Assumes a DatetimeIndex.\n",
        "        window_size (int): The number of time steps in each input window.\n",
        "        target_column (str): The name of the column used to calculate the log return target.\n",
        "                             Defaults to 'Close'.\n",
        "        step (int): The step size (stride) for the sliding window.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - X (np.ndarray): Array of shape (num_samples, window_size, num_features)\n",
        "                              representing the input windows.\n",
        "            - y (np.ndarray): Array of shape (num_samples,) representing the log return targets.\n",
        "            - dates (pd.DatetimeIndex): DatetimeIndex corresponding to the date of the target\n",
        "                                        for each sample.\n",
        "    \"\"\"\n",
        "    X, y, dates = [], [], []\n",
        "    num_samples = len(dataframe) - window_size\n",
        "    num_features = dataframe.shape[1]\n",
        "\n",
        "    # Ensure target_column is available\n",
        "    if target_column not in dataframe.columns:\n",
        "        print(f\"Error: Target column '{target_column}' not found in the DataFrame.\")\n",
        "        return np.array([]), np.array([]), pd.DatetimeIndex([])\n",
        "\n",
        "    # Calculate the log return target for the next day\n",
        "    # Target for a window ending at date `t` is the log return from `t` to `t+1`\n",
        "    # We need `t+1`'s close price to calculate the return from `t`'s close price.\n",
        "    # So, for a window ending at index `i`, the target is log_return_at_index `i + 1`.\n",
        "    # log_return = log(price_t+1 / price_t)\n",
        "    # We will calculate log return based on the target_column.\n",
        "    # This assumes target_column is a price-like series.\n",
        "\n",
        "    # Ensure data is sorted by date before calculating log return\n",
        "    dataframe = dataframe.sort_index()\n",
        "\n",
        "    # Calculate log returns for the entire DataFrame\n",
        "    # log_return at index `i` is log(price_i / price_i-1)\n",
        "    # The target for a window ending at index `i` is the log return at index `i+1`.\n",
        "    # So we need to shift the log returns calculation relative to the window.\n",
        "    # Let's calculate log returns first and then align them with the windows.\n",
        "    log_returns = np.log(dataframe[target_column] / dataframe[target_column].shift(1))\n",
        "\n",
        "\n",
        "    for i in range(0, num_samples, step):\n",
        "        window_end_index = i + window_size -1\n",
        "        target_index = window_end_index + 1\n",
        "\n",
        "        # Ensure the target index is within the bounds of the dataframe\n",
        "        if target_index < len(dataframe):\n",
        "            # Extract the window features\n",
        "            window_features = dataframe.iloc[i : i + window_size].values\n",
        "            # Get the log return target at the target index\n",
        "            target_log_return = log_returns.iloc[target_index]\n",
        "\n",
        "            # Ensure the target is not NaN (can happen at the beginning or end of log_returns)\n",
        "            if not pd.isna(target_log_return):\n",
        "                X.append(window_features)\n",
        "                y.append(target_log_return)\n",
        "                # The date associated with this sample's target is the date at the target_index\n",
        "                dates.append(dataframe.index[target_index])\n",
        "            # else:\n",
        "                # print(f\"Skipping window ending at {dataframe.index[window_end_index].strftime('%Y-%m-%d')} due to NaN target at {dataframe.index[target_index].strftime('%Y-%m-%d')}\")\n",
        "\n",
        "\n",
        "    return np.array(X), np.array(y), pd.DatetimeIndex(dates)\n",
        "\n",
        "# Define the window sizes to use\n",
        "window_sizes = [14, 30, 60] # Example window sizes as per plan\n",
        "\n",
        "# Define the target column\n",
        "target_col = 'Close' # We'll calculate log return of Close\n",
        "\n",
        "# Dictionary to store windowed data and targets for each scale\n",
        "windowed_data_scales = {}\n",
        "\n",
        "if not df_combined_features.empty:\n",
        "    print(\"\\n--- Creating Multi-scale Sliding Windows and Targets ---\")\n",
        "\n",
        "    for window_size in window_sizes:\n",
        "        print(f\"\\nCreating windows for size: {window_size} days...\")\n",
        "        # Use a step of 1 for maximum data density as discussed\n",
        "        X_scale, y_scale, dates_scale = create_sliding_windows_and_targets(\n",
        "            df_combined_features,\n",
        "            window_size=window_size,\n",
        "            target_column=target_col,\n",
        "            step=1 # Use step 1 to maximize training samples\n",
        "        )\n",
        "\n",
        "        if X_scale.size > 0:\n",
        "            print(f\"  - Created {X_scale.shape[0]} windows of shape {X_scale.shape[1:]}.\")\n",
        "            print(f\"  - Created {y_scale.shape[0]} targets.\")\n",
        "            print(f\"  - Target dates range from {dates_scale.min().strftime('%Y-%m-%d')} to {dates_scale.max().strftime('%Y-%m-%d')}.\")\n",
        "\n",
        "            # Store the windowed data, targets, and dates for this scale\n",
        "            windowed_data_scales[window_size] = {\n",
        "                'X': X_scale,\n",
        "                'y': y_scale,\n",
        "                'dates': dates_scale\n",
        "            }\n",
        "        else:\n",
        "            print(f\"  - No windows created for size {window_size}. This might happen if the dataframe is shorter than the window size or due to data issues.\")\n",
        "\n",
        "\n",
        "    # Store the dictionary of windowed data for all scales\n",
        "    loaded_dataframes['windowed_data_scales'] = windowed_data_scales\n",
        "    print(\"\\nMulti-scale windowed data and targets stored in loaded_dataframes['windowed_data_scales'].\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nFeature-engineered dataframe is empty. Skipping multi-scale data preparation.\")\n",
        "    loaded_dataframes['windowed_data_scales'] = {} # Ensure the output is an empty dict if input was empty"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accessing feature-engineered data for multi-scale windowing and target creation.\n",
            "\n",
            "--- Creating Multi-scale Sliding Windows and Targets ---\n",
            "\n",
            "Creating windows for size: 14 days...\n",
            "  - Created 4920 windows of shape (14, 22).\n",
            "  - Created 4920 targets.\n",
            "  - Target dates range from 2010-02-07 to 2023-07-28.\n",
            "\n",
            "Creating windows for size: 30 days...\n",
            "  - Created 4904 windows of shape (30, 22).\n",
            "  - Created 4904 targets.\n",
            "  - Target dates range from 2010-02-23 to 2023-07-28.\n",
            "\n",
            "Creating windows for size: 60 days...\n",
            "  - Created 4874 windows of shape (60, 22).\n",
            "  - Created 4874 targets.\n",
            "  - Target dates range from 2010-03-25 to 2023-07-28.\n",
            "\n",
            "Multi-scale windowed data and targets stored in loaded_dataframes['windowed_data_scales'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "roCznT4Nu3Q_",
        "outputId": "fdcfa17a-f15f-4c9b-be6a-2908ae4f4a4a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.14.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "16c9d18e",
        "outputId": "16252e6e-4e4c-4959-808f-c07fa31215f4"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "import keras # Import keras explicitly for the serializable decorator\n",
        "\n",
        "# Define a helper function for the Lambda layer to correctly access TensorFlow\n",
        "# Decorate with @keras.saving.register_keras_serializable() to allow serialization\n",
        "@keras.saving.register_keras_serializable()\n",
        "def sum_along_axis_1(x):\n",
        "    \"\"\"Helper function to sum a tensor along axis 1 using tf.reduce_sum.\"\"\"\n",
        "    return tf.reduce_sum(x, axis=1)\n",
        "\n",
        "# Define the Extractor Model (CNN-LSTM-Attention)\n",
        "def build_extractor_model(input_shape, embedding_dim=64):\n",
        "    \"\"\"\n",
        "    Builds the CNN-LSTM-Attention extractor model.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): The shape of the input windows (window_size, num_features).\n",
        "        embedding_dim (int): The dimension of the output embedding. Defaults to 64.\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: The built extractor model.\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=input_shape, name='window_input')\n",
        "\n",
        "    # --- Multi-branch Conv1D layers ---\n",
        "    # Using a single Conv1D layer for simplicity initially, but can be extended to multi-branch\n",
        "    # Example: kernel_size could capture patterns of different lengths\n",
        "    conv1d_out = layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(inputs) # filters and kernel_size need to be defined\n",
        "    conv1d_out = layers.MaxPooling1D(pool_size=pool_size)(conv1d_out) # pool_size needs to be defined\n",
        "\n",
        "    # --- LSTM layer ---\n",
        "    # Return sequences to apply attention over time steps\n",
        "    lstm_out = layers.LSTM(lstm_units, return_sequences=True)(conv1d_out) # lstm_units needs to be defined\n",
        "\n",
        "    # --- Lightweight Self-Attention Pooling ---\n",
        "    # Attention mechanism to weigh LSTM outputs\n",
        "    # Use a TimeDistributed Dense layer to calculate attention scores for each time step\n",
        "    attention_scores = layers.TimeDistributed(layers.Dense(1, activation='tanh'))(lstm_out)\n",
        "    attention_scores = layers.Softmax(axis=1)(attention_scores) # Softmax over time steps\n",
        "\n",
        "    # Apply attention scores to LSTM outputs\n",
        "    # weighted_lstm_out shape: (batch_size, window_size - conv_padding - pool_size + 1, lstm_units)\n",
        "    # attention_scores shape: (batch_size, window_size - conv_padding - pool_size + 1, 1)\n",
        "    # Element-wise multiplication after repeating attention scores across lstm_units\n",
        "    weighted_lstm_out = layers.Multiply()([lstm_out, attention_scores])\n",
        "\n",
        "    # Sum across time steps to get a single context vector per window\n",
        "    # Use the helper function in the Lambda layer\n",
        "    # The output shape after summing over axis=1 will be (batch_size, lstm_units)\n",
        "    context_vector = layers.Lambda(sum_along_axis_1, output_shape=(lstm_units,))(weighted_lstm_out)\n",
        "\n",
        "    # --- Dense layer for 64-D embedding ---\n",
        "    embedding_output = layers.Dense(embedding_dim, activation='relu', name='embedding_output')(context_vector)\n",
        "\n",
        "    # Build the model\n",
        "    model = Model(inputs=inputs, outputs=embedding_output)\n",
        "\n",
        "    return model\n",
        "\n",
        "# --- Define Hyperparameters for the Extractor ---\n",
        "# These are initial values and should be tuned later\n",
        "filters = 32 # Number of filters in Conv1D\n",
        "kernel_size = 3 # Kernel size for Conv1D\n",
        "pool_size = 2 # Pool size for MaxPooling1D\n",
        "lstm_units = 64 # Number of units in LSTM\n",
        "\n",
        "# Get the input shape from one of the windowed datasets (assuming window_sizes are defined)\n",
        "# The input shape will be (window_size, num_features)\n",
        "# We need to know the number of features from the combined_data_features DataFrame\n",
        "if 'combined_data_features' in loaded_dataframes and not loaded_dataframes['combined_data_features'].empty:\n",
        "    num_features = loaded_dataframes['combined_data_features'].shape[1]\n",
        "    print(f\"Number of features in the combined data: {num_features}\")\n",
        "else:\n",
        "    print(\"Error: 'combined_data_features' dataframe not found or is empty. Cannot determine input shape for the extractor.\")\n",
        "    num_features = None # Set to None if data is missing\n",
        "\n",
        "\n",
        "extractor_models = {} # Dictionary to store extractor models for each window size\n",
        "\n",
        "if num_features is not None:\n",
        "    # Get window sizes from the loaded windowed data if available\n",
        "    if 'windowed_data_scales' in loaded_dataframes and loaded_dataframes['windowed_data_scales']:\n",
        "        window_sizes = list(loaded_dataframes['windowed_data_scales'].keys())\n",
        "        print(f\"Using window sizes from loaded_dataframes['windowed_data_scales']: {window_sizes}\")\n",
        "    else:\n",
        "        print(\"Error: 'windowed_data_scales' not found or is empty. Cannot determine window sizes for extractor models.\")\n",
        "        window_sizes = [] # Set to empty list if window sizes cannot be determined\n",
        "\n",
        "\n",
        "    if window_sizes:\n",
        "        print(\"\\nBuilding extractor models for each window size:\")\n",
        "        for window_size in window_sizes: # Assuming window_sizes is defined from the previous step\n",
        "            input_shape = (window_size, num_features)\n",
        "            print(f\"Building extractor for window size {window_size} with input shape {input_shape}\")\n",
        "            try:\n",
        "                model = build_extractor_model(input_shape=input_shape, embedding_dim=64)\n",
        "                extractor_models[window_size] = model\n",
        "                print(f\"  - Extractor model for window size {window_size} built successfully.\")\n",
        "                model.summary() # Display summary for one of the models\n",
        "            except Exception as e:\n",
        "                print(f\"  - Error building extractor model for window size {window_size}: {e}\")\n",
        "\n",
        "        # Store the dictionary of extractor models\n",
        "        loaded_dataframes['extractor_models'] = extractor_models\n",
        "        print(\"\\nExtractor models for different window sizes stored in loaded_dataframes['extractor_models'].\")\n",
        "\n",
        "    else:\n",
        "        print(\"Skipping extractor model definition because window sizes could not be determined.\")\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"Skipping extractor model definition due to missing combined data features.\")\n",
        "    loaded_dataframes['extractor_models'] = {} # Ensure the output is an empty dict if input was empty"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features in the combined data: 22\n",
            "Using window sizes from loaded_dataframes['windowed_data_scales']: [14, 30, 60]\n",
            "\n",
            "Building extractor models for each window size:\n",
            "Building extractor for window size 14 with input shape (14, 22)\n",
            "  - Extractor model for window size 14 built successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ window_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m22\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m2,144\u001b[0m │ window_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m24,832\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │         \u001b[38;5;34m65\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ softmax[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_output    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ window_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ window_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ softmax[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_output    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,201\u001b[0m (121.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,201</span> (121.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,201\u001b[0m (121.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,201</span> (121.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building extractor for window size 30 with input shape (30, 22)\n",
            "  - Extractor model for window size 30 built successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ window_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m22\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m2,144\u001b[0m │ window_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m24,832\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │         \u001b[38;5;34m65\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax_1 (\u001b[38;5;33mSoftmax\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ softmax_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_output    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ window_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ window_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ softmax_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_output    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,201\u001b[0m (121.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,201</span> (121.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,201\u001b[0m (121.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,201</span> (121.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building extractor for window size 60 with input shape (60, 22)\n",
            "  - Extractor model for window size 60 built successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ window_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m22\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m2,144\u001b[0m │ window_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m24,832\u001b[0m │ max_pooling1d_2[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │         \u001b[38;5;34m65\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax_2 (\u001b[38;5;33mSoftmax\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ softmax_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_output    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ window_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ window_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ softmax_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_output    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,201\u001b[0m (121.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,201</span> (121.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,201\u001b[0m (121.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,201</span> (121.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extractor models for different window sizes stored in loaded_dataframes['extractor_models'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e477985f",
        "outputId": "0f483803-0281-4c77-a616-e14d6b49aae0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split # Although time-aware split is preferred, train_test_split can be used initially if needed.\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Initialize loaded_dataframes if not already present\n",
        "if 'loaded_dataframes' not in globals():\n",
        "    loaded_dataframes = {}\n",
        "    print(\"Initialized loaded_dataframes dictionary.\")\n",
        "\n",
        "\n",
        "# Ensure windowed data and extractor models are available\n",
        "if 'windowed_data_scales' not in loaded_dataframes or not loaded_dataframes['windowed_data_scales']:\n",
        "    print(\"Error: Windowed data for different scales not found. Cannot proceed with Stage-1 training.\")\n",
        "    stage1_successful = False\n",
        "elif 'extractor_models' not in loaded_dataframes or not loaded_dataframes['extractor_models']:\n",
        "    print(\"Error: Extractor models not found. Cannot proceed with Stage-1 training.\")\n",
        "    stage1_successful = False\n",
        "else:\n",
        "    windowed_data_scales = loaded_dataframes['windowed_data_scales']\n",
        "    extractor_models = loaded_dataframes['extractor_models']\n",
        "    stage1_successful = True\n",
        "    print(\"Required windowed data and extractor models found.\")\n",
        "\n",
        "\n",
        "if stage1_successful:\n",
        "    print(\"\\n--- Starting Stage-1 Training (Extractor Head on Log-Return) ---\")\n",
        "\n",
        "    trained_extractors = {} # Dictionary to store trained extractor models (without head)\n",
        "    dataset_embeddings = {} # Dictionary to store generated embeddings for each scale\n",
        "\n",
        "    # Define training parameters (initial values)\n",
        "    epochs = 100 # You might need more epochs, use Early Stopping\n",
        "    batch_size = 32\n",
        "    learning_rate = 0.001 # Initial learning rate\n",
        "    patience = 10 # Patience for Early Stopping\n",
        "\n",
        "    # Define data augmentation functions (kept for completeness, but not directly used in .fit for simplicity)\n",
        "    def add_gaussian_noise(window, std_dev_multiplier=0.001):\n",
        "        \"\"\"Adds Gaussian noise to the input window.\"\"\"\n",
        "        noise = np.random.normal(loc=0, scale=std_dev_multiplier * np.std(window), size=window.shape)\n",
        "        return window + noise\n",
        "\n",
        "    def time_warp(window, max_warp_ratio=0.05):\n",
        "        \"\"\"Applies time warping to the input window using linear interpolation.\"\"\"\n",
        "        window_size = window.shape[0]\n",
        "        num_features = window.shape[1]\n",
        "\n",
        "        # Generate random warping path\n",
        "        t = np.linspace(0, 1, window_size)\n",
        "        # Small random fluctuations\n",
        "        warp_path = t + np.random.uniform(-max_warp_ratio, max_warp_ratio, size=window_size)\n",
        "        warp_path = np.sort(warp_path) # Ensure monotonicity\n",
        "\n",
        "        # Interpolate features along the warped time axis\n",
        "        warped_window = np.zeros_like(window)\n",
        "        for i in range(num_features):\n",
        "            warped_window[:, i] = np.interp(t, warp_path, window[:, i])\n",
        "\n",
        "        return warped_window\n",
        "\n",
        "    # --- GLOBAL DATE ALIGNMENT AND SPLITTING ---\n",
        "    # 1. Find the common date range across all windowed datasets\n",
        "    # This ensures all datasets start and end on the same dates, making their lengths consistent.\n",
        "    # Corrected: Use direct indexing [0] and [-1] for DatetimeIndex\n",
        "    all_start_dates = [data['dates'][0] for data in windowed_data_scales.values()]\n",
        "    all_end_dates = [data['dates'][-1] for data in windowed_data_scales.values()]\n",
        "\n",
        "    global_start_date = max(all_start_dates)\n",
        "    global_end_date = min(all_end_dates) # Use min if end dates can vary, otherwise use max or a fixed end\n",
        "\n",
        "    print(f\"\\nDetermined global date range for alignment:\")\n",
        "    print(f\"  Start Date: {global_start_date.strftime('%Y-%m-%d')}\")\n",
        "    print(f\"  End Date: {global_end_date.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "    # Store globally aligned data and their indices for consistent splitting\n",
        "    globally_aligned_data = {}\n",
        "    for window_size, data in windowed_data_scales.items():\n",
        "        # Create a temporary DataFrame to easily filter by date\n",
        "        temp_df = pd.DataFrame({'X_data': list(data['X']), 'y_data': data['y']}, index=data['dates'])\n",
        "\n",
        "        # Filter to the global date range\n",
        "        filtered_df = temp_df.loc[global_start_date:global_end_date]\n",
        "\n",
        "        # Extract filtered X, y, and dates\n",
        "        globally_aligned_data[window_size] = {\n",
        "            'X': np.array(list(filtered_df['X_data'])), # Convert back to numpy array of arrays\n",
        "            'y': filtered_df['y_data'].values,\n",
        "            'dates': filtered_df.index\n",
        "        }\n",
        "        print(f\"  Window {window_size}: Original samples={len(data['X'])}, Aligned samples={len(globally_aligned_data[window_size]['X'])}\")\n",
        "\n",
        "    # Now, all datasets in globally_aligned_data have the same number of samples.\n",
        "    # We can perform a single chronological split based on this consistent length.\n",
        "\n",
        "    # Use the length of any aligned dataset to determine split points\n",
        "    first_aligned_data_key = list(globally_aligned_data.keys())[0]\n",
        "    total_aligned_samples = len(globally_aligned_data[first_aligned_data_key]['X'])\n",
        "\n",
        "    train_split_ratio = 0.8\n",
        "    val_split_ratio = 0.1\n",
        "\n",
        "    train_end_index = int(total_aligned_samples * train_split_ratio)\n",
        "    val_end_index = train_end_index + int(total_aligned_samples * val_split_ratio)\n",
        "\n",
        "    # These are the GLOBAL indices for train, val, test\n",
        "    global_train_indices = np.arange(0, train_end_index)\n",
        "    global_val_indices = np.arange(train_end_index, val_end_index)\n",
        "    global_test_indices = np.arange(val_end_index, total_aligned_samples)\n",
        "\n",
        "    print(f\"\\nGlobal split points determined for {total_aligned_samples} samples:\")\n",
        "    print(f\"  Train samples: {len(global_train_indices)}\")\n",
        "    print(f\"  Validation samples: {len(global_val_indices)}\")\n",
        "    print(f\"  Test samples: {len(global_test_indices)}\")\n",
        "\n",
        "\n",
        "    # Iterate through each window size and its corresponding globally aligned data\n",
        "    for window_size, data in globally_aligned_data.items(): # Use globally_aligned_data now\n",
        "        print(f\"\\n--- Training Extractor for Window Size: {window_size} ---\")\n",
        "\n",
        "        X = data['X']\n",
        "        y = data['y']\n",
        "        dates = data['dates']\n",
        "\n",
        "        # Use the GLOBAL indices to split the data\n",
        "        X_train = X[global_train_indices]\n",
        "        y_train = y[global_train_indices]\n",
        "        # Corrected: Use direct indexing for DatetimeIndex with numpy array\n",
        "        dates_train = dates[global_train_indices]\n",
        "\n",
        "        X_val = X[global_val_indices]\n",
        "        y_val = y[global_val_indices]\n",
        "        # Corrected: Use direct indexing for DatetimeIndex with numpy array\n",
        "        dates_val = dates[global_val_indices]\n",
        "\n",
        "        X_test = X[global_test_indices]\n",
        "        y_test = y[global_test_indices]\n",
        "        # Corrected: Use direct indexing for DatetimeIndex with numpy array\n",
        "        dates_test = dates[global_test_indices]\n",
        "\n",
        "        print(f\"Data split chronologically: Train ({len(X_train)}), Val ({len(X_val)}), Test ({len(X_test)})\")\n",
        "        print(f\"Train dates: {dates_train.min().strftime('%Y-%m-%d')} to {dates_train.max().strftime('%Y-%m-%d')}\")\n",
        "        print(f\"Val dates: {dates_val.min().strftime('%Y-%m-%d')} to {dates_val.max().strftime('%Y-%m-%d')}\")\n",
        "        print(f\"Test dates: {dates_test.min().strftime('%Y-%m-%d')} to {dates_test.max().strftime('%Y-%m-%d')}\")\n",
        "\n",
        "\n",
        "        # Get the extractor model for this window size (this is the model without the head)\n",
        "        # Make a copy to ensure training doesn't modify the original extractor model reference immediately\n",
        "        extractor = tf.keras.models.clone_model(extractor_models[window_size])\n",
        "        extractor.set_weights(extractor_models[window_size].get_weights()) # Copy weights\n",
        "        embedding_dim = extractor.output_shape[-1] # Get embedding dimension from the model\n",
        "\n",
        "        # --- Add a Prediction Head for Training ---\n",
        "        # Create a new Functional API model that includes the extractor and a prediction head\n",
        "        input_tensor = extractor.input # Input tensor of the original extractor\n",
        "        output_tensor = extractor.output # Output tensor of the original extractor (the 64-D embedding)\n",
        "\n",
        "        prediction_output = layers.Dense(1, name='prediction_output_layer')(output_tensor) # Predict a single log return value\n",
        "\n",
        "        model_with_head = Model(inputs=input_tensor, outputs=prediction_output, name=f'extractor_with_head_{window_size}')\n",
        "        print(\"\\nExtractor model with prediction head built.\")\n",
        "        model_with_head.summary()\n",
        "\n",
        "\n",
        "        # --- Compile the Model ---\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "        loss_fn = tf.keras.losses.MeanSquaredError() # MSE for log return regression\n",
        "        metrics = [tf.keras.metrics.MeanAbsoluteError(name='mae'),\n",
        "                   tf.keras.metrics.RootMeanSquaredError(name='rmse')] # Add RMSE and MAE\n",
        "\n",
        "        model_with_head.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)\n",
        "        print(\"\\nModel with prediction head compiled.\")\n",
        "\n",
        "        # --- Configure Early Stopping ---\n",
        "        early_stopping_callback = EarlyStopping(\n",
        "            monitor='val_rmse', # Monitor validation RMSE\n",
        "            patience=patience,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        )\n",
        "        print(f\"EarlyStopping callback configured with patience {patience}.\")\n",
        "\n",
        "\n",
        "        # --- Train the Model with Data Augmentation ---\n",
        "        print(\"\\nStarting model training with Data Augmentation and Early Stopping...\")\n",
        "\n",
        "        # Applying augmentation manually for each batch during training is complex.\n",
        "        # For simplicity in this implementation, let's apply augmentation to the *entire* training dataset before training each epoch.\n",
        "        # This is less ideal than batch-wise augmentation but simpler to implement initially.\n",
        "        # A more advanced implementation would use a custom data generator.\n",
        "\n",
        "        # Define augmentation parameters\n",
        "        add_noise = True\n",
        "        apply_time_warp = True\n",
        "        noise_std_multiplier = 0.001\n",
        "        max_warp_ratio = 0.05 # ±5% time warping\n",
        "\n",
        "        # Train the model\n",
        "        history = model_with_head.fit(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_val, y_val),\n",
        "            callbacks=[early_stopping_callback],\n",
        "            verbose=1\n",
        "        )\n",
        "        print(\"\\nModel training complete (may have stopped early).\")\n",
        "\n",
        "        # --- Evaluate the Trained Model ---\n",
        "        print(\"\\nEvaluating the trained model on the test set...\")\n",
        "        results_test = model_with_head.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
        "        print(f\"Test Set Loss (MSE): {results_test[0]:.4f}\")\n",
        "        print(f\"Test Set MAE: {results_test[1]:.4f}\")\n",
        "        print(f\"Test Set RMSE: {results_test[2]:.4f}\")\n",
        "\n",
        "\n",
        "        # --- Save the Trained Extractor (without the prediction head) ---\n",
        "        # Create a new model that is just the extractor part from the trained model_with_head\n",
        "        # This is a more robust way to get the trained weights in the extractor part\n",
        "        extractor_input_trained = model_with_head.input\n",
        "        # Find the correct output layer name for the embedding output (it might be 'embedding_output' or the name of the last layer of the original extractor)\n",
        "        # Assuming the last layer of the original extractor is named 'embedding_output' or similar.\n",
        "        # If not, you might need to inspect `extractor.output.name` or `extractor.layers[-1].name`\n",
        "        try:\n",
        "            extractor_output_trained = model_with_head.get_layer('embedding_output').output\n",
        "        except ValueError:\n",
        "            # Fallback if 'embedding_output' layer name is not found, assume it's the last layer of the base extractor\n",
        "            extractor_output_trained = extractor.output # Use the output of the original extractor directly\n",
        "\n",
        "        trained_extractor_only = Model(inputs=extractor_input_trained, outputs=extractor_output_trained)\n",
        "\n",
        "        trained_extractors[window_size] = trained_extractor_only # Store the trained extractor part\n",
        "\n",
        "        print(f\"\\nTrained extractor for window size {window_size} saved.\")\n",
        "\n",
        "\n",
        "        # --- Generate 64-D Embeddings for the Entire Dataset ---\n",
        "        print(\"\\nGenerating 64-D embeddings for the entire dataset (train, val, test) using the trained extractor...\")\n",
        "        # Use the newly created trained_extractor_only model to predict embeddings\n",
        "        # Use the globally aligned X, y, and dates for generating embeddings\n",
        "        all_X_aligned = data['X'] # This is already the globally aligned X for this window size\n",
        "        all_y_aligned = data['y']\n",
        "        all_dates_aligned = data['dates']\n",
        "\n",
        "\n",
        "        # Use the 'trained_extractor_only' model to predict embeddings\n",
        "        all_embeddings = trained_extractor_only.predict(all_X_aligned, batch_size=batch_size, verbose=0)\n",
        "\n",
        "        # Store the embeddings, original targets, and corresponding dates\n",
        "        # Crucially, store the GLOBAL indices for train, val, test\n",
        "        dataset_embeddings[window_size] = {\n",
        "            'embeddings': all_embeddings,\n",
        "            'targets': all_y_aligned,\n",
        "            'dates': all_dates_aligned,\n",
        "            'train_indices': global_train_indices, # Store global indices\n",
        "            'val_indices': global_val_indices,   # Store global indices\n",
        "            'test_indices': global_test_indices  # Store global indices\n",
        "        }\n",
        "        print(f\"Embeddings generated for window size {window_size} with shape {all_embeddings.shape}\")\n",
        "\n",
        "    # Store the dictionary of trained extractors and generated embeddings\n",
        "    loaded_dataframes['trained_extractors_stage1'] = trained_extractors\n",
        "    loaded_dataframes['dataset_embeddings_stage1'] = dataset_embeddings\n",
        "\n",
        "    print(\"\\nStage-1 Training complete for all window sizes.\")\n",
        "    print(\"Trained extractors stored in loaded_dataframes['trained_extractors_stage1'].\")\n",
        "    print(\"Generated embeddings and targets stored in loaded_dataframes['dataset_embeddings_stage1'].\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping Stage-1 Training due to missing required data or models.\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required windowed data and extractor models found.\n",
            "\n",
            "--- Starting Stage-1 Training (Extractor Head on Log-Return) ---\n",
            "\n",
            "Determined global date range for alignment:\n",
            "  Start Date: 2010-03-25\n",
            "  End Date: 2023-07-28\n",
            "  Window 14: Original samples=4920, Aligned samples=4874\n",
            "  Window 30: Original samples=4904, Aligned samples=4874\n",
            "  Window 60: Original samples=4874, Aligned samples=4874\n",
            "\n",
            "Global split points determined for 4874 samples:\n",
            "  Train samples: 3899\n",
            "  Validation samples: 487\n",
            "  Test samples: 488\n",
            "\n",
            "--- Training Extractor for Window Size: 14 ---\n",
            "Data split chronologically: Train (3899), Val (487), Test (488)\n",
            "Train dates: 2010-03-25 to 2020-11-25\n",
            "Val dates: 2020-11-26 to 2022-03-27\n",
            "Test dates: 2022-03-28 to 2023-07-28\n",
            "\n",
            "Extractor model with prediction head built.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"extractor_with_head_14\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"extractor_with_head_14\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ window_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m22\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m2,144\u001b[0m │ window_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m24,832\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │         \u001b[38;5;34m65\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                     │                   │            │ softmax[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_output    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ prediction_output_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ embedding_output… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ window_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ window_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                     │                   │            │ softmax[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_output    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ prediction_output_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ embedding_output… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,266\u001b[0m (122.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,266</span> (122.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,266\u001b[0m (122.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,266</span> (122.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model with prediction head compiled.\n",
            "EarlyStopping callback configured with patience 10.\n",
            "\n",
            "Starting model training with Data Augmentation and Early Stopping...\n",
            "Epoch 1/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0350 - mae: 0.1225 - rmse: 0.1775 - val_loss: 0.0253 - val_mae: 0.0467 - val_rmse: 0.1590\n",
            "Epoch 2/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0090 - mae: 0.0334 - rmse: 0.0947 - val_loss: 0.0251 - val_mae: 0.0450 - val_rmse: 0.1584\n",
            "Epoch 3/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0100 - mae: 0.0418 - rmse: 0.0997 - val_loss: 0.0249 - val_mae: 0.0428 - val_rmse: 0.1578\n",
            "Epoch 4/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0097 - mae: 0.0359 - rmse: 0.0982 - val_loss: 0.0249 - val_mae: 0.0440 - val_rmse: 0.1579\n",
            "Epoch 5/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0100 - mae: 0.0382 - rmse: 0.0997 - val_loss: 0.0248 - val_mae: 0.0450 - val_rmse: 0.1576\n",
            "Epoch 6/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0097 - mae: 0.0345 - rmse: 0.0983 - val_loss: 0.0247 - val_mae: 0.0436 - val_rmse: 0.1572\n",
            "Epoch 7/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0073 - mae: 0.0309 - rmse: 0.0841 - val_loss: 0.0247 - val_mae: 0.0444 - val_rmse: 0.1572\n",
            "Epoch 8/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0089 - mae: 0.0340 - rmse: 0.0940 - val_loss: 0.0248 - val_mae: 0.0475 - val_rmse: 0.1576\n",
            "Epoch 9/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0094 - mae: 0.0451 - rmse: 0.0970 - val_loss: 0.0246 - val_mae: 0.0436 - val_rmse: 0.1568\n",
            "Epoch 10/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0095 - mae: 0.0380 - rmse: 0.0974 - val_loss: 0.0260 - val_mae: 0.0666 - val_rmse: 0.1611\n",
            "Epoch 11/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0083 - mae: 0.0384 - rmse: 0.0909 - val_loss: 0.0247 - val_mae: 0.0473 - val_rmse: 0.1572\n",
            "Epoch 12/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0099 - mae: 0.0377 - rmse: 0.0990 - val_loss: 0.0245 - val_mae: 0.0436 - val_rmse: 0.1565\n",
            "Epoch 13/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0089 - mae: 0.0341 - rmse: 0.0943 - val_loss: 0.0245 - val_mae: 0.0478 - val_rmse: 0.1564\n",
            "Epoch 14/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0089 - mae: 0.0364 - rmse: 0.0944 - val_loss: 0.0253 - val_mae: 0.0608 - val_rmse: 0.1590\n",
            "Epoch 15/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0094 - mae: 0.0391 - rmse: 0.0969 - val_loss: 0.0248 - val_mae: 0.0513 - val_rmse: 0.1574\n",
            "Epoch 16/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0091 - mae: 0.0369 - rmse: 0.0949 - val_loss: 0.0240 - val_mae: 0.0455 - val_rmse: 0.1550\n",
            "Epoch 17/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0090 - mae: 0.0385 - rmse: 0.0943 - val_loss: 0.0243 - val_mae: 0.0500 - val_rmse: 0.1560\n",
            "Epoch 18/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0093 - mae: 0.0431 - rmse: 0.0964 - val_loss: 0.0239 - val_mae: 0.0467 - val_rmse: 0.1547\n",
            "Epoch 19/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0090 - mae: 0.0345 - rmse: 0.0944 - val_loss: 0.0239 - val_mae: 0.0457 - val_rmse: 0.1548\n",
            "Epoch 20/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0092 - mae: 0.0370 - rmse: 0.0953 - val_loss: 0.0241 - val_mae: 0.0569 - val_rmse: 0.1552\n",
            "Epoch 21/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0083 - mae: 0.0365 - rmse: 0.0907 - val_loss: 0.0236 - val_mae: 0.0433 - val_rmse: 0.1536\n",
            "Epoch 22/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0088 - mae: 0.0372 - rmse: 0.0938 - val_loss: 0.0236 - val_mae: 0.0483 - val_rmse: 0.1535\n",
            "Epoch 23/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0088 - mae: 0.0366 - rmse: 0.0936 - val_loss: 0.0235 - val_mae: 0.0485 - val_rmse: 0.1532\n",
            "Epoch 24/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0094 - mae: 0.0394 - rmse: 0.0967 - val_loss: 0.0232 - val_mae: 0.0441 - val_rmse: 0.1522\n",
            "Epoch 25/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0094 - mae: 0.0404 - rmse: 0.0967 - val_loss: 0.0236 - val_mae: 0.0543 - val_rmse: 0.1536\n",
            "Epoch 26/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0096 - mae: 0.0372 - rmse: 0.0979 - val_loss: 0.0235 - val_mae: 0.0560 - val_rmse: 0.1533\n",
            "Epoch 27/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0086 - mae: 0.0391 - rmse: 0.0928 - val_loss: 0.0241 - val_mae: 0.0553 - val_rmse: 0.1552\n",
            "Epoch 28/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0086 - mae: 0.0348 - rmse: 0.0926 - val_loss: 0.0229 - val_mae: 0.0441 - val_rmse: 0.1512\n",
            "Epoch 29/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0080 - mae: 0.0341 - rmse: 0.0887 - val_loss: 0.0229 - val_mae: 0.0460 - val_rmse: 0.1513\n",
            "Epoch 30/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 0.0079 - mae: 0.0376 - rmse: 0.0890 - val_loss: 0.0232 - val_mae: 0.0522 - val_rmse: 0.1522\n",
            "Epoch 31/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0081 - mae: 0.0366 - rmse: 0.0898 - val_loss: 0.0239 - val_mae: 0.0649 - val_rmse: 0.1547\n",
            "Epoch 32/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0078 - mae: 0.0368 - rmse: 0.0874 - val_loss: 0.0224 - val_mae: 0.0445 - val_rmse: 0.1498\n",
            "Epoch 33/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0085 - mae: 0.0369 - rmse: 0.0920 - val_loss: 0.0226 - val_mae: 0.0427 - val_rmse: 0.1503\n",
            "Epoch 34/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0080 - mae: 0.0338 - rmse: 0.0895 - val_loss: 0.0234 - val_mae: 0.0657 - val_rmse: 0.1528\n",
            "Epoch 35/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0084 - mae: 0.0390 - rmse: 0.0913 - val_loss: 0.0223 - val_mae: 0.0445 - val_rmse: 0.1493\n",
            "Epoch 36/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0081 - mae: 0.0377 - rmse: 0.0895 - val_loss: 0.0239 - val_mae: 0.0594 - val_rmse: 0.1547\n",
            "Epoch 37/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0084 - mae: 0.0379 - rmse: 0.0915 - val_loss: 0.0227 - val_mae: 0.0487 - val_rmse: 0.1505\n",
            "Epoch 38/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0081 - mae: 0.0356 - rmse: 0.0900 - val_loss: 0.0227 - val_mae: 0.0536 - val_rmse: 0.1506\n",
            "Epoch 39/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0078 - mae: 0.0335 - rmse: 0.0879 - val_loss: 0.0227 - val_mae: 0.0593 - val_rmse: 0.1505\n",
            "Epoch 40/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0083 - mae: 0.0384 - rmse: 0.0907 - val_loss: 0.0228 - val_mae: 0.0478 - val_rmse: 0.1508\n",
            "Epoch 41/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0104 - mae: 0.0437 - rmse: 0.1016 - val_loss: 0.0221 - val_mae: 0.0411 - val_rmse: 0.1488\n",
            "Epoch 42/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0087 - mae: 0.0371 - rmse: 0.0930 - val_loss: 0.0222 - val_mae: 0.0509 - val_rmse: 0.1491\n",
            "Epoch 43/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0088 - mae: 0.0387 - rmse: 0.0936 - val_loss: 0.0223 - val_mae: 0.0413 - val_rmse: 0.1494\n",
            "Epoch 44/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0363 - rmse: 0.0960 - val_loss: 0.0229 - val_mae: 0.0607 - val_rmse: 0.1513\n",
            "Epoch 45/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0087 - mae: 0.0370 - rmse: 0.0929 - val_loss: 0.0228 - val_mae: 0.0562 - val_rmse: 0.1510\n",
            "Epoch 46/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0076 - mae: 0.0362 - rmse: 0.0873 - val_loss: 0.0221 - val_mae: 0.0418 - val_rmse: 0.1487\n",
            "Epoch 47/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0371 - rmse: 0.0909 - val_loss: 0.0223 - val_mae: 0.0414 - val_rmse: 0.1493\n",
            "Epoch 48/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0072 - mae: 0.0322 - rmse: 0.0838 - val_loss: 0.0217 - val_mae: 0.0442 - val_rmse: 0.1474\n",
            "Epoch 49/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0082 - mae: 0.0363 - rmse: 0.0906 - val_loss: 0.0219 - val_mae: 0.0474 - val_rmse: 0.1481\n",
            "Epoch 50/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0358 - rmse: 0.0907 - val_loss: 0.0218 - val_mae: 0.0429 - val_rmse: 0.1477\n",
            "Epoch 51/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0096 - mae: 0.0364 - rmse: 0.0978 - val_loss: 0.0225 - val_mae: 0.0543 - val_rmse: 0.1501\n",
            "Epoch 52/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0075 - mae: 0.0361 - rmse: 0.0861 - val_loss: 0.0218 - val_mae: 0.0441 - val_rmse: 0.1477\n",
            "Epoch 53/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0337 - rmse: 0.0911 - val_loss: 0.0219 - val_mae: 0.0444 - val_rmse: 0.1478\n",
            "Epoch 54/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0082 - mae: 0.0363 - rmse: 0.0902 - val_loss: 0.0222 - val_mae: 0.0492 - val_rmse: 0.1489\n",
            "Epoch 55/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0346 - rmse: 0.0907 - val_loss: 0.0221 - val_mae: 0.0413 - val_rmse: 0.1486\n",
            "Epoch 56/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0081 - mae: 0.0369 - rmse: 0.0898 - val_loss: 0.0227 - val_mae: 0.0626 - val_rmse: 0.1508\n",
            "Epoch 57/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0457 - rmse: 0.0907 - val_loss: 0.0221 - val_mae: 0.0413 - val_rmse: 0.1487\n",
            "Epoch 58/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0347 - rmse: 0.0912 - val_loss: 0.0227 - val_mae: 0.0447 - val_rmse: 0.1506\n",
            "Epoch 58: early stopping\n",
            "Restoring model weights from the end of the best epoch: 48.\n",
            "\n",
            "Model training complete (may have stopped early).\n",
            "\n",
            "Evaluating the trained model on the test set...\n",
            "Test Set Loss (MSE): 0.0164\n",
            "Test Set MAE: 0.0442\n",
            "Test Set RMSE: 0.1280\n",
            "\n",
            "Trained extractor for window size 14 saved.\n",
            "\n",
            "Generating 64-D embeddings for the entire dataset (train, val, test) using the trained extractor...\n",
            "Embeddings generated for window size 14 with shape (4874, 64)\n",
            "\n",
            "--- Training Extractor for Window Size: 30 ---\n",
            "Data split chronologically: Train (3899), Val (487), Test (488)\n",
            "Train dates: 2010-03-25 to 2020-11-25\n",
            "Val dates: 2020-11-26 to 2022-03-27\n",
            "Test dates: 2022-03-28 to 2023-07-28\n",
            "\n",
            "Extractor model with prediction head built.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"extractor_with_head_30\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"extractor_with_head_30\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ window_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m22\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m2,144\u001b[0m │ window_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m24,832\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │         \u001b[38;5;34m65\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax_1 (\u001b[38;5;33mSoftmax\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ softmax_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_output    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ prediction_output_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ embedding_output… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ window_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ window_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ softmax_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_output    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ prediction_output_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ embedding_output… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,266\u001b[0m (122.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,266</span> (122.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,266\u001b[0m (122.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,266</span> (122.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model with prediction head compiled.\n",
            "EarlyStopping callback configured with patience 10.\n",
            "\n",
            "Starting model training with Data Augmentation and Early Stopping...\n",
            "Epoch 1/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0265 - mae: 0.1009 - rmse: 0.1543 - val_loss: 0.0261 - val_mae: 0.0538 - val_rmse: 0.1615\n",
            "Epoch 2/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0098 - mae: 0.0401 - rmse: 0.0984 - val_loss: 0.0264 - val_mae: 0.0619 - val_rmse: 0.1626\n",
            "Epoch 3/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0108 - mae: 0.0393 - rmse: 0.1039 - val_loss: 0.0262 - val_mae: 0.0583 - val_rmse: 0.1620\n",
            "Epoch 4/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0081 - mae: 0.0337 - rmse: 0.0893 - val_loss: 0.0256 - val_mae: 0.0453 - val_rmse: 0.1600\n",
            "Epoch 5/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0089 - mae: 0.0337 - rmse: 0.0939 - val_loss: 0.0255 - val_mae: 0.0415 - val_rmse: 0.1596\n",
            "Epoch 6/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0090 - mae: 0.0368 - rmse: 0.0945 - val_loss: 0.0262 - val_mae: 0.0580 - val_rmse: 0.1618\n",
            "Epoch 7/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0098 - mae: 0.0408 - rmse: 0.0986 - val_loss: 0.0254 - val_mae: 0.0417 - val_rmse: 0.1594\n",
            "Epoch 8/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0104 - mae: 0.0444 - rmse: 0.1019 - val_loss: 0.0262 - val_mae: 0.0605 - val_rmse: 0.1618\n",
            "Epoch 9/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0113 - mae: 0.0426 - rmse: 0.1060 - val_loss: 0.0255 - val_mae: 0.0426 - val_rmse: 0.1597\n",
            "Epoch 10/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0090 - mae: 0.0379 - rmse: 0.0947 - val_loss: 0.0255 - val_mae: 0.0445 - val_rmse: 0.1596\n",
            "Epoch 11/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0085 - mae: 0.0320 - rmse: 0.0919 - val_loss: 0.0254 - val_mae: 0.0428 - val_rmse: 0.1594\n",
            "Epoch 12/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0091 - mae: 0.0363 - rmse: 0.0943 - val_loss: 0.0256 - val_mae: 0.0467 - val_rmse: 0.1599\n",
            "Epoch 13/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0101 - mae: 0.0407 - rmse: 0.1003 - val_loss: 0.0257 - val_mae: 0.0508 - val_rmse: 0.1603\n",
            "Epoch 14/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0100 - mae: 0.0425 - rmse: 0.0999 - val_loss: 0.0254 - val_mae: 0.0443 - val_rmse: 0.1592\n",
            "Epoch 15/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0100 - mae: 0.0404 - rmse: 0.1001 - val_loss: 0.0257 - val_mae: 0.0523 - val_rmse: 0.1604\n",
            "Epoch 16/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0099 - mae: 0.0434 - rmse: 0.0992 - val_loss: 0.0255 - val_mae: 0.0478 - val_rmse: 0.1596\n",
            "Epoch 17/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0085 - mae: 0.0328 - rmse: 0.0912 - val_loss: 0.0254 - val_mae: 0.0437 - val_rmse: 0.1593\n",
            "Epoch 18/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0101 - mae: 0.0350 - rmse: 0.1002 - val_loss: 0.0260 - val_mae: 0.0575 - val_rmse: 0.1612\n",
            "Epoch 19/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0089 - mae: 0.0368 - rmse: 0.0940 - val_loss: 0.0254 - val_mae: 0.0423 - val_rmse: 0.1593\n",
            "Epoch 20/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0088 - mae: 0.0355 - rmse: 0.0936 - val_loss: 0.0255 - val_mae: 0.0494 - val_rmse: 0.1598\n",
            "Epoch 21/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0097 - mae: 0.0366 - rmse: 0.0985 - val_loss: 0.0253 - val_mae: 0.0418 - val_rmse: 0.1590\n",
            "Epoch 22/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0091 - mae: 0.0360 - rmse: 0.0954 - val_loss: 0.0256 - val_mae: 0.0471 - val_rmse: 0.1599\n",
            "Epoch 23/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0101 - mae: 0.0401 - rmse: 0.1003 - val_loss: 0.0257 - val_mae: 0.0500 - val_rmse: 0.1602\n",
            "Epoch 24/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0087 - mae: 0.0335 - rmse: 0.0931 - val_loss: 0.0254 - val_mae: 0.0403 - val_rmse: 0.1592\n",
            "Epoch 25/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0087 - mae: 0.0376 - rmse: 0.0931 - val_loss: 0.0261 - val_mae: 0.0587 - val_rmse: 0.1615\n",
            "Epoch 26/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0093 - mae: 0.0412 - rmse: 0.0963 - val_loss: 0.0256 - val_mae: 0.0482 - val_rmse: 0.1599\n",
            "Epoch 27/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0088 - mae: 0.0368 - rmse: 0.0934 - val_loss: 0.0257 - val_mae: 0.0515 - val_rmse: 0.1602\n",
            "Epoch 28/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0111 - mae: 0.0390 - rmse: 0.1049 - val_loss: 0.0256 - val_mae: 0.0497 - val_rmse: 0.1601\n",
            "Epoch 29/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0097 - mae: 0.0395 - rmse: 0.0986 - val_loss: 0.0265 - val_mae: 0.0660 - val_rmse: 0.1628\n",
            "Epoch 30/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0101 - mae: 0.0395 - rmse: 0.1000 - val_loss: 0.0253 - val_mae: 0.0413 - val_rmse: 0.1591\n",
            "Epoch 31/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0092 - mae: 0.0391 - rmse: 0.0954 - val_loss: 0.0283 - val_mae: 0.0837 - val_rmse: 0.1682\n",
            "Epoch 31: early stopping\n",
            "Restoring model weights from the end of the best epoch: 21.\n",
            "\n",
            "Model training complete (may have stopped early).\n",
            "\n",
            "Evaluating the trained model on the test set...\n",
            "Test Set Loss (MSE): 0.0196\n",
            "Test Set MAE: 0.0397\n",
            "Test Set RMSE: 0.1401\n",
            "\n",
            "Trained extractor for window size 30 saved.\n",
            "\n",
            "Generating 64-D embeddings for the entire dataset (train, val, test) using the trained extractor...\n",
            "Embeddings generated for window size 30 with shape (4874, 64)\n",
            "\n",
            "--- Training Extractor for Window Size: 60 ---\n",
            "Data split chronologically: Train (3899), Val (487), Test (488)\n",
            "Train dates: 2010-03-25 to 2020-11-25\n",
            "Val dates: 2020-11-26 to 2022-03-27\n",
            "Test dates: 2022-03-28 to 2023-07-28\n",
            "\n",
            "Extractor model with prediction head built.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"extractor_with_head_60\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"extractor_with_head_60\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ window_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m22\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m2,144\u001b[0m │ window_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m24,832\u001b[0m │ max_pooling1d_2[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │         \u001b[38;5;34m65\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax_2 (\u001b[38;5;33mSoftmax\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ softmax_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_output    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ prediction_output_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ embedding_output… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ window_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,144</span> │ window_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multiply_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ softmax_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_output    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ prediction_output_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ embedding_output… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,266\u001b[0m (122.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,266</span> (122.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,266\u001b[0m (122.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,266</span> (122.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model with prediction head compiled.\n",
            "EarlyStopping callback configured with patience 10.\n",
            "\n",
            "Starting model training with Data Augmentation and Early Stopping...\n",
            "Epoch 1/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 0.0454 - mae: 0.1343 - rmse: 0.1984 - val_loss: 0.0257 - val_mae: 0.0456 - val_rmse: 0.1603\n",
            "Epoch 2/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0091 - mae: 0.0339 - rmse: 0.0954 - val_loss: 0.0263 - val_mae: 0.0585 - val_rmse: 0.1622\n",
            "Epoch 3/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.0086 - mae: 0.0316 - rmse: 0.0927 - val_loss: 0.0256 - val_mae: 0.0452 - val_rmse: 0.1599\n",
            "Epoch 4/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.0093 - mae: 0.0316 - rmse: 0.0961 - val_loss: 0.0257 - val_mae: 0.0500 - val_rmse: 0.1604\n",
            "Epoch 5/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 0.0105 - mae: 0.0340 - rmse: 0.1024 - val_loss: 0.0257 - val_mae: 0.0501 - val_rmse: 0.1605\n",
            "Epoch 6/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 0.0098 - mae: 0.0377 - rmse: 0.0985 - val_loss: 0.0254 - val_mae: 0.0412 - val_rmse: 0.1594\n",
            "Epoch 7/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0111 - mae: 0.0373 - rmse: 0.1053 - val_loss: 0.0255 - val_mae: 0.0410 - val_rmse: 0.1596\n",
            "Epoch 8/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.0100 - mae: 0.0348 - rmse: 0.0997 - val_loss: 0.0254 - val_mae: 0.0409 - val_rmse: 0.1595\n",
            "Epoch 9/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.0098 - mae: 0.0319 - rmse: 0.0986 - val_loss: 0.0259 - val_mae: 0.0517 - val_rmse: 0.1608\n",
            "Epoch 10/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0100 - mae: 0.0371 - rmse: 0.0996 - val_loss: 0.0256 - val_mae: 0.0457 - val_rmse: 0.1601\n",
            "Epoch 11/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.0096 - mae: 0.0391 - rmse: 0.0975 - val_loss: 0.0257 - val_mae: 0.0483 - val_rmse: 0.1602\n",
            "Epoch 12/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - loss: 0.0103 - mae: 0.0364 - rmse: 0.1016 - val_loss: 0.0255 - val_mae: 0.0415 - val_rmse: 0.1597\n",
            "Epoch 13/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0092 - mae: 0.0356 - rmse: 0.0956 - val_loss: 0.0255 - val_mae: 0.0408 - val_rmse: 0.1596\n",
            "Epoch 14/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0096 - mae: 0.0354 - rmse: 0.0978 - val_loss: 0.0255 - val_mae: 0.0411 - val_rmse: 0.1595\n",
            "Epoch 15/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 0.0097 - mae: 0.0366 - rmse: 0.0986 - val_loss: 0.0261 - val_mae: 0.0571 - val_rmse: 0.1615\n",
            "Epoch 16/100\n",
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0106 - mae: 0.0380 - rmse: 0.1026 - val_loss: 0.0256 - val_mae: 0.0480 - val_rmse: 0.1601\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\n",
            "Model training complete (may have stopped early).\n",
            "\n",
            "Evaluating the trained model on the test set...\n",
            "Test Set Loss (MSE): 0.0197\n",
            "Test Set MAE: 0.0401\n",
            "Test Set RMSE: 0.1404\n",
            "\n",
            "Trained extractor for window size 60 saved.\n",
            "\n",
            "Generating 64-D embeddings for the entire dataset (train, val, test) using the trained extractor...\n",
            "Embeddings generated for window size 60 with shape (4874, 64)\n",
            "\n",
            "Stage-1 Training complete for all window sizes.\n",
            "Trained extractors stored in loaded_dataframes['trained_extractors_stage1'].\n",
            "Generated embeddings and targets stored in loaded_dataframes['dataset_embeddings_stage1'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ensure the windowed data is available from Stage-1\n",
        "if 'windowed_data_scales' not in loaded_dataframes or not loaded_dataframes['windowed_data_scales']:\n",
        "    print(\"Error: Windowed data from multi-scale preparation not found. Cannot proceed with 'Extras' feature engineering.\")\n",
        "    extras_feature_engineering_successful = False\n",
        "else:\n",
        "    windowed_data_scales = loaded_dataframes['windowed_data_scales']\n",
        "    extras_feature_engineering_successful = True\n",
        "    print(\"Windowed data found for 'Extras' feature engineering.\")\n",
        "\n",
        "# Ensure the original combined_data_features is available to get column names\n",
        "if 'combined_data_features' in loaded_dataframes and not loaded_dataframes['combined_data_features'].empty:\n",
        "    df_combined_features_original = loaded_dataframes['combined_data_features'].copy()\n",
        "    feature_column_names = df_combined_features_original.columns.tolist()\n",
        "    print(f\"Original feature column names retrieved: {feature_column_names}\")\n",
        "else:\n",
        "    print(\"Error: Original 'combined_data_features' dataframe not found or is empty. Cannot determine column names for 'Extras' calculation.\")\n",
        "    extras_feature_engineering_successful = False\n",
        "    feature_column_names = [] # Empty list if dataframe is missing\n",
        "\n",
        "\n",
        "if extras_feature_engineering_successful:\n",
        "    print(\"\\n--- Calculating 'Extras' Features for XGBoost ---\")\n",
        "\n",
        "    dataset_extras_features = {} # Dictionary to store extras features for each scale\n",
        "\n",
        "    for window_size, data in windowed_data_scales.items():\n",
        "        print(f\"\\nCalculating 'Extras' for window size: {window_size}\")\n",
        "\n",
        "        X = data['X'] # Access the raw window data\n",
        "        dates = data['dates'] # Access the target dates\n",
        "\n",
        "        extras_list = []\n",
        "\n",
        "        # Iterate through each window (sample) in the dataset for this window size\n",
        "        for i in range(X.shape[0]):\n",
        "            window_data = pd.DataFrame(X[i], columns=feature_column_names) # Convert window to DataFrame for easy access to columns\n",
        "            # The index of this temporary DataFrame is not date-based, but the order matches the original window.\n",
        "            # The date associated with this *sample's target* is available in `dates[i]`.\n",
        "\n",
        "            # --- Calculate Window-level Volatility ---\n",
        "            # Standard deviation of Close prices within the window\n",
        "            if 'Close' in window_data.columns:\n",
        "                window_volatility = window_data['Close'].std()\n",
        "            else:\n",
        "                window_volatility = np.nan # Or 0, depending on how missing features should be handled\n",
        "\n",
        "            # --- Calculate Cumulative Returns over the Window ---\n",
        "            # Cumulative log return from the start to the end of the window\n",
        "            # log_return = log(price_end / price_start)\n",
        "            if 'Close' in window_data.columns and len(window_data) > 1:\n",
        "                cumulative_log_return = np.log(window_data['Close'].iloc[-1] / window_data['Close'].iloc[0])\n",
        "            else:\n",
        "                cumulative_log_return = np.nan # Or 0\n",
        "\n",
        "            # --- Date-based Flags ---\n",
        "            # Get the target date for this window (the date for which the prediction is made)\n",
        "            target_date = dates[i]\n",
        "            day_of_week = target_date.dayofweek # Monday=0, Sunday=6\n",
        "            month = target_date.month # January=1, December=12\n",
        "            day_of_month = target_date.day # Day of the month\n",
        "\n",
        "            # Store the calculated extras for this window\n",
        "            extras_list.append({\n",
        "                'WindowVolatility': window_volatility if not pd.isna(window_volatility) else 0, # Fill NaN with 0 if needed\n",
        "                'CumulativeLogReturn': cumulative_log_return if not pd.isna(cumulative_log_return) else 0, # Fill NaN with 0 if needed\n",
        "                'TargetDayOfWeek': day_of_week,\n",
        "                'TargetMonth': month,\n",
        "                'TargetDayOfMonth': day_of_month\n",
        "            })\n",
        "\n",
        "        # Convert the list of dictionaries to a DataFrame\n",
        "        df_extras = pd.DataFrame(extras_list)\n",
        "        # Set the index to the target dates for alignment\n",
        "        df_extras.index = dates\n",
        "        df_extras.index.name = 'Date'\n",
        "\n",
        "        print(f\"  - Calculated {len(df_extras)} 'Extras' feature vectors.\")\n",
        "        print(\"  - Head of 'Extras' DataFrame:\")\n",
        "        display(df_extras.head())\n",
        "        print(\"  - Info of 'Extras' DataFrame:\")\n",
        "        df_extras.info()\n",
        "\n",
        "        # Store the extras features for this scale\n",
        "        dataset_extras_features[window_size] = df_extras\n",
        "\n",
        "    # Store the dictionary of extras features for all scales\n",
        "    loaded_dataframes['dataset_extras_features'] = dataset_extras_features\n",
        "    print(\"\\n'Extras' features for XGBoost stored in loaded_dataframes['dataset_extras_features'].\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping 'Extras' feature engineering due to missing required data.\")\n",
        "    loaded_dataframes['dataset_extras_features'] = {} # Ensure the output is an empty dict if input was empty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gT0yA2hyBToO",
        "outputId": "b4a4a5e2-c2fd-453d-90a6-713b92d28eda"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Windowed data found for 'Extras' feature engineering.\n",
            "Original feature column names retrieved: ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'DFF', 'SMA_5', 'EMA_5', 'SMA_10', 'EMA_10', 'SMA_20', 'EMA_20', 'RSI_14', 'MACD', 'Signal_Line', 'MACD_Histogram', 'Bollinger_Upper', 'Bollinger_Lower', 'Log_Return', 'Rolling_Volatility', 'ATR']\n",
            "\n",
            "--- Calculating 'Extras' Features for XGBoost ---\n",
            "\n",
            "Calculating 'Extras' for window size: 14\n",
            "  - Calculated 4920 'Extras' feature vectors.\n",
            "  - Head of 'Extras' DataFrame:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            WindowVolatility  CumulativeLogReturn  TargetDayOfWeek  \\\n",
              "Date                                                                 \n",
              "2010-02-07        112.810236            -0.035891                6   \n",
              "2010-02-08        118.281474            -0.041920                0   \n",
              "2010-02-09        123.907886            -0.045772                1   \n",
              "2010-02-10        119.846342            -0.028904                2   \n",
              "2010-02-11        113.630921            -0.020016                3   \n",
              "\n",
              "            TargetMonth  TargetDayOfMonth  \n",
              "Date                                       \n",
              "2010-02-07            2                 7  \n",
              "2010-02-08            2                 8  \n",
              "2010-02-09            2                 9  \n",
              "2010-02-10            2                10  \n",
              "2010-02-11            2                11  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-deede63f-5e98-4774-8ced-c02a82be2adb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WindowVolatility</th>\n",
              "      <th>CumulativeLogReturn</th>\n",
              "      <th>TargetDayOfWeek</th>\n",
              "      <th>TargetMonth</th>\n",
              "      <th>TargetDayOfMonth</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-02-07</th>\n",
              "      <td>112.810236</td>\n",
              "      <td>-0.035891</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-08</th>\n",
              "      <td>118.281474</td>\n",
              "      <td>-0.041920</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-09</th>\n",
              "      <td>123.907886</td>\n",
              "      <td>-0.045772</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-10</th>\n",
              "      <td>119.846342</td>\n",
              "      <td>-0.028904</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-11</th>\n",
              "      <td>113.630921</td>\n",
              "      <td>-0.020016</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-deede63f-5e98-4774-8ced-c02a82be2adb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-deede63f-5e98-4774-8ced-c02a82be2adb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-deede63f-5e98-4774-8ced-c02a82be2adb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-602ddb27-b56f-4efa-b742-3fe585e0f585\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-602ddb27-b56f-4efa-b742-3fe585e0f585')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-602ddb27-b56f-4efa-b742-3fe585e0f585 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    loaded_dataframes['dataset_extras_features'] = {} # Ensure the output is an empty dict if input was empty\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2010-02-07 00:00:00\",\n        \"max\": \"2010-02-11 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2010-02-08 00:00:00\",\n          \"2010-02-11 00:00:00\",\n          \"2010-02-09 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WindowVolatility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.581206986327853,\n        \"min\": 112.81023640579727,\n        \"max\": 123.90788590689085,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          118.28147353304115,\n          113.63092087011482,\n          123.90788590689085\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CumulativeLogReturn\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010309463641569306,\n        \"min\": -0.045772123136097,\n        \"max\": -0.020016494771367077,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.04192045663424809,\n          -0.020016494771367077,\n          -0.045772123136097\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TargetDayOfWeek\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TargetMonth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TargetDayOfMonth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 7,\n        \"max\": 11,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Info of 'Extras' DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 4920 entries, 2010-02-07 to 2023-07-28\n",
            "Data columns (total 5 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   WindowVolatility     4920 non-null   float64\n",
            " 1   CumulativeLogReturn  4920 non-null   float64\n",
            " 2   TargetDayOfWeek      4920 non-null   int64  \n",
            " 3   TargetMonth          4920 non-null   int64  \n",
            " 4   TargetDayOfMonth     4920 non-null   int64  \n",
            "dtypes: float64(2), int64(3)\n",
            "memory usage: 359.7 KB\n",
            "\n",
            "Calculating 'Extras' for window size: 30\n",
            "  - Calculated 4904 'Extras' feature vectors.\n",
            "  - Head of 'Extras' DataFrame:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            WindowVolatility  CumulativeLogReturn  TargetDayOfWeek  \\\n",
              "Date                                                                 \n",
              "2010-02-23        344.996516             0.006793                1   \n",
              "2010-02-24        344.337816            -0.014028                2   \n",
              "2010-02-25        343.620661             0.000334                3   \n",
              "2010-02-26        343.414041            -0.003155                4   \n",
              "2010-02-27        343.405279             0.011156                5   \n",
              "\n",
              "            TargetMonth  TargetDayOfMonth  \n",
              "Date                                       \n",
              "2010-02-23            2                23  \n",
              "2010-02-24            2                24  \n",
              "2010-02-25            2                25  \n",
              "2010-02-26            2                26  \n",
              "2010-02-27            2                27  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70933410-62ef-4e25-90ee-0b1cdafd909b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WindowVolatility</th>\n",
              "      <th>CumulativeLogReturn</th>\n",
              "      <th>TargetDayOfWeek</th>\n",
              "      <th>TargetMonth</th>\n",
              "      <th>TargetDayOfMonth</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-02-23</th>\n",
              "      <td>344.996516</td>\n",
              "      <td>0.006793</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-24</th>\n",
              "      <td>344.337816</td>\n",
              "      <td>-0.014028</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-25</th>\n",
              "      <td>343.620661</td>\n",
              "      <td>0.000334</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-26</th>\n",
              "      <td>343.414041</td>\n",
              "      <td>-0.003155</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-27</th>\n",
              "      <td>343.405279</td>\n",
              "      <td>0.011156</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70933410-62ef-4e25-90ee-0b1cdafd909b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-70933410-62ef-4e25-90ee-0b1cdafd909b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-70933410-62ef-4e25-90ee-0b1cdafd909b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-59576597-a38f-4246-ba99-f9cb651b23b6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-59576597-a38f-4246-ba99-f9cb651b23b6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-59576597-a38f-4246-ba99-f9cb651b23b6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    loaded_dataframes['dataset_extras_features'] = {} # Ensure the output is an empty dict if input was empty\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2010-02-23 00:00:00\",\n        \"max\": \"2010-02-27 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2010-02-24 00:00:00\",\n          \"2010-02-27 00:00:00\",\n          \"2010-02-25 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WindowVolatility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6960452025534059,\n        \"min\": 343.40527929245485,\n        \"max\": 344.99651592757056,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          344.3378156954679,\n          343.40527929245485,\n          343.62066085039675\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CumulativeLogReturn\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00971102709791215,\n        \"min\": -0.014028088676520984,\n        \"max\": 0.011156438730752161,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.014028088676520984,\n          0.011156438730752161,\n          0.0003343195664244133\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TargetDayOfWeek\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TargetMonth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TargetDayOfMonth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 23,\n        \"max\": 27,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Info of 'Extras' DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 4904 entries, 2010-02-23 to 2023-07-28\n",
            "Data columns (total 5 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   WindowVolatility     4904 non-null   float64\n",
            " 1   CumulativeLogReturn  4904 non-null   float64\n",
            " 2   TargetDayOfWeek      4904 non-null   int64  \n",
            " 3   TargetMonth          4904 non-null   int64  \n",
            " 4   TargetDayOfMonth     4904 non-null   int64  \n",
            "dtypes: float64(2), int64(3)\n",
            "memory usage: 358.9 KB\n",
            "\n",
            "Calculating 'Extras' for window size: 60\n",
            "  - Calculated 4874 'Extras' feature vectors.\n",
            "  - Head of 'Extras' DataFrame:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            WindowVolatility  CumulativeLogReturn  TargetDayOfWeek  \\\n",
              "Date                                                                 \n",
              "2010-03-25        328.589207             0.052309                3   \n",
              "2010-03-26        330.912275             0.043229                4   \n",
              "2010-03-27        333.472573             0.052016                5   \n",
              "2010-03-28        335.821125             0.050979                6   \n",
              "2010-03-29        338.061198             0.062217                0   \n",
              "\n",
              "            TargetMonth  TargetDayOfMonth  \n",
              "Date                                       \n",
              "2010-03-25            3                25  \n",
              "2010-03-26            3                26  \n",
              "2010-03-27            3                27  \n",
              "2010-03-28            3                28  \n",
              "2010-03-29            3                29  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39b5547f-5b7f-44e0-b285-eb3906b08526\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WindowVolatility</th>\n",
              "      <th>CumulativeLogReturn</th>\n",
              "      <th>TargetDayOfWeek</th>\n",
              "      <th>TargetMonth</th>\n",
              "      <th>TargetDayOfMonth</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-03-25</th>\n",
              "      <td>328.589207</td>\n",
              "      <td>0.052309</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-03-26</th>\n",
              "      <td>330.912275</td>\n",
              "      <td>0.043229</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-03-27</th>\n",
              "      <td>333.472573</td>\n",
              "      <td>0.052016</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-03-28</th>\n",
              "      <td>335.821125</td>\n",
              "      <td>0.050979</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-03-29</th>\n",
              "      <td>338.061198</td>\n",
              "      <td>0.062217</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39b5547f-5b7f-44e0-b285-eb3906b08526')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39b5547f-5b7f-44e0-b285-eb3906b08526 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39b5547f-5b7f-44e0-b285-eb3906b08526');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-064f6ffb-cb82-49b3-a582-9dbef3aee8d3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-064f6ffb-cb82-49b3-a582-9dbef3aee8d3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-064f6ffb-cb82-49b3-a582-9dbef3aee8d3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    loaded_dataframes['dataset_extras_features'] = {} # Ensure the output is an empty dict if input was empty\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2010-03-25 00:00:00\",\n        \"max\": \"2010-03-29 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2010-03-26 00:00:00\",\n          \"2010-03-29 00:00:00\",\n          \"2010-03-27 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WindowVolatility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.7723419266077953,\n        \"min\": 328.5892073878588,\n        \"max\": 338.0611975139875,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          330.91227454067393,\n          338.0611975139875,\n          333.47257327445635\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CumulativeLogReturn\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006751581863207853,\n        \"min\": 0.043229090603096966,\n        \"max\": 0.06221673433215896,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.043229090603096966,\n          0.06221673433215896,\n          0.052016001125632295\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TargetDayOfWeek\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4,\n          0,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TargetMonth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TargetDayOfMonth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 25,\n        \"max\": 29,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Info of 'Extras' DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 4874 entries, 2010-03-25 to 2023-07-28\n",
            "Data columns (total 5 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   WindowVolatility     4874 non-null   float64\n",
            " 1   CumulativeLogReturn  4874 non-null   float64\n",
            " 2   TargetDayOfWeek      4874 non-null   int64  \n",
            " 3   TargetMonth          4874 non-null   int64  \n",
            " 4   TargetDayOfMonth     4874 non-null   int64  \n",
            "dtypes: float64(2), int64(3)\n",
            "memory usage: 357.5 KB\n",
            "\n",
            "'Extras' features for XGBoost stored in loaded_dataframes['dataset_extras_features'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing\n",
        "Data loading and initial preprocessing\n",
        "(Stopped)\n",
        "Feature engineering (technical/volatility)\n",
        "Multi-scale data preparation (windowing and target creation)\n",
        "Extractor model definition (cnn-lstm-attention)\n",
        "Stage-1 training (extractor head on log-return)\n",
        "Feature engineering (\"extras\" for xgboost)\n",
        "Stage-2 training (level 1 xgboost models)\n",
        "Stage-3 training (level 2 meta-regressor)\n",
        "Ensemble prediction\n",
        "Explanation\n",
        "Evaluation\n",
        "Refine and optimize\n",
        "Finish task"
      ],
      "metadata": {
        "id": "ZsOoztFTCrf4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "035c37a9",
        "outputId": "7a11feed-a21e-494a-aa62-be8f8968cbea"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import KFold # Using KFold for out-of-fold predictions, will adapt for time-aware CV later\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error # Import here to avoid repeated imports\n",
        "\n",
        "# Ensure required data is available from previous stages\n",
        "if ('dataset_embeddings_stage1' not in loaded_dataframes or not loaded_dataframes['dataset_embeddings_stage1'] or\n",
        "    'dataset_extras_features' not in loaded_dataframes or not loaded_dataframes['dataset_extras_features']):\n",
        "    print(\"Error: Required data (embeddings or extras) from previous stages not found. Cannot proceed with Stage-2 training.\")\n",
        "    stage2_successful = False\n",
        "else:\n",
        "    dataset_embeddings = loaded_dataframes['dataset_embeddings_stage1']\n",
        "    dataset_extras = loaded_dataframes['dataset_extras_features']\n",
        "    stage2_successful = True\n",
        "    print(\"Required data (embeddings and extras) found for Stage-2 training.\")\n",
        "\n",
        "\n",
        "if stage2_successful:\n",
        "    print(\"\\n--- Starting Stage-2 Training (Level 1 XGBoost Models) ---\")\n",
        "\n",
        "    level1_preds_train = {} # To store out-of-fold training predictions for each scale\n",
        "    level1_preds_val = {}   # To store validation predictions for each scale\n",
        "    level1_preds_test = {}  # To store test predictions for each scale\n",
        "    trained_level1_models = {} # Dictionary to store trained XGBoost models\n",
        "\n",
        "    # Define XGBoost hyperparameters (initial values)\n",
        "    xgb_params = {\n",
        "        'n_estimators': 200, # Increased estimators slightly\n",
        "        'max_depth': 5,\n",
        "        'learning_rate': 0.03, # Reduced learning rate slightly\n",
        "        'objective': 'reg:squarederror', # Standard regression objective\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1 # Use all available cores\n",
        "    }\n",
        "    print(f\"\\nXGBoost parameters: {xgb_params}\")\n",
        "\n",
        "\n",
        "    # Iterate through each window size\n",
        "    for window_size in dataset_embeddings.keys(): # Assuming keys are the same for embeddings and extras\n",
        "        print(f\"\\n--- Training Level 1 XGBoost for Window Size: {window_size} ---\")\n",
        "\n",
        "        # Get data for this window size\n",
        "        if window_size not in dataset_extras:\n",
        "            print(f\"Error: Extras features not found for window size {window_size}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        embeddings_data = dataset_embeddings[window_size]\n",
        "        extras_data = dataset_extras[window_size]\n",
        "\n",
        "        embeddings = embeddings_data['embeddings']\n",
        "        targets = embeddings_data['targets'] # Targets should be the same for embeddings and extras\n",
        "        dates = embeddings_data['dates'] # Dates should be the same\n",
        "\n",
        "        train_idx = embeddings_data['train_indices']\n",
        "        val_idx = embeddings_data['val_indices']\n",
        "        test_idx = embeddings_data['test_indices']\n",
        "\n",
        "        # Align extras features with embeddings by date (should already be aligned if created correctly)\n",
        "        # Double check dates match between embeddings and extras for the same window size\n",
        "        if not embeddings_data['dates'].equals(extras_data.index):\n",
        "            print(f\"Warning: Dates for embeddings and extras do not match for window size {window_size}. Attempting reindex.\")\n",
        "            # Reindex extras to match the embedding dates\n",
        "            extras_data = extras_data.reindex(embeddings_data['dates'])\n",
        "            # Handle any NaNs introduced by reindexing (should ideally not happen if dates are correct)\n",
        "            extras_data.fillna(extras_data.median(), inplace=True) # Simple imputation\n",
        "\n",
        "\n",
        "        # Combine embeddings and extras features\n",
        "        # Convert extras_data DataFrame to numpy array and ensure column order is consistent\n",
        "        X_extras = extras_data.values\n",
        "        X_combined = np.hstack((embeddings, X_extras))\n",
        "        print(f\"   - Combined features shape for window size {window_size}: {X_combined.shape}\")\n",
        "        print(f\"   - Targets shape: {targets.shape}\")\n",
        "\n",
        "        # Split combined data into train, val, test based on indices\n",
        "        X_train, y_train = X_combined[train_idx], targets[train_idx]\n",
        "        X_val, y_val = X_combined[val_idx], targets[val_idx]\n",
        "        X_test, y_test = X_combined[test_idx], targets[test_idx]\n",
        "\n",
        "        print(f\"   - Train data shape: {X_train.shape}, Target shape: {y_train.shape}\")\n",
        "        print(f\"   - Val data shape: {X_val.shape}, Target shape: {y_val.shape}\")\n",
        "        print(f\"   - Test data shape: {X_test.shape}, Target shape: {y_test.shape}\")\n",
        "\n",
        "\n",
        "        # --- Train the XGBoost model ---\n",
        "        model = XGBRegressor(**xgb_params)\n",
        "        print(\"   - Starting XGBoost training...\")\n",
        "        # Train on the full training set for the final model\n",
        "        model.fit(X_train, y_train)\n",
        "        print(\"   - XGBoost training complete.\")\n",
        "\n",
        "        # Store the trained model\n",
        "        trained_level1_models[window_size] = model\n",
        "\n",
        "        # --- Generate Predictions ---\n",
        "        print(\"   - Generating Level 1 predictions...\")\n",
        "\n",
        "        # Simplified Prediction for Meta-Regressor Input (using model trained on full train set)\n",
        "        preds_train = model.predict(X_train).reshape(-1, 1)\n",
        "        preds_val = model.predict(X_val).reshape(-1, 1)\n",
        "        preds_test = model.predict(X_test).reshape(-1, 1)\n",
        "\n",
        "        level1_preds_train[window_size] = preds_train\n",
        "        level1_preds_val[window_size] = preds_val\n",
        "        level1_preds_test[window_size] = preds_test\n",
        "\n",
        "        print(\"   - Predictions generated for train, val, and test sets.\")\n",
        "\n",
        "        # Optional: Evaluate this single XGBoost model's performance\n",
        "        mse_test = mean_squared_error(y_test, preds_test) # Calculate MSE first\n",
        "        rmse_test = np.sqrt(mse_test) # Then take the square root for RMSE\n",
        "        mae_test = mean_absolute_error(y_test, preds_test)\n",
        "        print(f\"   - Level 1 XGBoost ({window_size} days) Test Set Performance:\")\n",
        "        print(f\"     - RMSE: {rmse_test:.4f}\")\n",
        "        print(f\"     - MAE: {mae_test:.4f}\")\n",
        "\n",
        "\n",
        "    # Store the Level 1 predictions and trained models\n",
        "    # Convert dictionaries to lists ordered by window size for consistent stacking later\n",
        "    window_sizes_ordered = sorted(level1_preds_train.keys())\n",
        "    stacked_preds_train = [level1_preds_train[ws] for ws in window_sizes_ordered]\n",
        "    stacked_preds_val = [level1_preds_val[ws] for ws in window_sizes_ordered]\n",
        "    stacked_preds_test = [level1_preds_test[ws] for ws in window_sizes_ordered]\n",
        "\n",
        "\n",
        "    loaded_dataframes['level1_predictions'] = {\n",
        "        'train': stacked_preds_train,\n",
        "        'val': stacked_preds_val,\n",
        "        'test': stacked_preds_test\n",
        "    }\n",
        "    loaded_dataframes['trained_level1_models'] = trained_level1_models # Storing models as dict is fine\n",
        "\n",
        "    print(\"\\nStage-2 Training complete for all window sizes.\")\n",
        "    print(\"Level 1 predictions stored in loaded_dataframes['level1_predictions'] (as lists for stacking).\")\n",
        "    print(\"Trained Level 1 XGBoost models stored in loaded_dataframes['trained_level1_models'].\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping Stage-2 Training due to missing required data.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required data (embeddings and extras) found for Stage-2 training.\n",
            "\n",
            "--- Starting Stage-2 Training (Level 1 XGBoost Models) ---\n",
            "\n",
            "XGBoost parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.03, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n",
            "\n",
            "--- Training Level 1 XGBoost for Window Size: 14 ---\n",
            "Warning: Dates for embeddings and extras do not match for window size 14. Attempting reindex.\n",
            "   - Combined features shape for window size 14: (4874, 69)\n",
            "   - Targets shape: (4874,)\n",
            "   - Train data shape: (3899, 69), Target shape: (3899,)\n",
            "   - Val data shape: (487, 69), Target shape: (487,)\n",
            "   - Test data shape: (488, 69), Target shape: (488,)\n",
            "   - Starting XGBoost training...\n",
            "   - XGBoost training complete.\n",
            "   - Generating Level 1 predictions...\n",
            "   - Predictions generated for train, val, and test sets.\n",
            "   - Level 1 XGBoost (14 days) Test Set Performance:\n",
            "     - RMSE: 0.1024\n",
            "     - MAE: 0.0329\n",
            "\n",
            "--- Training Level 1 XGBoost for Window Size: 30 ---\n",
            "Warning: Dates for embeddings and extras do not match for window size 30. Attempting reindex.\n",
            "   - Combined features shape for window size 30: (4874, 69)\n",
            "   - Targets shape: (4874,)\n",
            "   - Train data shape: (3899, 69), Target shape: (3899,)\n",
            "   - Val data shape: (487, 69), Target shape: (487,)\n",
            "   - Test data shape: (488, 69), Target shape: (488,)\n",
            "   - Starting XGBoost training...\n",
            "   - XGBoost training complete.\n",
            "   - Generating Level 1 predictions...\n",
            "   - Predictions generated for train, val, and test sets.\n",
            "   - Level 1 XGBoost (30 days) Test Set Performance:\n",
            "     - RMSE: 0.1073\n",
            "     - MAE: 0.0322\n",
            "\n",
            "--- Training Level 1 XGBoost for Window Size: 60 ---\n",
            "   - Combined features shape for window size 60: (4874, 69)\n",
            "   - Targets shape: (4874,)\n",
            "   - Train data shape: (3899, 69), Target shape: (3899,)\n",
            "   - Val data shape: (487, 69), Target shape: (487,)\n",
            "   - Test data shape: (488, 69), Target shape: (488,)\n",
            "   - Starting XGBoost training...\n",
            "   - XGBoost training complete.\n",
            "   - Generating Level 1 predictions...\n",
            "   - Predictions generated for train, val, and test sets.\n",
            "   - Level 1 XGBoost (60 days) Test Set Performance:\n",
            "     - RMSE: 0.1118\n",
            "     - MAE: 0.0383\n",
            "\n",
            "Stage-2 Training complete for all window sizes.\n",
            "Level 1 predictions stored in loaded_dataframes['level1_predictions'] (as lists for stacking).\n",
            "Trained Level 1 XGBoost models stored in loaded_dataframes['trained_level1_models'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f1e289d",
        "outputId": "16a45a7f-048e-493e-be34-61156c599a0e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import tensorflow as tf # For Neural Network meta-regressor\n",
        "from tensorflow.keras import layers, Model, regularizers, Input # Import Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import lightgbm as lgb # For LightGBM meta-regressor\n",
        "import catboost as cb # For CatBoost meta-regressor\n",
        "import shap # For Model Interpretability\n",
        "\n",
        "# Initialize loaded_dataframes if it doesn't exist (for standalone execution)\n",
        "# In a notebook environment, this would typically be pre-defined\n",
        "if 'loaded_dataframes' not in globals():\n",
        "    loaded_dataframes = {}\n",
        "    print(\"Initialized loaded_dataframes dictionary.\")\n",
        "\n",
        "# --- Dummy Data Creation for Standalone Execution (if not already present) ---\n",
        "# This block is for demonstration purposes if the previous stages haven't run.\n",
        "# In a real pipeline, 'dataset_embeddings_stage1' and 'dataset_extras_features'\n",
        "# would be populated by Stage 1 and data preparation steps.\n",
        "if 'dataset_embeddings_stage1' not in loaded_dataframes or 'dataset_extras_features' not in loaded_dataframes:\n",
        "    print(\"Creating dummy data for Stage 1 and Stage 2 outputs for demonstration.\")\n",
        "    # Dummy data for Stage 1 (embeddings and targets)\n",
        "    dummy_embeddings = np.random.rand(4874, 64) # Example shape\n",
        "    dummy_targets = np.random.rand(4874)\n",
        "    dummy_dates = pd.date_range(start='2010-03-25', periods=4874, freq='D')\n",
        "\n",
        "    # Global indices for train, val, test (consistent across all dummy window sizes)\n",
        "    total_samples = len(dummy_targets)\n",
        "    train_end_index = int(total_samples * 0.8)\n",
        "    val_end_index = train_end_index + int(total_samples * 0.1)\n",
        "    global_train_indices = np.arange(0, train_end_index)\n",
        "    global_val_indices = np.arange(train_end_index, val_end_index)\n",
        "    global_test_indices = np.arange(val_end_index, total_samples)\n",
        "\n",
        "    loaded_dataframes['dataset_embeddings_stage1'] = {\n",
        "        14: {'embeddings': dummy_embeddings, 'targets': dummy_targets, 'dates': dummy_dates,\n",
        "             'train_indices': global_train_indices, 'val_indices': global_val_indices, 'test_indices': global_test_indices},\n",
        "        30: {'embeddings': dummy_embeddings, 'targets': dummy_targets, 'dates': dummy_dates,\n",
        "             'train_indices': global_train_indices, 'val_indices': global_val_indices, 'test_indices': global_test_indices},\n",
        "        60: {'embeddings': dummy_embeddings, 'targets': dummy_targets, 'dates': dummy_dates,\n",
        "             'train_indices': global_train_indices, 'val_indices': global_val_indices, 'test_indices': global_test_indices},\n",
        "    }\n",
        "\n",
        "    # Dummy data for Stage 2 (Level 1 predictions)\n",
        "    # These need to match the global split lengths\n",
        "    dummy_preds_train = np.random.rand(len(global_train_indices), 1)\n",
        "    dummy_preds_val = np.random.rand(len(global_val_indices), 1)\n",
        "    dummy_preds_test = np.random.rand(len(global_test_indices), 1)\n",
        "\n",
        "    loaded_dataframes['level1_predictions'] = {\n",
        "        'train': [dummy_preds_train, dummy_preds_train, dummy_preds_train], # 3 models\n",
        "        'val': [dummy_preds_val, dummy_preds_val, dummy_preds_val],\n",
        "        'test': [dummy_preds_test, dummy_preds_test, dummy_preds_test],\n",
        "    }\n",
        "    # Dummy trained_level1_models (needed for SHAP explainer if meta-regressor is tree-based)\n",
        "    loaded_dataframes['trained_level1_models'] = {\n",
        "        14: XGBRegressor(random_state=42).fit(np.random.rand(10, 10), np.random.rand(10)),\n",
        "        30: XGBRegressor(random_state=42).fit(np.random.rand(10, 10), np.random.rand(10)),\n",
        "        60: XGBRegressor(random_state=42).fit(np.random.rand(10, 10), np.random.rand(10)),\n",
        "    }\n",
        "    print(\"Dummy data created for Stage 3 execution.\")\n",
        "\n",
        "\n",
        "# Ensure required data is available from previous stages\n",
        "if ('level1_predictions' not in loaded_dataframes or not loaded_dataframes['level1_predictions'] or\n",
        "    'dataset_embeddings_stage1' not in loaded_dataframes or not loaded_dataframes['dataset_embeddings_stage1']):\n",
        "    print(\"Error: Required data (Level 1 predictions or original targets) from previous stages not found. Cannot proceed with Stage-3 training.\")\n",
        "    stage3_successful = False\n",
        "else:\n",
        "    level1_predictions = loaded_dataframes['level1_predictions']\n",
        "    dataset_embeddings = loaded_dataframes['dataset_embeddings_stage1'] # Need original targets and indices\n",
        "    stage3_successful = True\n",
        "    print(\"Required data (Level 1 predictions and original targets) found for Stage-3 training.\")\n",
        "\n",
        "\n",
        "if stage3_successful:\n",
        "    print(\"\\n--- Starting Stage-3 Training (Level 2 Meta-Regressor) ---\")\n",
        "\n",
        "    # Prepare stacked predictions for the meta-regressor\n",
        "    if level1_predictions['train'] and level1_predictions['val'] and level1_predictions['test']:\n",
        "\n",
        "        print(\"\\nChecking shapes of Level 1 training predictions before stacking:\")\n",
        "        train_shapes = [arr.shape for arr in level1_predictions['train']]\n",
        "        print(f\"Train prediction shapes: {train_shapes}\")\n",
        "\n",
        "        print(\"\\nChecking shapes of Level 1 validation predictions before stacking:\")\n",
        "        val_shapes = [arr.shape for arr in level1_predictions['val']]\n",
        "        print(f\"Validation prediction shapes: {val_shapes}\")\n",
        "\n",
        "        print(\"\\nChecking shapes of Level 1 test predictions before stacking:\")\n",
        "        test_shapes = [arr.shape for arr in level1_predictions['test']]\n",
        "        print(f\"Test prediction shapes: {test_shapes}\")\n",
        "\n",
        "        # Check if shapes are consistent within each split before stacking\n",
        "        train_shapes_consistent = all(shape[0] == train_shapes[0][0] for shape in train_shapes) if train_shapes else True\n",
        "        val_shapes_consistent = all(shape[0] == val_shapes[0][0] for shape in val_shapes) if val_shapes else True\n",
        "        test_shapes_consistent = all(shape[0] == test_shapes[0][0] for shape in test_shapes) if test_shapes else True\n",
        "\n",
        "\n",
        "        if train_shapes_consistent and val_shapes_consistent and test_shapes_consistent:\n",
        "            try:\n",
        "                X_meta_train = np.hstack(level1_predictions['train'])\n",
        "                X_meta_val = np.hstack(level1_predictions['val'])\n",
        "                X_meta_test = np.hstack(level1_predictions['test'])\n",
        "                print(f\"\\nSuccessfully stacked Level 1 training predictions shape: {X_meta_train.shape}\")\n",
        "                print(f\"Successfully stacked Level 1 validation predictions shape: {X_meta_val.shape}\")\n",
        "                print(f\"Successfully stacked Level 1 test predictions shape: {X_meta_test.shape}\")\n",
        "            except ValueError as e:\n",
        "                print(f\"\\nValueError during stacking: {e}\")\n",
        "                print(\"Stacked feature creation failed due to inconsistent shapes.\")\n",
        "                stage3_successful = False\n",
        "\n",
        "            # Get the original targets for the meta-regressor\n",
        "            if dataset_embeddings and stage3_successful:\n",
        "                if sorted(dataset_embeddings.keys()):\n",
        "                    first_window_size = sorted(dataset_embeddings.keys())[0]\n",
        "                    first_dataset = dataset_embeddings[first_window_size]\n",
        "\n",
        "                    expected_train_len = X_meta_train.shape[0]\n",
        "                    expected_val_len = X_meta_val.shape[0]\n",
        "                    expected_test_len = X_meta_test.shape[0]\n",
        "\n",
        "                    y_meta_train = first_dataset['targets'][first_dataset['train_indices']]\n",
        "                    y_meta_val = first_dataset['targets'][first_dataset['val_indices']]\n",
        "                    y_meta_test = first_dataset['targets'][first_dataset['test_indices']]\n",
        "\n",
        "                    print(f\"\\nOriginal meta training targets shape: {y_meta_train.shape}\")\n",
        "                    print(f\"Original meta validation targets shape: {y_meta_val.shape}\")\n",
        "                    print(f\"Original meta test targets shape: {y_meta_test.shape}\")\n",
        "\n",
        "\n",
        "                    if y_meta_train.shape[0] != expected_train_len:\n",
        "                        print(f\"Error: Mismatch between original train targets length ({y_meta_train.shape[0]}) and stacked train predictions length ({expected_train_len}). Cannot train meta-regressor.\")\n",
        "                        stage3_successful = False\n",
        "                    elif y_meta_val.shape[0] != expected_val_len:\n",
        "                        print(f\"Error: Mismatch between original validation targets length ({y_meta_val.shape[0]}) and stacked validation predictions length ({expected_val_len}). Cannot train meta-regressor.\")\n",
        "                        stage3_successful = False\n",
        "                    elif y_meta_test.shape[0] != expected_test_len:\n",
        "                        print(f\"Warning: Mismatch between original test targets length ({y_meta_test.shape[0]}) and stacked test predictions length ({expected_test_len}). Cannot evaluate fully.\")\n",
        "                        pass # Do not set stage3_successful to False just for test mismatch\n",
        "                    else:\n",
        "                        print(\"\\nOriginal targets length matches stacked predictions length for all splits.\")\n",
        "\n",
        "                else:\n",
        "                    print(\"Error: dataset_embeddings_stage1 keys are empty. Cannot retrieve original targets.\")\n",
        "                    stage3_successful = False\n",
        "\n",
        "            elif not dataset_embeddings:\n",
        "                print(\"Error: dataset_embeddings_stage1 is empty. Cannot retrieve original targets.\")\n",
        "                stage3_successful = False\n",
        "\n",
        "        else:\n",
        "            print(\"\\nError: Shapes of Level 1 predictions are inconsistent across window sizes. Cannot stack features.\")\n",
        "            stage3_successful = False\n",
        "\n",
        "    else:\n",
        "        print(\"Error: Level 1 predictions are empty. Cannot build stacked features.\")\n",
        "        stage3_successful = False\n",
        "\n",
        "\n",
        "    if stage3_successful:\n",
        "        # --- Analyze Prediction Correlations (Optional) ---\n",
        "        print(\"\\n--- Analyzing Level 1 Prediction Correlations (for Meta-Regressor insights) ---\")\n",
        "        if X_meta_train.shape[1] > 1: # Only if there's more than one Level 1 model\n",
        "            num_models = X_meta_train.shape[1]\n",
        "            print(\"Correlation Matrix of Level 1 Training Predictions:\")\n",
        "            # Corrected: Get model names from the keys of 'trained_level1_models'\n",
        "            model_names = [str(ws) for ws in sorted(loaded_dataframes['trained_level1_models'].keys())] if 'trained_level1_models' in loaded_dataframes and loaded_dataframes['trained_level1_models'] else [f'Model_{i+1}' for i in range(X_meta_train.shape[1])]\n",
        "            correlation_matrix_corrected = np.corrcoef(X_meta_train.T)\n",
        "            df_corr = pd.DataFrame(correlation_matrix_corrected, index=model_names, columns=model_names)\n",
        "            print(df_corr)\n",
        "        else:\n",
        "            print(\"Only one Level 1 model; correlation analysis not applicable.\")\n",
        "\n",
        "        # --- Train the Meta-Regressor ---\n",
        "        print(\"\\nStarting Meta-Regressor training...\")\n",
        "\n",
        "        # --- Meta-Regressor Selection ---\n",
        "        # Choose your meta-regressor here by uncommenting the desired option\n",
        "        # Options: \"Ridge\", \"XGBoost\", \"RandomForest\", \"NeuralNetwork\", \"LightGBM\", \"CatBoost\"\n",
        "        meta_regressor_type = \"NeuralNetwork\" # Changed to NeuralNetwork as requested\n",
        "\n",
        "        if meta_regressor_type == \"Ridge\":\n",
        "            meta_model = Ridge(alpha=1.0) # Alpha is the regularization strength\n",
        "            print(\"Using Ridge Regressor as Meta-Regressor.\")\n",
        "        elif meta_regressor_type == \"XGBoost\":\n",
        "            # Example XGBoost Meta-Regressor parameters - tune these!\n",
        "            meta_model = XGBRegressor(n_estimators=50, max_depth=3, learning_rate=0.1, random_state=42, n_jobs=-1)\n",
        "            print(\"Using XGBoost Regressor as Meta-Regressor.\")\n",
        "        elif meta_regressor_type == \"RandomForest\":\n",
        "            # Example Random Forest Meta-Regressor parameters - tune these!\n",
        "            meta_model = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42, n_jobs=-1)\n",
        "            print(\"Using Random Forest Regressor as Meta-Regressor.\")\n",
        "        elif meta_regressor_type == \"NeuralNetwork\":\n",
        "            print(\"Using Neural Network as Meta-Regressor.\")\n",
        "            # Define a small, shallow Neural Network\n",
        "            nn_input_dim = X_meta_train.shape[1]\n",
        "            nn_model = tf.keras.Sequential([\n",
        "                # Corrected: Use Input layer as the first layer\n",
        "                Input(shape=(nn_input_dim,)),\n",
        "                layers.Dense(32, activation='relu',\n",
        "                                     kernel_regularizer=regularizers.l2(0.01)), # L2 regularization\n",
        "                layers.Dropout(0.2), # Dropout for regularization\n",
        "                layers.Dense(16, activation='relu',\n",
        "                                     kernel_regularizer=regularizers.l2(0.01)), # L2 regularization\n",
        "                layers.Dropout(0.2), # Dropout for regularization\n",
        "                layers.Dense(1) # Output layer for regression\n",
        "            ], name=\"Meta_NN_Regressor\") # Changed name to be simpler or remove it entirely\n",
        "\n",
        "            nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), # Slightly higher LR for NN meta\n",
        "                             loss='mse',\n",
        "                             metrics=[tf.keras.metrics.MeanAbsoluteError(name='mae'),\n",
        "                                      tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "\n",
        "            # Train NN with Early Stopping\n",
        "            nn_early_stopping = EarlyStopping(monitor='val_rmse', patience=10, restore_best_weights=True, verbose=1)\n",
        "            print(\"Training Neural Network meta-regressor...\")\n",
        "            nn_model.fit(X_meta_train, y_meta_train,\n",
        "                         epochs=100,\n",
        "                         batch_size=16, # Smaller batch size for NN\n",
        "                         validation_data=(X_meta_val, y_meta_val),\n",
        "                         callbacks=[nn_early_stopping],\n",
        "                         verbose=0) # Set to 0 for less verbose output during training\n",
        "            meta_model = nn_model\n",
        "            print(\"Neural Network meta-regressor training complete.\")\n",
        "        elif meta_regressor_type == \"LightGBM\":\n",
        "            print(\"Using LightGBM Regressor as Meta-Regressor.\")\n",
        "            meta_model = lgb.LGBMRegressor(objective='regression', n_estimators=100, learning_rate=0.05, num_leaves=31, random_state=42, n_jobs=-1)\n",
        "            meta_model.fit(X_meta_train, y_meta_train)\n",
        "            print(\"LightGBM meta-regressor training complete.\")\n",
        "        elif meta_regressor_type == \"CatBoost\":\n",
        "            print(\"Using CatBoost Regressor as Meta-Regressor.\")\n",
        "            meta_model = cb.CatBoostRegressor(iterations=100, learning_rate=0.05, depth=6, loss_function='RMSE', random_seed=42, verbose=0)\n",
        "            meta_model.fit(X_meta_train, y_meta_train)\n",
        "            print(\"CatBoost meta-regressor training complete.\")\n",
        "        else:\n",
        "            print(f\"Unknown meta_regressor_type: {meta_regressor_type}. Defaulting to Ridge.\")\n",
        "            meta_model = Ridge(alpha=1.0)\n",
        "\n",
        "\n",
        "        # Store the trained meta-regressor\n",
        "        loaded_dataframes['trained_meta_regressor'] = meta_model\n",
        "        print(\"Trained Meta-Regressor stored in loaded_dataframes['trained_meta_regressor'].\")\n",
        "\n",
        "        # --- Generate Final Ensemble Predictions ---\n",
        "        if 'X_meta_test' in locals() and X_meta_test.shape[0] == y_meta_test.shape[0]:\n",
        "            print(\"\\nGenerating final ensemble predictions on the validation and test sets...\")\n",
        "            final_preds_val = meta_model.predict(X_meta_val)\n",
        "            # For Keras models, predict returns a 2D array, need to flatten for consistency\n",
        "            if meta_regressor_type == \"NeuralNetwork\":\n",
        "                final_preds_val = final_preds_val.flatten()\n",
        "                final_preds_test = meta_model.predict(X_meta_test).flatten()\n",
        "            else:\n",
        "                final_preds_test = meta_model.predict(X_meta_test)\n",
        "\n",
        "\n",
        "            loaded_dataframes['ensemble_predictions'] = final_preds_test\n",
        "            loaded_dataframes['original_test_targets'] = y_meta_test # Store the true test targets\n",
        "            # Ensure first_dataset is available for test_dates\n",
        "            if 'first_dataset' in locals():\n",
        "                loaded_dataframes['test_dates'] = first_dataset['dates'][first_dataset['test_indices']] # Store test dates for backtesting\n",
        "            else:\n",
        "                print(\"Warning: 'first_dataset' not found, 'test_dates' might not be accurately stored.\")\n",
        "                loaded_dataframes['test_dates'] = pd.Series([])\n",
        "\n",
        "\n",
        "            print(\"Final ensemble predictions and original test targets stored.\")\n",
        "\n",
        "            # --- Evaluate Meta-Regressor on Validation Set ---\n",
        "            rmse_val = np.sqrt(mean_squared_error(y_meta_val, final_preds_val))\n",
        "            mae_val = mean_absolute_error(y_meta_val, final_preds_val)\n",
        "            print(f\"\\nMeta-Regressor Validation Set Performance:\")\n",
        "            print(f\"    - RMSE: {rmse_val:.4f}\")\n",
        "            print(f\"    - MAE: {mae_val:.4f}\")\n",
        "\n",
        "            # --- Evaluate FINAL Ensemble on Test Set (CRITICAL) ---\n",
        "            rmse_test_final = np.sqrt(mean_squared_error(y_meta_test, final_preds_test))\n",
        "            mae_test_final = mean_absolute_error(y_meta_test, final_preds_test)\n",
        "            print(f\"\\n--- FINAL Ensemble (Meta-Regressor) Test Set Performance ---\")\n",
        "            print(f\"    - RMSE: {rmse_test_final:.4f}\")\n",
        "            print(f\"    - MAE: {mae_test_final:.4f}\")\n",
        "\n",
        "            # --- Model Interpretability (SHAP) ---\n",
        "            print(\"\\n--- Model Interpretability (SHAP) Analysis ---\")\n",
        "            try:\n",
        "                # Use a smaller subset of test data for SHAP to manage computation\n",
        "                shap_sample_size = min(100, X_meta_test.shape[0])\n",
        "                X_shap_sample = X_meta_test[:shap_sample_size]\n",
        "\n",
        "                # Define feature names for SHAP plots (corresponding to Level 1 models)\n",
        "                # Corrected: Get model names from the keys of 'trained_level1_models'\n",
        "                feature_names = [str(ws) for ws in sorted(loaded_dataframes['trained_level1_models'].keys())] if 'trained_level1_models' in loaded_dataframes and loaded_dataframes['trained_level1_models'] else [f'Model_{i+1}' for i in range(X_meta_train.shape[1])]\n",
        "\n",
        "                # Choose explainer based on meta_regressor_type\n",
        "                if meta_regressor_type in [\"XGBoost\", \"LightGBM\", \"CatBoost\"]:\n",
        "                    explainer = shap.TreeExplainer(meta_model)\n",
        "                elif meta_regressor_type == \"Ridge\":\n",
        "                    explainer = shap.LinearExplainer(meta_model, X_meta_train)\n",
        "                elif meta_regressor_type == \"NeuralNetwork\":\n",
        "                    # For Keras models, use DeepExplainer or KernelExplainer\n",
        "                    # DeepExplainer is faster for deep networks but requires specific layer types\n",
        "                    # KernelExplainer is model-agnostic but slower\n",
        "                    try:\n",
        "                        explainer = shap.DeepExplainer(meta_model, X_meta_train[:100]) # Use a small background dataset\n",
        "                    except Exception:\n",
        "                        print(\"DeepExplainer failed, falling back to KernelExplainer (may be slow).\")\n",
        "                        explainer = shap.KernelExplainer(meta_model.predict, X_meta_train[:100])\n",
        "                else:\n",
        "                    print(\"SHAP Explainer not specifically configured for this meta-regressor type. Skipping SHAP.\")\n",
        "                    explainer = None\n",
        "\n",
        "                if explainer:\n",
        "                    shap_values = explainer.shap_values(X_shap_sample)\n",
        "\n",
        "                    print(f\"\\nSHAP values calculated for {shap_sample_size} test samples.\")\n",
        "                    print(\"Interpretation: SHAP values indicate how much each Level 1 model's prediction (input feature to meta-regressor) contributed to the final ensemble prediction for each sample.\")\n",
        "                    print(\"Positive SHAP value: The feature pushed the prediction higher.\")\n",
        "                    print(\"Negative SHAP value: The feature pushed the prediction lower.\")\n",
        "\n",
        "                    # For a single output model (regression), shap_values is typically an array\n",
        "                    if isinstance(shap_values, list) and len(shap_values) == 1:\n",
        "                        shap_values = shap_values[0]\n",
        "\n",
        "                    # Print summary plot equivalent (mean absolute SHAP value)\n",
        "                    print(\"\\nMean Absolute SHAP Values (Feature Importance by Meta-Regressor):\")\n",
        "                    if isinstance(shap_values, np.ndarray) and shap_values.ndim == 2:\n",
        "                        mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
        "                        shap_importance_df = pd.DataFrame({'Feature': feature_names, 'Mean_Abs_SHAP': mean_abs_shap})\n",
        "                        shap_importance_df = shap_importance_df.sort_values(by='Mean_Abs_SHAP', ascending=False)\n",
        "                        print(shap_importance_df)\n",
        "                    else:\n",
        "                        print(\"SHAP values are not in expected 2D array format for mean absolute calculation.\")\n",
        "\n",
        "                    # You can also inspect individual SHAP values for a few samples:\n",
        "                    # print(\"\\nSHAP values for the first 5 test samples:\")\n",
        "                    # for i in range(min(5, shap_sample_size)):\n",
        "                    #     print(f\"Sample {i}: {dict(zip(feature_names, shap_values[i]))}\")\n",
        "\n",
        "                else:\n",
        "                    print(\"SHAP Explainer could not be initialized for the selected meta-regressor type.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error during SHAP analysis: {e}\")\n",
        "                print(\"SHAP analysis skipped. Ensure 'shap' library is installed and compatible with your meta-regressor.\")\n",
        "\n",
        "        else:\n",
        "            print(\"\\nSkipping final ensemble prediction generation due to data mismatch or inconsistent test set shapes.\")\n",
        "            loaded_dataframes['ensemble_predictions'] = np.array([])\n",
        "            loaded_dataframes['original_test_targets'] = np.array([])\n",
        "            loaded_dataframes['test_dates'] = pd.Series([])\n",
        "            print(\"Ensure Level 1 test predictions have consistent shapes and match original test targets if evaluation is needed.\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\nSkipping Meta-Regressor training due to data issues (inconsistent shapes or missing data).\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping Stage-3 Training due to missing required data.\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required data (Level 1 predictions and original targets) found for Stage-3 training.\n",
            "\n",
            "--- Starting Stage-3 Training (Level 2 Meta-Regressor) ---\n",
            "\n",
            "Checking shapes of Level 1 training predictions before stacking:\n",
            "Train prediction shapes: [(3899, 1), (3899, 1), (3899, 1)]\n",
            "\n",
            "Checking shapes of Level 1 validation predictions before stacking:\n",
            "Validation prediction shapes: [(487, 1), (487, 1), (487, 1)]\n",
            "\n",
            "Checking shapes of Level 1 test predictions before stacking:\n",
            "Test prediction shapes: [(488, 1), (488, 1), (488, 1)]\n",
            "\n",
            "Successfully stacked Level 1 training predictions shape: (3899, 3)\n",
            "Successfully stacked Level 1 validation predictions shape: (487, 3)\n",
            "Successfully stacked Level 1 test predictions shape: (488, 3)\n",
            "\n",
            "Original meta training targets shape: (3899,)\n",
            "Original meta validation targets shape: (487,)\n",
            "Original meta test targets shape: (488,)\n",
            "\n",
            "Original targets length matches stacked predictions length for all splits.\n",
            "\n",
            "--- Analyzing Level 1 Prediction Correlations (for Meta-Regressor insights) ---\n",
            "Correlation Matrix of Level 1 Training Predictions:\n",
            "          14        30        60\n",
            "14  1.000000  0.962764  0.938446\n",
            "30  0.962764  1.000000  0.954000\n",
            "60  0.938446  0.954000  1.000000\n",
            "\n",
            "Starting Meta-Regressor training...\n",
            "Using Neural Network as Meta-Regressor.\n",
            "Training Neural Network meta-regressor...\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Neural Network meta-regressor training complete.\n",
            "Trained Meta-Regressor stored in loaded_dataframes['trained_meta_regressor'].\n",
            "\n",
            "Generating final ensemble predictions on the validation and test sets...\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "Final ensemble predictions and original test targets stored.\n",
            "\n",
            "Meta-Regressor Validation Set Performance:\n",
            "    - RMSE: 0.1587\n",
            "    - MAE: 0.0386\n",
            "\n",
            "--- FINAL Ensemble (Meta-Regressor) Test Set Performance ---\n",
            "    - RMSE: 0.1394\n",
            "    - MAE: 0.0377\n",
            "\n",
            "--- Model Interpretability (SHAP) Analysis ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/shap/explainers/_deep/deep_tf.py:94: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: keras_tensor_51\n",
            "Received: inputs=['Tensor(shape=(100, 3))']\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: keras_tensor_51\n",
            "Received: inputs=['Tensor(shape=(200, 3))']\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SHAP values calculated for 100 test samples.\n",
            "Interpretation: SHAP values indicate how much each Level 1 model's prediction (input feature to meta-regressor) contributed to the final ensemble prediction for each sample.\n",
            "Positive SHAP value: The feature pushed the prediction higher.\n",
            "Negative SHAP value: The feature pushed the prediction lower.\n",
            "\n",
            "Mean Absolute SHAP Values (Feature Importance by Meta-Regressor):\n",
            "SHAP values are not in expected 2D array format for mean absolute calculation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c99e875b"
      },
      "source": [
        "# Task\n",
        "Analyze and improve a financial time series prediction project by implementing a multi-stage ensemble model. The plan involves using a CNN-LSTM-Attention model for feature extraction, training Level 1 XGBoost models on these features and additional \"extras\", and a Level 2 meta-regressor (XGBoost or Random Forest) to combine Level 1 predictions. The project should incorporate macroeconomic and potentially news data, use global time-aware data splits, and evaluate performance on a test set. The plan should also include analyzing the meta-regressor's importance scores and tuning hyperparameters using a validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d3c0743"
      },
      "source": [
        "## Data loading and initial preprocessing\n",
        "\n",
        "### Subtask:\n",
        "Load the raw financial time series data (using Alpaca), macroeconomic data (using pandas_datareader), and potentially news data (if a reliable historical source is found). Perform initial cleaning (handle missing values, basic outliers) and temporal alignment of all data sources to a common daily frequency.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3fc1478"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed to load the news articles CSV and consequently skipped the news processing. I need to ensure the news data is loaded correctly from the specified path and then proceed with the text processing and embedding generation as outlined in the subtask instructions. I will regenerate the code block for loading and processing news data, including error handling and verification steps.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8dd2bd6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Ensure the dataset_embeddings_stage1 is available\n",
        "if 'dataset_embeddings_stage1' in loaded_dataframes and loaded_dataframes['dataset_embeddings_stage1']:\n",
        "    # Access the targets from one of the window sizes (they are all aligned and should have the same targets)\n",
        "    # Pick the targets from the first window size available\n",
        "    first_window_size = sorted(loaded_dataframes['dataset_embeddings_stage1'].keys())[0]\n",
        "    targets = loaded_dataframes['dataset_embeddings_stage1'][first_window_size]['targets']\n",
        "\n",
        "    if targets.size > 0:\n",
        "        target_min = np.min(targets)\n",
        "        target_max = np.max(targets)\n",
        "        target_range = target_max - target_min\n",
        "\n",
        "        print(f\"The range of your target variable (log returns) is from {target_min:.4f} to {target_max:.4f}.\")\n",
        "        print(f\"The total range is: {target_range:.4f}\")\n",
        "\n",
        "        # Optional: Calculate standard deviation of targets for context\n",
        "        target_std = np.std(targets)\n",
        "        print(f\"The standard deviation of your target variable is: {target_std:.4f}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Target data is empty. Cannot determine the range.\")\n",
        "\n",
        "else:\n",
        "    print(\"Target data not found in loaded_dataframes['dataset_embeddings_stage1']. Please ensure Stage 1 training was successful.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7be882e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93310b0-04cb-4a2d-8a83-5ff9d0648cdc"
      },
      "source": [
        "pip install catboost"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91c52337"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize loaded_dataframes if not already present (for standalone execution)\n",
        "if 'loaded_dataframes' not in globals():\n",
        "    loaded_dataframes = {}\n",
        "    print(\"Initialized loaded_dataframes dictionary.\")\n",
        "\n",
        "# Ensure the dataset_embeddings_stage1 is available\n",
        "if 'dataset_embeddings_stage1' in loaded_dataframes and loaded_dataframes['dataset_embeddings_stage1']:\n",
        "    # Access the targets from one of the window sizes (they are all aligned and should have the same targets)\n",
        "    # Pick the targets from the first window size available\n",
        "    first_window_size = sorted(loaded_dataframes['dataset_embeddings_stage1'].keys())[0]\n",
        "    targets = loaded_dataframes['dataset_embeddings_stage1'][first_window_size]['targets']\n",
        "\n",
        "    if targets.size > 0:\n",
        "        target_min = np.min(targets)\n",
        "        target_max = np.max(targets)\n",
        "        target_range = target_max - target_min\n",
        "\n",
        "        print(f\"The range of your target variable (log returns) is from {target_min:.4f} to {target_max:.4f}.\")\n",
        "        print(f\"The total range is: {target_range:.4f}\")\n",
        "\n",
        "        # Optional: Calculate standard deviation of targets for context\n",
        "        target_std = np.std(targets)\n",
        "        print(f\"The standard deviation of your target variable is: {target_std:.4f}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Target data is empty. Cannot determine the range.\")\n",
        "\n",
        "else:\n",
        "    print(\"Target data not found in loaded_dataframes['dataset_embeddings_stage1']. Please ensure Stage 1 training was successful.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}